{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1602,"status":"ok","timestamp":1769012216055,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"_Yk55RhvJw8G","outputId":"2d0316d0-10c0-4a7a-fd9f-8e95ae628729"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14628,"status":"ok","timestamp":1769012230678,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"F8sURfFTjpEZ","outputId":"18dbcbc1-2d06-4772-b987-7f69337c2798"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n","Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n"]}],"source":["pip install catboost"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOjXGVk9VjH8","executionInfo":{"status":"ok","timestamp":1769012243922,"user_tz":-60,"elapsed":13241,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"ce134b9f-5c29-40b6-a6fb-171d78bbb4d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.7.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"]}],"source":["pip install optuna"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MYh81eBXKDOP","executionInfo":{"status":"ok","timestamp":1769012258030,"user_tz":-60,"elapsed":14100,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"3b651805-957d-4138-fae2-167ddc8b6b38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: feature-engine in /usr/local/lib/python3.12/dist-packages (1.9.3)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (2.0.2)\n","Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (2.2.2)\n","Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (1.6.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (1.16.3)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (0.14.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2025.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->feature-engine) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->feature-engine) (3.6.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.11.1->feature-engine) (1.0.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.11.1->feature-engine) (25.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->feature-engine) (1.17.0)\n"]}],"source":["pip install feature-engine"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpFSgeWnKJVP","executionInfo":{"status":"ok","timestamp":1769012272003,"user_tz":-60,"elapsed":13970,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"fdac898a-144a-4ef8-ff80-755ad979a5a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sktime in /usr/local/lib/python3.12/dist-packages (0.40.1)\n","Requirement already satisfied: joblib<1.6,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.5.3)\n","Requirement already satisfied: numpy<2.4,>=1.21 in /usr/local/lib/python3.12/dist-packages (from sktime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from sktime) (25.0)\n","Requirement already satisfied: pandas<2.4.0,>=1.1 in /usr/local/lib/python3.12/dist-packages (from sktime) (2.2.2)\n","Requirement already satisfied: scikit-base<0.14.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from sktime) (0.13.0)\n","Requirement already satisfied: scikit-learn<1.8.0,>=0.24 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.6.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.16.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2025.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=0.24->sktime) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=1.1->sktime) (1.17.0)\n"]}],"source":["pip install sktime"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Y1lHHjOIJ3fY","executionInfo":{"status":"ok","timestamp":1769012272014,"user_tz":-60,"elapsed":5,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","#import cmaes\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import logging\n","logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from feature_engine.datetime import DatetimeFeatures\n","from feature_engine.creation import CyclicalFeatures\n","from feature_engine.timeseries.forecasting import ExpandingWindowFeatures,LagFeatures\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","from sktime.transformations.series.fourier import FourierFeatures\n","from feature_engine.timeseries.forecasting import WindowFeatures\n","import holidays\n","from sklearn.ensemble import RandomForestRegressor\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"dvcVDWpOKRN3","executionInfo":{"status":"ok","timestamp":1769012272208,"user_tz":-60,"elapsed":196,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"outputs":[],"source":["def sliding_window_forecast_fixed_size(modelname, fcst, DF_training_scaled, DF_validation_scaled, scaler_target,\n","                                       prediction_horizon_steps=96, fixed_training_size=8832):\n","    \"\"\"\n","    Perform a sliding window forecast with a fixed-size training set.\n","\n","    Parameters:\n","    fcst (MLForecast): The forecast model.\n","    DF_training_scaled (pd.DataFrame): Scaled initial training data.\n","    DF_validation_scaled (pd.DataFrame): Scaled validation data for future predictions.\n","    scaler_target (MinMaxScaler): Scaler used to inverse transform the target variable.\n","    prediction_horizon_steps (int): Number of steps ahead to predict (default: 96).\n","    fixed_training_size (int): Fixed size of the rolling training window.\n","\n","    Returns:\n","    pd.DataFrame: A DataFrame containing the day-ahead predictions for each step.\n","    \"\"\"\n","    # Create an empty DataFrame to store all predictions\n","    all_preds = pd.DataFrame()\n","\n","    # Sliding window loop: run as long as there are enough validation points left\n","    num_iterations = len(DF_validation_scaled) // prediction_horizon_steps\n","\n","    for i in range(num_iterations):\n","        # Step 1: Fit the model on the current training data (empty static features)\n","        fcst.fit(DF_training_scaled, static_features=[])\n","\n","        # Step 2: Predict the next 'prediction_horizon_steps' (e.g., 96 steps)\n","        # Ensure only the next prediction_horizon_steps rows are passed to X_df\n","        X_df = DF_validation_scaled.drop(columns=[\"y\"], axis=1).iloc[:prediction_horizon_steps]\n","        preds = fcst.predict(h=prediction_horizon_steps, X_df=X_df)\n","\n","        # Step 3: Reshape and inverse transform the predictions to original scale\n","        predictions_reshaped = preds[modelname].to_numpy().reshape(-1, 1)\n","        predictions_original_scale = scaler_target.inverse_transform(predictions_reshaped).flatten()\n","\n","        # Step 4: Assign the predictions to the original DataFrame (store the time index 'ds' and unscaled predictions)\n","        preds[modelname+\"_unscaled\"] = predictions_original_scale\n","\n","        # Step 5: Append predictions to the results DataFrame\n","        all_preds = pd.concat([all_preds, preds], axis=0)\n","\n","        # Step 6: Update the training data by appending new validation data\n","        new_data = DF_validation_scaled.iloc[:prediction_horizon_steps]\n","\n","        # Remove the newly added data from DF_validation_scaled after each iteration\n","        DF_validation_scaled = DF_validation_scaled.iloc[prediction_horizon_steps:]\n","\n","        # Step 7: Maintain a fixed training size by appending new data and dropping the oldest data\n","        DF_training_scaled = pd.concat([DF_training_scaled, new_data], axis=0)\n","        if len(DF_training_scaled) > fixed_training_size:\n","            DF_training_scaled = DF_training_scaled.iloc[-fixed_training_size:]  # Keep only the latest entries\n","\n","    return all_preds\n","\n","def plot_predictions(model_name, df_validation_y, all_preds_unscaled):\n","    plt.figure(figsize=(14, 7))\n","\n","    # Plot actual values\n","    plt.plot(df_validation_y.index, df_validation_y.values, label='Actual Values', color='blue', linewidth=2)\n","\n","    # Plot predicted values\n","    plt.plot(all_preds_unscaled.index, all_preds_unscaled.values, label=f'Predicted Values ({model_name})', color='red', linestyle='-', linewidth=2)\n","\n","    # Add labels and title\n","    plt.xlabel('Time')\n","    plt.ylabel('Net Load')\n","    plt.title(f'Actual vs Predicted Values ({model_name})')\n","\n","    # Add legend\n","    plt.legend()\n","\n","    # Rotate x-ticks for better readability\n","    plt.xticks(rotation=45)\n","\n","    # Show the plot\n","    plt.tight_layout()\n","    plt.show()\n","\n","def CreateWorkHourFeature(input_data):\n","    \"\"\"\n","    Receives as input a DataFrame or Series and outputs a DataFrame with the working hours during the day.\n","    When the day of the week is larger than 4, it is considered a weekend (1), otherwise, it's a workday (0).\n","    During workdays and between 8:00 and 17:00, it is considered a working hour.\n","\n","    Parameters:\n","    input_data (DataFrame or Series): Input data with a DatetimeIndex.\n","\n","    Returns:\n","    DataFrame: DataFrame with the added \"WorkingHour_flag\" column.\n","    \"\"\"\n","    if isinstance(input_data, pd.Series):\n","        input_df = pd.DataFrame(input_data)\n","    elif isinstance(input_data, pd.DataFrame):\n","        input_df = input_data\n","    else:\n","        raise ValueError(\"Input must be a DataFrame or Series.\")\n","\n","    assert isinstance(input_df.index, pd.DatetimeIndex), \"Index must be a datetime index.\"\n","\n","    input_df[\"dayOfWeek\"] = input_df.index.dayofweek\n","    input_df.loc[input_df[\"dayOfWeek\"] > 4, \"weekendFlag\"] = 1\n","    input_df.loc[input_df[\"dayOfWeek\"] < 5, \"weekendFlag\"] = 0\n","    input_df[\"hour\"] = input_df.index.hour\n","    input_df[\"WorkingHour_flag\"] = 0\n","    input_df.loc[((input_df[\"hour\"] > 8) & (input_df[\"hour\"] < 17) & (input_df[\"weekendFlag\"] == 0)), \"WorkingHour_flag\"] = 1\n","    input_df.drop([\"hour\", \"dayOfWeek\", \"weekendFlag\"], axis=1, inplace=True)\n","\n","    return input_df\n","\n","\n","def ListCreatorFlagger(df, substrings=['flag', 'cos', 'sin','day_of_week', 'day_of_month', 'weekend', 'days_in_month', 'hour', 'minute']):\n","    \"\"\"\n","    A function that separates the columns containing specified substrings from those that don't.\n","    df is the dataframe in question and the substring is a list.\n","    \"\"\"\n","    flag_columns = [col for col in df.columns if any(substring in col for substring in substrings)]\n","\n","    if not flag_columns:\n","        print(\"No columns with the specified substrings found.\")\n","        return None, None\n","\n","    non_flag_columns = [col for col in df.columns if col not in flag_columns]\n","\n","    return non_flag_columns, flag_columns\n","\n","\n","def HolidayFeatureCreator(input_data):\n","    \"\"\"\n","    Receives as input a DataFrame or Series and creates a column named \"Holidays_flag\" with 1 if there is a holiday and with 0 if no holidays exist.\n","    Holidays derived from Germany.\n","    \"\"\"\n","    if isinstance(input_data, pd.Series):\n","        input_df = pd.DataFrame(input_data)\n","    elif isinstance(input_data, pd.DataFrame):\n","        input_df = input_data\n","    else:\n","        raise ValueError(\"Input must be a DataFrame or Series.\")\n","\n","    assert isinstance(input_df.index, pd.DatetimeIndex), \"Index must be a datetime index.\"\n","\n","    national_holidays_all = holidays.DE(years=[2014,2015,2016,2017,2018,2019,2020, 2021, 2022, 2023, 2024, 2025, 2026]).items()\n","    national_holidays = [items[0] for items in national_holidays_all]  # this is a list\n","\n","    # Create a new column for holidays flag\n","    input_df[\"Holidays_flag\"] = 0\n","\n","    # Iterate over the index and set holiday flag to 1 if the date matches any national holiday\n","    for index_date in input_df.index:\n","        if index_date.date() in national_holidays:\n","            input_df.at[index_date, \"Holidays_flag\"] = 1\n","\n","    return input_df\n","\n","\n","\n","\n","def TimeRelatedFeatureConstructor(df):\n","  \"\"\"\n","  Works only in a dataframe as input: run the other functions first.\n","  Extracts time-related features\n","  \"\"\"\n","  TimeFeaturesToExtract=[\"day_of_week\",\"weekend\",\"hour\",] #consider to add more\n","  dtfs=DatetimeFeatures(variables=\"index\", features_to_extract=TimeFeaturesToExtract, drop_original=False)\n","  df=dtfs.fit_transform(df)\n","\n","  CyclicalFeaturesToExtract=[\"day_of_week\",\"hour\",]\n","  cyclical_dtfs=CyclicalFeatures(variables=CyclicalFeaturesToExtract,drop_original=False)\n","  df=cyclical_dtfs.fit_transform(df)\n","  return df\n","\n","\n","def FourierFeatureConstructor(df, granularity, fourier_terms_list):\n","    # Extract numerical part of granularity\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    number_int = int(number_part) if number_part else 1  # Fallback to 1 to avoid division by zero\n","\n","    # Calculate minutes per hour, ensuring no division by zero\n","    minutes4hour = 60 / number_int if number_int != 0 else 60\n","\n","    # Define seasonal periods (sp_list) for Fourier transformation\n","    sp_list = [\n","        max(minutes4hour, 4),                 # Hourly - for 15min, this should be 4\n","        max(24 * minutes4hour, 96),           # Daily - for 15min, this should be 96\n","        max(24 * 7 * minutes4hour, 672),      # Weekly - for 15min, this should be 672\n","        max(24 * 30 * minutes4hour, 2880)     # Monthly - for 15min, this should be 2880\n","    ]\n","\n","    # Fourier transformer setup\n","    Fourier_Transformer = FourierFeatures(\n","        sp_list=sp_list,\n","        fourier_terms_list=fourier_terms_list,\n","        freq=granularity,\n","        keep_original_columns=True\n","    )\n","\n","    # Apply Fourier transformation\n","    Fourier_Transformer.fit(df)\n","    df = Fourier_Transformer.transform(df)\n","    return df\n","\n","\n","\n","def WindowFeaturesConstructor(df, granularity, ListWithNoFlags):\n","    \"\"\"\n","    This is a function that makes a list of 4 window features starting from double the granularity and following by doubling the previous value\n","    \"\"\"\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    number_int = int(number_part)\n","    double_granularity = 2 * number_int\n","    time_intervals = [double_granularity]\n","\n","    # Calculate subsequent values\n","    for i in range(3):\n","        time_intervals.append(time_intervals[-1] * 2)\n","\n","    windowlist = [interval // number_int for interval in time_intervals]  # Corrected division\n","    functionsList = [\"mean\", \"std\"]\n","    WindownFeatureTransformer = WindowFeatures(variables=ListWithNoFlags,\n","                                               functions=functionsList,\n","                                               window=windowlist,\n","                                               freq=granularity,\n","                                               drop_original=False)\n","\n","    df = WindownFeatureTransformer.fit_transform(df)\n","    return df\n","\n","def ExpandingWindowFeatureConstructor(df,ListWithNoFlags):\n","  functionsList=[\"mean\",\"std\"]\n","  frequency = pd.infer_freq(df.index) #infer the frequency from the dataframe\n","  ExpandingWindownFeatureTransformer=ExpandingWindowFeatures(variables=ListWithNoFlags,\n","                                                           functions=functionsList,\n","                                                           freq=frequency, #I put the freq to shift it down! but now it is performed automatically!\n","                                                           drop_original=False)\n","  df=ExpandingWindownFeatureTransformer.fit_transform(df)\n","  return df\n","\n","def WeightedLinearFeatureMaker(df,ListWithNoFlags,granularity):\n","  \"\"\"\n","  This is a function that takes the original DF and modifies the continious value columns\n","  Inputs: Dataframe, List of columns that are continous values, daily window to slide, weights of the values\n","  \"\"\"\n","  number_part = ''.join(filter(str.isdigit, granularity))\n","  Minutedensity=int(number_part)\n","  Window=int((60/Minutedensity)*24) #288 means a daily window\n","  weights=np.arange(1,Window+1)\n","\n","  # if i had hourly data then i would have had np.arange(1,24*7) for a weekly window\n","\n","  def weighted_mean (x,weights):\n","    return (weights*x).sum()/weights.sum()\n","\n","  def weighted_std(x,weights):\n","    mean_w= weighted_mean(x, weights)\n","    var_w= (weights* (x-mean_w)**2).sum()/weights.sum()\n","    return np.sqrt(var_w)\n","\n","  # LETS make the weighted mean column\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=Window) #here we pick a window size. Needs to be the same as the len(weights)\n","        .apply(weighted_mean, args=(weights,))\n","        .shift(1)#shift by 1 to avoid data leakage\n","        .to_frame()#convert series to df\n","        )\n","\n","    result.columns=[str(i)+\"_weighted_\"+str(Window)+\"_mean\"]\n","    df=df.join(result)\n","\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=Window) #here we pick a window size. Needs to be the same as the len(weights)\n","        .apply(weighted_std, args=(weights,))\n","        .shift(1)#shift by 1 to avoid data leakage\n","        .to_frame()#convert series to df\n","        )\n","\n","    result.columns=[str(i)+\"_weighted_\"+str(Window)+\"_std\"]\n","    df=df.join(result)\n","  return df\n","\n","def ExpWeightMeanMaker(df,ListWithNoFlags,granularity):\n","  \"\"\"\n","  This is a function that makes exp weighted average with a sliding window approach\n","  \"\"\"\n","  number_part = ''.join(filter(str.isdigit, granularity))\n","  Minutedensity=int(number_part)\n","  Window=int((60/Minutedensity)*24) #288 means a daily window\n","\n","  def exp_weights(alpha,window_size):\n","    \"\"\"\n","    a function to calculate the weights for every single component of our sliding windown\n","    \"\"\"\n","    weights=np.ones(window_size) #initializing weights\n","    for ix in range(window_size):\n","      weights[ix]=(1-alpha)**(window_size-1-ix)\n","    return weights\n","\n","  def exp_weighted_mean(x):\n","    \"\"\"\n","    a functions that calculates the exp weigted mean\n","    \"\"\"\n","\n","    weights=exp_weights(alpha=0.05, window_size=len(x)) # HERE WE SET THE ALPHA\n","    return (weights*x).sum()/weights.sum()\n","\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=int(Window))\n","        .agg([exp_weighted_mean])\n","        .shift(1)\n","    )\n","\n","\n","    result.columns=[str(i)+\"_Exp_weighted_\"+str(Window)+\"_SL.win\"]\n","    df=df.join(result)\n","  return df\n","\n","def WeightedExponentialExpandingWindow(df,ListWithNoFlags,alpha):\n","  \"\"\"\n","  This is a funtion that takes as input the df,a list of continuous values and the alpha.\n","  Outputs: all continuous features on the df that are \"mean\" and \"std\"\n","  \"\"\"\n","\n","  for i in ListWithNoFlags:\n","    df[[str(i)+\"_ewm_mean_expanding.win\",str(i)+\"ewm_std_expanding.win\"]]= (\n","                                              df[i].ewm(alpha=alpha).\n","                                              agg([\"mean\",\"std\"])\n","                                              .shift(1)\n","                                            )\n","  return df\n","\n","def FeatureLagger(df,ListOfFeatures,granularity,PredictionHorizon):\n","\n","    time_intervals = []\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    Minutedensity=int(number_part)\n","    end_in_day=int((PredictionHorizon)/(Minutedensity))\n","    for i in range(1, 1+end_in_day):  # 24 hours * 60 minutes / 15 minutes = 96 intervals\n","        time_intervals.append(f\"{i * 15}min\")\n","\n","    lag_transformer= LagFeatures(variables=ListOfFeatures,\n","                                freq=time_intervals,\n","                                drop_original=False) #make a lagger transformer drop all original features\n","\n","    df=lag_transformer.fit_transform(df) # transform the features to DF joined\n","    return df\n","\n","\n","def ErrorCalculator(name, y_true, y_pred):\n","    errors = {\"Pipelines\": name,\n","              \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n","              \"MAE\": mean_absolute_error(y_true, y_pred),\n","              \"MSE\": mean_squared_error(y_true, y_pred),\n","\n","             }\n","    return errors\n","\n","\n","def separate_future_past_features(df_columns):\n","    \"\"\"\n","    Separates future and past features from a list of dataframe columns.\n","\n","    Args:\n","        df_columns (list): A list of column names from the dataframe.\n","\n","    Returns:\n","        dict: A dictionary with keys 'future_features' and 'past_features', containing the respective lists of column names.\n","    \"\"\"\n","    future_keywords = ['sin', 'cos', 'weekend', 'hour', 'holiday', 'minute', 'day','+']\n","\n","    future_features = []\n","    past_features = []\n","\n","    for col in df_columns:\n","        # Check if the column contains \"+\" in its name to classify as a past feature\n","        if any(keyword in col.lower() for keyword in future_keywords):\n","            future_features.append(col)\n","        # Columns that don't meet the above conditions are considered past features by default\n","        else:\n","            past_features.append(col)\n","\n","    return future_features, past_features\n","\n","\n","def plot_errors (ErrorSeries):\n","  \"\"\"\n","  This is a function that plots the features that are not\n","  \"\"\"\n","  import matplotlib as mpl\n","  import matplotlib.pyplot as plt\n","  import matplotlib.path as mpath\n","  import numpy as np\n","\n","  import matplotlib.pyplot as plt\n","  import numpy as np\n","\n","  x = np.arange(len(ErrorSeries.index))\n","  y = ErrorSeries.values\n","  labels = ErrorSeries.index\n","\n","  plt.figure(1,figsize=(13,5))\n","  plt.style.use(\"seaborn-v0_8-whitegrid\")\n","  plt.plot(x, y)\n","\n","  plt.xticks(x, labels, rotation =40)\n","  plt.ylabel('RMSE [â‚¬/MWh]', wrap=True)\n","  plt.xlabel('Features', wrap=True)\n","\n","\n","  plt.margins(0.05)\n","\n","  plt.subplots_adjust(bottom = 0.05)\n","  plt.show()\n","\n","\n","def select_features_minimum_plus_others(series):\n","    \"\"\"\n","    Takes a pandas Series and selects the features that:\n","    - Include all features up to the minimum error.\n","    - After the minimum error, only include features that reduce the error compared to the previous one.\n","    - Ensures no duplicate features are added.\n","\n","    Parameters:\n","    - series: A pandas Series where index are feature names and values are errors.\n","\n","    Returns:\n","    - A list of selected feature names without duplicates.\n","    \"\"\"\n","    # Find the index of the minimum value\n","    min_idx = series.idxmin()\n","\n","    # Select all features up to and including the minimum\n","    selected_features = list(dict.fromkeys(series[:min_idx].index.tolist() + [min_idx]))\n","\n","    # After the minimum, keep only the features that decrease the error\n","    after_min_series = series[min_idx:]\n","\n","    # Loop through the series after the minimum value and add features that decrease the error\n","    for i in range(1, len(after_min_series)):\n","        if after_min_series[i] < after_min_series[i - 1]:\n","            feature = after_min_series.index[i]\n","            if feature not in selected_features:\n","                selected_features.append(feature)\n","\n","    return selected_features\n","\n","def keep_indices_till_min(series):\n","    \"\"\"\n","    Keeps all index values from the series up to and including the minimum value using a for loop,\n","    while ensuring no duplicates are added.\n","\n","    Parameters:\n","    - series: A pandas Series where the index are feature names and the values are errors.\n","\n","    Returns:\n","    - A list of unique index values (features) up to and including the minimum error value.\n","    \"\"\"\n","    # Initialize an empty list to store the selected indices\n","    selected_features = []\n","\n","    # Find the minimum value in the series\n","    min_value = series.min()\n","\n","    # Loop over the series\n","    for idx, value in series.items():\n","        # Add the current index to the selected features only if it's not already present\n","        if idx not in selected_features:\n","            selected_features.append(idx)\n","\n","        # If the current value is the minimum, stop the loop\n","        if value == min_value:\n","            break\n","\n","    return selected_features\n","\n","def laggedColumnCreator(df,columnName,lagStart, lagInterval, lagEnd):\n","  for i in range(lagStart, lagEnd+1, lagInterval):\n","     newColumnName = columnName + \"-\" + str(i) + \"step\" #you gotta put it in string\n","     df[newColumnName] = df[columnName].shift(i)\n","  return df\n","\n","\n","def make_splits(\n","    test_start_str: str,\n","    freq: str = \"15min\",      # your timestep\n","    val_days: int = 14,\n","    train_steps: int = 7000,\n","    test_days: int = 14,       # length of test period\n","):\n","    step = pd.to_timedelta(freq)\n","\n","    # TEST\n","    test_start = pd.Timestamp(test_start_str)\n","    # If you slice df.loc[start:end] (inclusive), use -step to get exactly `test_days` worth of data\n","    test_end = test_start + pd.Timedelta(days=test_days)\n","\n","    # VALIDATION (ends one step before test_start)\n","    validation_end = test_start - step\n","    # `val_days` long, inclusive: end - start = val_days days - step\n","    validation_start = validation_end - pd.Timedelta(days=val_days) + step\n","\n","    # TRAIN (ends one step before validation_start)\n","    train_end = validation_start - step\n","    # exactly `train_steps` steps long: end - start = (train_steps - 1) * step\n","    train_start = validation_start - train_steps * step\n","\n","    return {\n","        \"train_start\": train_start,\n","        \"train_end\": train_end,\n","        \"validation_start\": validation_start,\n","        \"validation_end\": validation_end,\n","        \"test_start\": test_start,\n","        \"test_end\": test_end,\n","    }\n","\n","\n","def FeatureSelection(regressor, DF_features, DF_target, ordered_features_list, test_size=672, tolerance=400):\n","    \"\"\"\n","    This function receives a regressor model, the features that the model was trained with,\n","    and the target that it had to forecast. Starting from the most important feature,\n","    we find the error of the TimeSeries Cross-Validation with a fixed test size.\n","    By adding features, we find the new error of the forecast.\n","\n","    Parameters:\n","    - regressor: The regression model to use for training and prediction.\n","    - DF_features: DataFrame containing the features.\n","    - DF_target: Series containing the target variable.\n","    - ordered_features_list: List of features ordered by importance (e.g., from SHAP analysis).\n","    - test_size: Number of steps to use in the test set (default is 672).\n","    - tolerance: Number of features to add before stopping if no improvement in error (default is 20).\n","\n","    Returns:\n","    - ErrorSeries: A pandas Series with the errors for each step of feature addition.\n","    \"\"\"\n","\n","    feature_list = []  # Empty list of features\n","    error_list = []  # Empty list to store errors for each set of features\n","    total_samples = len(DF_features)  # Total number of samples in the dataset\n","    n_splits = 5  # Number of splits (fixed)\n","    no_improvement_count = 0  # Count features added without improvement\n","    min_error = float('inf')  # Start with a large error to track the minimum error\n","\n","    for i in ordered_features_list:\n","        # Start the loop with the best feature and append the next ones\n","        feature_list.append(i)\n","\n","        X = DF_features[feature_list].to_numpy()\n","        y = DF_target.to_numpy()\n","\n","        #print(f\"Performing feature selection with features: {feature_list}\")\n","\n","        # Custom logic to create splits with a fixed test size of 672\n","        splits = []\n","        start_train_size = total_samples - (n_splits * test_size)  # Calculate where to start training\n","\n","        for split in range(n_splits):\n","            train_end = start_train_size + split * test_size\n","            test_start = train_end\n","            test_end = test_start + test_size\n","\n","            if test_end <= total_samples:  # Ensure the test set is within the bounds\n","                splits.append((list(range(0, train_end)), list(range(test_start, test_end))))\n","\n","        TimeSeriesCVerror = []  # MSE errors for each fold\n","\n","        # Time series cross-validation with fixed test size\n","        for train_index, test_index in splits:\n","            #print(f\"TRAIN: {train_index}, TEST: {test_index}\")\n","            X_train, X_test = X[train_index], X[test_index]\n","            y_train, y_test = y[train_index], y[test_index]\n","\n","            # Train the regressor and predict\n","            regressor.fit(X_train, y_train)\n","            predicted_val = regressor.predict(X_test)\n","\n","            # Calculate the error for this fold\n","            Error = np.sqrt(mean_squared_error(y_test, predicted_val))\n","            TimeSeriesCVerror.append(Error)\n","            #print(f\"This is the error for one TS iteration: {Error}\")\n","\n","        # Calculate the average error across all splits\n","        TS_CV_error = sum(TimeSeriesCVerror) / len(TimeSeriesCVerror)\n","        #print(f\"Cumulative error of the last steps: {TS_CV_error}\")\n","        error_list.append(TS_CV_error)  # Store the error for this set of features\n","\n","        # Check if the error improved\n","        if TS_CV_error < min_error:\n","            min_error = TS_CV_error  # Update the minimum error\n","            no_improvement_count = 0  # Reset the no-improvement count\n","        else:\n","            no_improvement_count += 1  # Increment if there's no improvement\n","\n","        # Break the loop if no improvement is observed after 20 features\n","        if no_improvement_count >= tolerance:\n","            print(f\"No improvement after {tolerance} features. Stopping early.\")\n","            break\n","\n","    # Create a pandas Series to store the error associated with each feature\n","    ErrorSeries = pd.Series(error_list, index=feature_list)\n","\n","    # Plot the errors using a custom plot function\n","    plot_errors(ErrorSeries)\n","\n","    return ErrorSeries"]},{"cell_type":"markdown","metadata":{"id":"jncuxW1sR5BZ"},"source":["# start"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9hNWTTUR4fm","executionInfo":{"status":"ok","timestamp":1769012290184,"user_tz":-60,"elapsed":17972,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"80c3ef15-0143-4337-8135-91ffc40998c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["this is the prediction horizon in steps 144\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"Holidays_flag\"] = 0\n","/tmp/ipython-input-2329344273.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"dayOfWeek\"] = input_df.index.dayofweek\n","/tmp/ipython-input-2329344273.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df.loc[input_df[\"dayOfWeek\"] > 4, \"weekendFlag\"] = 1\n","/tmp/ipython-input-2329344273.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"hour\"] = input_df.index.hour\n","/tmp/ipython-input-2329344273.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"WorkingHour_flag\"] = 0\n"]}],"source":["filename=\"NO2_price_10min_2024_2025.xlsx\"\n","#define the path of the folder with the data\n","path=\"/content/gdrive/MyDrive/IEEE-EEM2026/\"\n","#join the folder with the name of the file I want to study\n","\n","df = pd.read_excel(os.path.join(path,filename), parse_dates=[0]).set_index('timestamp')\n","df = df[~df.index.duplicated(keep='first')] # Drop duplicate timestamps before setting frequency\n","df = df.asfreq('10min') # Set the frequency of the index\n","\n","OriginalFeatures=df.columns.to_list()\n","\n","df[\"target\"]=df[\"NO2 price (NOK/kWh)\"]\n","target=\"target\"\n","\n","OutputPath = r\"C:\\Users\\User\\Desktop\\_badenova_forecaster\\outputs\"\n","\n","granularity=\"10min\"\n","prediction_horizon=\"1440min\"\n","\n","number_part_hor = ''.join(filter(str.isdigit, prediction_horizon))\n","PredictionHorizon=int(number_part_hor)\n","number_part = ''.join(filter(str.isdigit, granularity))\n","Minutedensity=int(number_part)\n","fourier_terms_list=[2,2,2,2]\n","prediction_horizon_steps=PredictionHorizon//Minutedensity # this is 96\n","print(\"this is the prediction horizon in steps\", prediction_horizon_steps)\n","# lets make some features\n","lagStart = prediction_horizon_steps          # Start lagging from 1 step\n","lagInterval = 1       # Interval of 1 step\n","lagEnd = prediction_horizon_steps *2\n","\n","for feature in OriginalFeatures:\n","    df = laggedColumnCreator(df, feature, lagStart, lagInterval, lagEnd)\n","#lets build the target and the features\n","df=HolidayFeatureCreator(df)\n","df=CreateWorkHourFeature(df)\n","df=TimeRelatedFeatureConstructor(df)\n","df=FourierFeatureConstructor(df,granularity,fourier_terms_list)\n","\n","df=df.drop(columns=OriginalFeatures)\n","\n","df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"IZ-YxhBlV0ub","executionInfo":{"status":"ok","timestamp":1769012290295,"user_tz":-60,"elapsed":106,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"outputs":[],"source":["test_date=\"2025-06-01 00:00:00\" #summer\n","#test_date=\"2025-02-01 00:00:00\" #winter\n","\n","\n","# Example\n","splits = make_splits(test_date, freq=\"10min\", val_days=14, train_steps=5000)\n","\n","train_start=splits[\"train_start\"]\n","train_end=splits[\"train_end\"]\n","validation_start=splits[\"validation_start\"]\n","validation_end=splits[\"validation_end\"]\n","test_start=splits[\"test_start\"]\n","test_end =splits[\"test_end\"]\n","\n","#lets split them\n","DF_training = df[train_start:train_end]  # Include up to train_end_date\n","DF_validation = df[validation_start:validation_end]  # Start after train_end_date\n","DF_test = df[test_start:test_end]  # Start after validation_end_date\n","\n","\n","DF_training_and_DF_validation=pd.concat([DF_training,DF_validation])\n","Selected_Features=DF_training_and_DF_validation.drop([target],axis=1) # df, all features except target in a dataframe for the first period\n","DF_target=DF_training_and_DF_validation[target] #one column df of the target for the next period\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"15e45b85","executionInfo":{"status":"ok","timestamp":1769012541242,"user_tz":-60,"elapsed":250939,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6af4594-b415-4ea4-8706-fe360e91be0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE scores for each fold: [np.float64(0.4938315051105351), np.float64(0.38424906703216344), np.float64(0.25979307493779197), np.float64(0.26571803963682), np.float64(0.31205875626088725)]\n","Average RMSE across all folds: 0.34313008859563954\n"]}],"source":["from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","from catboost import CatBoostRegressor\n","\n","# Define features (X) and target (y)\n","X = Selected_Features\n","y = DF_target\n","\n","# Initialize XGBRegressor\n","model = CatBoostRegressor(random_state=42, verbose=0) # Added verbose=0 to suppress training output\n","\n","# Initialize TimeSeriesSplit\n","# n_splits determines the number of train/test splits to generate.\n","# Each split's training set grows, and its test set is a fixed size (the last part of the data).\n","# For example, if n_splits=5, there will be 5 splits.\n","# The first split might use 20% for train, 20% for test, and the last uses 80% for train, 20% for test.\n","tscv = TimeSeriesSplit(n_splits=5)\n","\n","rmse_scores = []\n","\n","# Perform Time Series Cross-Validation\n","for train_index, test_index in tscv.split(X):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate RMSE and store it\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","    rmse_scores.append(rmse)\n","\n","print(f\"RMSE scores for each fold: {rmse_scores}\")\n","print(f\"Average RMSE across all folds: {np.mean(rmse_scores)}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"4b40e176","executionInfo":{"status":"ok","timestamp":1769012541248,"user_tz":-60,"elapsed":123,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b408e347-9e2f-42c9-c8e8-33c27f2e2914"},"outputs":[{"output_type":"stream","name":"stdout","text":["Optuna objective function 'objective' defined successfully with CatBoost-specific hyperparameters.\n"]}],"source":["import optuna\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","from catboost import CatBoostRegressor\n","\n","def objective(trial):\n","    # 3. Suggest hyperparameters for CatBoost\n","    param = {\n","        'iterations': trial.suggest_int('iterations', 100, 1000), # Equivalent to n_estimators\n","        'depth': trial.suggest_int('depth', 3, 9), # Equivalent to max_depth\n","        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","        'subsample': trial.suggest_float('subsample', 0.6, 1.0), # Fraction of samples to use for fitting the trees\n","        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0), # Fraction of features to use per level\n","        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n","        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 30), # Minimum number of samples in a leaf\n","        'random_seed': 42,\n","        'verbose': 0 # Suppress training output\n","    }\n","\n","    # 4. Initialize a CatBoostRegressor model using the suggested hyperparameters\n","    model = CatBoostRegressor(**param)\n","\n","    # 5. Instantiate TimeSeriesSplit\n","    tscv = TimeSeriesSplit(n_splits=5)\n","\n","    # 6. Initialize an empty list to store RMSE scores for each fold\n","    rmse_scores = []\n","\n","    # Use the globally available X (Selected_Features) and y (DF_target)\n","    X = Selected_Features\n","    y = DF_target\n","\n","    # 7. Loop through the splits generated by TimeSeriesSplit\n","    for train_index, test_index in tscv.split(X):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","        # 8. Train the model and make predictions\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # 9. Calculate RMSE for each fold and append it to the rmse_scores list\n","        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","        rmse_scores.append(rmse)\n","\n","    # 10. Calculate the mean of the rmse_scores\n","    mean_rmse = np.mean(rmse_scores)\n","\n","    # 11. Return the calculated mean RMSE\n","    return mean_rmse\n","\n","print(\"Optuna objective function 'objective' defined successfully with CatBoost-specific hyperparameters.\")"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"c62d71e9","executionInfo":{"status":"ok","timestamp":1769014994722,"user_tz":-60,"elapsed":2453482,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b6a5ba7219984275a84a25291af09b32","a5e45a7cb0034ebbbf33d8c53649de5a","57a69e3e2a2e4221a1f97b1b02aa7507","8fd1becba2274420b99658a0823cc60b","7a6e98119dd4492b9d3d66b66646a02b","73a99106d24e4efbac2e67da635e4d14","0a7420353cae49079aae1b09c068bf99","f2ce56365c2b4b6db143f4d247d0d0a5","0b517c6ee06446f4bc368451a0d9b963","bb506c2878cf4b5c873cd521b22ee96f","a4d56b6adb18455cbddcfe9062ee67ac"]},"outputId":"922890a8-31de-4518-fb38-20be3134ce6b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2026-01-21 16:22:22,054] A new study created in memory with name: no-name-11bc166e-0bd6-426b-9b0c-328174c5f026\n"]},{"output_type":"stream","name":"stdout","text":["Starting Optuna optimization...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a5ba7219984275a84a25291af09b32"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:33:35,927] Trial 0 finished with value: 0.3528972215748389 and parameters: {'iterations': 437, 'depth': 9, 'learning_rate': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bylevel': 0.6624074561769746, 'l2_leaf_reg': 0.004207053950287938, 'min_data_in_leaf': 2}. Best is trial 0 with value: 0.3528972215748389.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:39:50,834] Trial 1 finished with value: 0.34493905622186904 and parameters: {'iterations': 880, 'depth': 7, 'learning_rate': 0.11114989443094977, 'subsample': 0.608233797718321, 'colsample_bylevel': 0.9879639408647978, 'l2_leaf_reg': 2.1368329072358767, 'min_data_in_leaf': 7}. Best is trial 1 with value: 0.34493905622186904.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:40:12,191] Trial 2 finished with value: 0.3353322583616562 and parameters: {'iterations': 263, 'depth': 4, 'learning_rate': 0.028145092716060652, 'subsample': 0.8099025726528951, 'colsample_bylevel': 0.7727780074568463, 'l2_leaf_reg': 0.014618962793704957, 'min_data_in_leaf': 19}. Best is trial 2 with value: 0.3353322583616562.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:40:48,610] Trial 3 finished with value: 0.3382317817407371 and parameters: {'iterations': 225, 'depth': 5, 'learning_rate': 0.03476649150592621, 'subsample': 0.7824279936868144, 'colsample_bylevel': 0.9140703845572055, 'l2_leaf_reg': 0.006290644294586149, 'min_data_in_leaf': 16}. Best is trial 2 with value: 0.3353322583616562.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:41:15,399] Trial 4 finished with value: 0.3462201865782587 and parameters: {'iterations': 633, 'depth': 3, 'learning_rate': 0.07896186801026692, 'subsample': 0.6682096494749166, 'colsample_bylevel': 0.6260206371941118, 'l2_leaf_reg': 6.245139574743075, 'min_data_in_leaf': 29}. Best is trial 2 with value: 0.3353322583616562.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:43:12,126] Trial 5 finished with value: 0.34287439204695735 and parameters: {'iterations': 828, 'depth': 5, 'learning_rate': 0.013940346079873234, 'subsample': 0.8736932106048627, 'colsample_bylevel': 0.7760609974958406, 'l2_leaf_reg': 0.003077180271250686, 'min_data_in_leaf': 15}. Best is trial 2 with value: 0.3353322583616562.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:46:47,222] Trial 6 finished with value: 0.336728248989972 and parameters: {'iterations': 130, 'depth': 9, 'learning_rate': 0.024112898115291985, 'subsample': 0.8650089137415928, 'colsample_bylevel': 0.7246844304357644, 'l2_leaf_reg': 0.12030178871154672, 'min_data_in_leaf': 17}. Best is trial 2 with value: 0.3353322583616562.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:54:27,697] Trial 7 finished with value: 0.34550875892433014 and parameters: {'iterations': 266, 'depth': 9, 'learning_rate': 0.13962563737015762, 'subsample': 0.9757995766256756, 'colsample_bylevel': 0.9579309401710595, 'l2_leaf_reg': 0.24637685958997463, 'min_data_in_leaf': 28}. Best is trial 2 with value: 0.3353322583616562.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:54:43,853] Trial 8 finished with value: 0.3290987077406068 and parameters: {'iterations': 179, 'depth': 4, 'learning_rate': 0.011662890273931383, 'subsample': 0.7301321323053057, 'colsample_bylevel': 0.7554709158757928, 'l2_leaf_reg': 0.01217295809836997, 'min_data_in_leaf': 25}. Best is trial 8 with value: 0.3290987077406068.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:55:20,875] Trial 9 finished with value: 0.3530781796672689 and parameters: {'iterations': 421, 'depth': 4, 'learning_rate': 0.06333268775321842, 'subsample': 0.6563696899899051, 'colsample_bylevel': 0.9208787923016158, 'l2_leaf_reg': 0.0019870215385428634, 'min_data_in_leaf': 30}. Best is trial 8 with value: 0.3290987077406068.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:59:37,931] Trial 10 finished with value: 0.3610701893001981 and parameters: {'iterations': 562, 'depth': 7, 'learning_rate': 0.27047297227177763, 'subsample': 0.7387403565626488, 'colsample_bylevel': 0.8560354009870226, 'l2_leaf_reg': 0.03320258070519291, 'min_data_in_leaf': 22}. Best is trial 8 with value: 0.3290987077406068.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:59:45,211] Trial 11 finished with value: 0.34457159637400936 and parameters: {'iterations': 110, 'depth': 3, 'learning_rate': 0.010145748985881197, 'subsample': 0.7347390152853027, 'colsample_bylevel': 0.7834697240695936, 'l2_leaf_reg': 0.0191105329608563, 'min_data_in_leaf': 23}. Best is trial 8 with value: 0.3290987077406068.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:00:29,978] Trial 12 finished with value: 0.3410708458812196 and parameters: {'iterations': 336, 'depth': 5, 'learning_rate': 0.02126743947839957, 'subsample': 0.7807747864725972, 'colsample_bylevel': 0.7124283041267608, 'l2_leaf_reg': 0.026832483895444594, 'min_data_in_leaf': 22}. Best is trial 8 with value: 0.3290987077406068.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:01:32,152] Trial 13 finished with value: 0.34722461674383653 and parameters: {'iterations': 721, 'depth': 4, 'learning_rate': 0.036483583545466734, 'subsample': 0.9418772351343092, 'colsample_bylevel': 0.83238303297342, 'l2_leaf_reg': 0.0010893830666974071, 'min_data_in_leaf': 11}. Best is trial 8 with value: 0.3290987077406068.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1028683451.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","/tmp/ipython-input-1028683451.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0), # L2 regularization term on weights\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:03:11,423] Trial 14 finished with value: 0.33798319033721896 and parameters: {'iterations': 418, 'depth': 6, 'learning_rate': 0.016866290936609026, 'subsample': 0.7119963901081219, 'colsample_bylevel': 0.7364639864192708, 'l2_leaf_reg': 0.45042834710787033, 'min_data_in_leaf': 25}. Best is trial 8 with value: 0.3290987077406068.\n","Optuna optimization finished.\n","\n","Best trial:\n","  Value (Mean RMSE): 0.3291\n","  Params:\n","    iterations: 179\n","    depth: 4\n","    learning_rate: 0.011662890273931383\n","    subsample: 0.7301321323053057\n","    colsample_bylevel: 0.7554709158757928\n","    l2_leaf_reg: 0.01217295809836997\n","    min_data_in_leaf: 25\n","\n","Training final CatBoostRegressor model with best parameters...\n","0:\tlearn: 0.3773322\ttotal: 44.8ms\tremaining: 7.97s\n","1:\tlearn: 0.3754357\ttotal: 87.6ms\tremaining: 7.75s\n","2:\tlearn: 0.3736071\ttotal: 132ms\tremaining: 7.76s\n","3:\tlearn: 0.3718699\ttotal: 177ms\tremaining: 7.72s\n","4:\tlearn: 0.3701692\ttotal: 217ms\tremaining: 7.56s\n","5:\tlearn: 0.3682661\ttotal: 248ms\tremaining: 7.15s\n","6:\tlearn: 0.3663864\ttotal: 295ms\tremaining: 7.25s\n","7:\tlearn: 0.3646581\ttotal: 326ms\tremaining: 6.96s\n","8:\tlearn: 0.3629732\ttotal: 354ms\tremaining: 6.69s\n","9:\tlearn: 0.3611436\ttotal: 391ms\tremaining: 6.6s\n","10:\tlearn: 0.3594956\ttotal: 429ms\tremaining: 6.55s\n","11:\tlearn: 0.3578336\ttotal: 461ms\tremaining: 6.41s\n","12:\tlearn: 0.3563542\ttotal: 501ms\tremaining: 6.39s\n","13:\tlearn: 0.3547702\ttotal: 535ms\tremaining: 6.3s\n","14:\tlearn: 0.3531562\ttotal: 578ms\tremaining: 6.32s\n","15:\tlearn: 0.3515890\ttotal: 607ms\tremaining: 6.19s\n","16:\tlearn: 0.3499728\ttotal: 639ms\tremaining: 6.09s\n","17:\tlearn: 0.3484641\ttotal: 677ms\tremaining: 6.05s\n","18:\tlearn: 0.3469941\ttotal: 726ms\tremaining: 6.11s\n","19:\tlearn: 0.3454708\ttotal: 759ms\tremaining: 6.03s\n","20:\tlearn: 0.3440315\ttotal: 787ms\tremaining: 5.92s\n","21:\tlearn: 0.3425812\ttotal: 831ms\tremaining: 5.93s\n","22:\tlearn: 0.3411885\ttotal: 869ms\tremaining: 5.89s\n","23:\tlearn: 0.3399972\ttotal: 903ms\tremaining: 5.83s\n","24:\tlearn: 0.3386736\ttotal: 936ms\tremaining: 5.76s\n","25:\tlearn: 0.3373351\ttotal: 969ms\tremaining: 5.7s\n","26:\tlearn: 0.3359922\ttotal: 1s\tremaining: 5.65s\n","27:\tlearn: 0.3347603\ttotal: 1.03s\tremaining: 5.58s\n","28:\tlearn: 0.3333840\ttotal: 1.07s\tremaining: 5.52s\n","29:\tlearn: 0.3321179\ttotal: 1.11s\tremaining: 5.53s\n","30:\tlearn: 0.3307930\ttotal: 1.14s\tremaining: 5.45s\n","31:\tlearn: 0.3295846\ttotal: 1.17s\tremaining: 5.38s\n","32:\tlearn: 0.3283225\ttotal: 1.21s\tremaining: 5.34s\n","33:\tlearn: 0.3270960\ttotal: 1.25s\tremaining: 5.33s\n","34:\tlearn: 0.3259705\ttotal: 1.28s\tremaining: 5.28s\n","35:\tlearn: 0.3249187\ttotal: 1.32s\tremaining: 5.25s\n","36:\tlearn: 0.3237091\ttotal: 1.36s\tremaining: 5.21s\n","37:\tlearn: 0.3225513\ttotal: 1.39s\tremaining: 5.16s\n","38:\tlearn: 0.3214354\ttotal: 1.41s\tremaining: 5.08s\n","39:\tlearn: 0.3203672\ttotal: 1.45s\tremaining: 5.03s\n","40:\tlearn: 0.3192268\ttotal: 1.48s\tremaining: 4.98s\n","41:\tlearn: 0.3180124\ttotal: 1.51s\tremaining: 4.93s\n","42:\tlearn: 0.3169932\ttotal: 1.55s\tremaining: 4.92s\n","43:\tlearn: 0.3159135\ttotal: 1.6s\tremaining: 4.91s\n","44:\tlearn: 0.3148372\ttotal: 1.64s\tremaining: 4.88s\n","45:\tlearn: 0.3138763\ttotal: 1.67s\tremaining: 4.82s\n","46:\tlearn: 0.3129126\ttotal: 1.7s\tremaining: 4.79s\n","47:\tlearn: 0.3119916\ttotal: 1.74s\tremaining: 4.75s\n","48:\tlearn: 0.3110095\ttotal: 1.77s\tremaining: 4.71s\n","49:\tlearn: 0.3100524\ttotal: 1.79s\tremaining: 4.63s\n","50:\tlearn: 0.3090661\ttotal: 1.81s\tremaining: 4.55s\n","51:\tlearn: 0.3081327\ttotal: 1.83s\tremaining: 4.47s\n","52:\tlearn: 0.3071386\ttotal: 1.85s\tremaining: 4.4s\n","53:\tlearn: 0.3062106\ttotal: 1.86s\tremaining: 4.32s\n","54:\tlearn: 0.3053331\ttotal: 1.88s\tremaining: 4.25s\n","55:\tlearn: 0.3044794\ttotal: 1.9s\tremaining: 4.17s\n","56:\tlearn: 0.3036819\ttotal: 1.92s\tremaining: 4.1s\n","57:\tlearn: 0.3028217\ttotal: 1.93s\tremaining: 4.03s\n","58:\tlearn: 0.3019335\ttotal: 1.95s\tremaining: 3.97s\n","59:\tlearn: 0.3011222\ttotal: 1.97s\tremaining: 3.9s\n","60:\tlearn: 0.3002396\ttotal: 1.98s\tremaining: 3.83s\n","61:\tlearn: 0.2995310\ttotal: 2s\tremaining: 3.77s\n","62:\tlearn: 0.2988329\ttotal: 2.01s\tremaining: 3.71s\n","63:\tlearn: 0.2979863\ttotal: 2.03s\tremaining: 3.65s\n","64:\tlearn: 0.2972952\ttotal: 2.04s\tremaining: 3.59s\n","65:\tlearn: 0.2964718\ttotal: 2.06s\tremaining: 3.53s\n","66:\tlearn: 0.2957453\ttotal: 2.07s\tremaining: 3.47s\n","67:\tlearn: 0.2949886\ttotal: 2.09s\tremaining: 3.41s\n","68:\tlearn: 0.2942228\ttotal: 2.11s\tremaining: 3.36s\n","69:\tlearn: 0.2934267\ttotal: 2.12s\tremaining: 3.31s\n","70:\tlearn: 0.2926840\ttotal: 2.14s\tremaining: 3.25s\n","71:\tlearn: 0.2919680\ttotal: 2.15s\tremaining: 3.2s\n","72:\tlearn: 0.2912482\ttotal: 2.17s\tremaining: 3.15s\n","73:\tlearn: 0.2905117\ttotal: 2.18s\tremaining: 3.1s\n","74:\tlearn: 0.2898413\ttotal: 2.19s\tremaining: 3.04s\n","75:\tlearn: 0.2891884\ttotal: 2.21s\tremaining: 3s\n","76:\tlearn: 0.2884579\ttotal: 2.22s\tremaining: 2.94s\n","77:\tlearn: 0.2877487\ttotal: 2.24s\tremaining: 2.9s\n","78:\tlearn: 0.2870353\ttotal: 2.25s\tremaining: 2.85s\n","79:\tlearn: 0.2863652\ttotal: 2.27s\tremaining: 2.81s\n","80:\tlearn: 0.2857499\ttotal: 2.3s\tremaining: 2.79s\n","81:\tlearn: 0.2850688\ttotal: 2.32s\tremaining: 2.75s\n","82:\tlearn: 0.2845229\ttotal: 2.35s\tremaining: 2.71s\n","83:\tlearn: 0.2838495\ttotal: 2.36s\tremaining: 2.67s\n","84:\tlearn: 0.2832758\ttotal: 2.38s\tremaining: 2.63s\n","85:\tlearn: 0.2826815\ttotal: 2.4s\tremaining: 2.59s\n","86:\tlearn: 0.2820718\ttotal: 2.41s\tremaining: 2.55s\n","87:\tlearn: 0.2814103\ttotal: 2.43s\tremaining: 2.51s\n","88:\tlearn: 0.2808472\ttotal: 2.45s\tremaining: 2.48s\n","89:\tlearn: 0.2801630\ttotal: 2.47s\tremaining: 2.44s\n","90:\tlearn: 0.2795885\ttotal: 2.49s\tremaining: 2.4s\n","91:\tlearn: 0.2788806\ttotal: 2.5s\tremaining: 2.37s\n","92:\tlearn: 0.2782551\ttotal: 2.52s\tremaining: 2.33s\n","93:\tlearn: 0.2776599\ttotal: 2.53s\tremaining: 2.29s\n","94:\tlearn: 0.2770448\ttotal: 2.55s\tremaining: 2.25s\n","95:\tlearn: 0.2764986\ttotal: 2.56s\tremaining: 2.21s\n","96:\tlearn: 0.2759172\ttotal: 2.58s\tremaining: 2.18s\n","97:\tlearn: 0.2753029\ttotal: 2.6s\tremaining: 2.15s\n","98:\tlearn: 0.2747736\ttotal: 2.62s\tremaining: 2.12s\n","99:\tlearn: 0.2742413\ttotal: 2.63s\tremaining: 2.08s\n","100:\tlearn: 0.2737285\ttotal: 2.65s\tremaining: 2.05s\n","101:\tlearn: 0.2732274\ttotal: 2.67s\tremaining: 2.01s\n","102:\tlearn: 0.2727604\ttotal: 2.68s\tremaining: 1.98s\n","103:\tlearn: 0.2722901\ttotal: 2.7s\tremaining: 1.95s\n","104:\tlearn: 0.2717450\ttotal: 2.71s\tremaining: 1.91s\n","105:\tlearn: 0.2712927\ttotal: 2.73s\tremaining: 1.88s\n","106:\tlearn: 0.2707992\ttotal: 2.74s\tremaining: 1.84s\n","107:\tlearn: 0.2703039\ttotal: 2.76s\tremaining: 1.81s\n","108:\tlearn: 0.2697374\ttotal: 2.77s\tremaining: 1.78s\n","109:\tlearn: 0.2692540\ttotal: 2.79s\tremaining: 1.75s\n","110:\tlearn: 0.2687738\ttotal: 2.8s\tremaining: 1.72s\n","111:\tlearn: 0.2683246\ttotal: 2.82s\tremaining: 1.68s\n","112:\tlearn: 0.2678912\ttotal: 2.84s\tremaining: 1.66s\n","113:\tlearn: 0.2674274\ttotal: 2.85s\tremaining: 1.63s\n","114:\tlearn: 0.2670343\ttotal: 2.87s\tremaining: 1.6s\n","115:\tlearn: 0.2665915\ttotal: 2.88s\tremaining: 1.57s\n","116:\tlearn: 0.2661483\ttotal: 2.9s\tremaining: 1.54s\n","117:\tlearn: 0.2657131\ttotal: 2.92s\tremaining: 1.51s\n","118:\tlearn: 0.2653168\ttotal: 2.94s\tremaining: 1.48s\n","119:\tlearn: 0.2647660\ttotal: 2.95s\tremaining: 1.45s\n","120:\tlearn: 0.2643189\ttotal: 2.97s\tremaining: 1.43s\n","121:\tlearn: 0.2639458\ttotal: 2.99s\tremaining: 1.4s\n","122:\tlearn: 0.2634388\ttotal: 3s\tremaining: 1.37s\n","123:\tlearn: 0.2630302\ttotal: 3.02s\tremaining: 1.34s\n","124:\tlearn: 0.2626054\ttotal: 3.03s\tremaining: 1.31s\n","125:\tlearn: 0.2622718\ttotal: 3.05s\tremaining: 1.28s\n","126:\tlearn: 0.2618789\ttotal: 3.07s\tremaining: 1.26s\n","127:\tlearn: 0.2614888\ttotal: 3.09s\tremaining: 1.23s\n","128:\tlearn: 0.2610233\ttotal: 3.11s\tremaining: 1.2s\n","129:\tlearn: 0.2606914\ttotal: 3.12s\tremaining: 1.18s\n","130:\tlearn: 0.2603710\ttotal: 3.14s\tremaining: 1.15s\n","131:\tlearn: 0.2599816\ttotal: 3.15s\tremaining: 1.12s\n","132:\tlearn: 0.2594557\ttotal: 3.17s\tremaining: 1.09s\n","133:\tlearn: 0.2590685\ttotal: 3.18s\tremaining: 1.07s\n","134:\tlearn: 0.2587439\ttotal: 3.2s\tremaining: 1.04s\n","135:\tlearn: 0.2582591\ttotal: 3.22s\tremaining: 1.02s\n","136:\tlearn: 0.2579386\ttotal: 3.23s\tremaining: 991ms\n","137:\tlearn: 0.2575464\ttotal: 3.25s\tremaining: 965ms\n","138:\tlearn: 0.2571194\ttotal: 3.26s\tremaining: 939ms\n","139:\tlearn: 0.2567500\ttotal: 3.28s\tremaining: 914ms\n","140:\tlearn: 0.2562125\ttotal: 3.31s\tremaining: 892ms\n","141:\tlearn: 0.2558562\ttotal: 3.34s\tremaining: 871ms\n","142:\tlearn: 0.2554860\ttotal: 3.36s\tremaining: 846ms\n","143:\tlearn: 0.2551217\ttotal: 3.38s\tremaining: 821ms\n","144:\tlearn: 0.2547103\ttotal: 3.39s\tremaining: 796ms\n","145:\tlearn: 0.2542794\ttotal: 3.41s\tremaining: 770ms\n","146:\tlearn: 0.2537678\ttotal: 3.42s\tremaining: 745ms\n","147:\tlearn: 0.2534259\ttotal: 3.44s\tremaining: 720ms\n","148:\tlearn: 0.2531723\ttotal: 3.45s\tremaining: 695ms\n","149:\tlearn: 0.2527741\ttotal: 3.46s\tremaining: 670ms\n","150:\tlearn: 0.2524697\ttotal: 3.48s\tremaining: 646ms\n","151:\tlearn: 0.2521028\ttotal: 3.5s\tremaining: 622ms\n","152:\tlearn: 0.2517545\ttotal: 3.52s\tremaining: 599ms\n","153:\tlearn: 0.2514766\ttotal: 3.54s\tremaining: 575ms\n","154:\tlearn: 0.2511852\ttotal: 3.56s\tremaining: 551ms\n","155:\tlearn: 0.2507315\ttotal: 3.57s\tremaining: 527ms\n","156:\tlearn: 0.2503498\ttotal: 3.59s\tremaining: 503ms\n","157:\tlearn: 0.2499977\ttotal: 3.6s\tremaining: 479ms\n","158:\tlearn: 0.2496480\ttotal: 3.62s\tremaining: 455ms\n","159:\tlearn: 0.2492766\ttotal: 3.63s\tremaining: 432ms\n","160:\tlearn: 0.2489798\ttotal: 3.65s\tremaining: 408ms\n","161:\tlearn: 0.2487014\ttotal: 3.66s\tremaining: 384ms\n","162:\tlearn: 0.2484193\ttotal: 3.68s\tremaining: 361ms\n","163:\tlearn: 0.2481683\ttotal: 3.7s\tremaining: 338ms\n","164:\tlearn: 0.2479190\ttotal: 3.71s\tremaining: 315ms\n","165:\tlearn: 0.2476082\ttotal: 3.73s\tremaining: 292ms\n","166:\tlearn: 0.2473514\ttotal: 3.74s\tremaining: 269ms\n","167:\tlearn: 0.2470800\ttotal: 3.76s\tremaining: 246ms\n","168:\tlearn: 0.2467468\ttotal: 3.78s\tremaining: 224ms\n","169:\tlearn: 0.2464907\ttotal: 3.8s\tremaining: 201ms\n","170:\tlearn: 0.2461061\ttotal: 3.81s\tremaining: 178ms\n","171:\tlearn: 0.2457806\ttotal: 3.83s\tremaining: 156ms\n","172:\tlearn: 0.2455832\ttotal: 3.84s\tremaining: 133ms\n","173:\tlearn: 0.2452031\ttotal: 3.86s\tremaining: 111ms\n","174:\tlearn: 0.2449905\ttotal: 3.87s\tremaining: 88.5ms\n","175:\tlearn: 0.2446171\ttotal: 3.89s\tremaining: 66.3ms\n","176:\tlearn: 0.2441831\ttotal: 3.91s\tremaining: 44.1ms\n","177:\tlearn: 0.2437434\ttotal: 3.92s\tremaining: 22ms\n","178:\tlearn: 0.2434356\ttotal: 3.94s\tremaining: 0us\n","{'Pipelines': 'CatBoost', 'RMSE': np.float64(0.2364840613701683), 'MAE': 0.16758344795208874, 'MSE': 0.05592471128212954}\n"]}],"source":["import joblib\n","import optuna\n","\n","# 1. Create an Optuna study\n","# Using a TPE sampler with a seed for reproducibility\n","sampler = optuna.samplers.TPESampler(seed=42)\n","study = optuna.create_study(direction='minimize', sampler=sampler)\n","\n","# 2. Run the optimization process\n","# You can adjust n_trials based on computational resources and desired exploration\n","print(\"Starting Optuna optimization...\")\n","study.optimize(objective, n_trials=15, show_progress_bar=True)\n","print(\"Optuna optimization finished.\")\n","\n","# 3. Print the best trial's value and parameters\n","print(\"\\nBest trial:\")\n","trial = study.best_trial\n","print(f\"  Value (Mean RMSE): {trial.value:.4f}\")\n","print(\"  Params:\")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")\n","\n","# 4. Retrieve the best hyperparameters from the Optuna study\n","best_params = study.best_params\n","\n","# 5. Train a final CatBoostRegressor model with the best parameters\n","print(\"\\nTraining final CatBoostRegressor model with best parameters...\")\n","final_model = CatBoostRegressor(**best_params, random_state=42)\n","\n","\n","X_train=DF_training_and_DF_validation.drop([target],axis=1) # df, all features except target in a dataframe for the first period\n","X_test=DF_test.drop([target],axis=1) #df , all feature except target (same as before but for the next available period period)\n","y_train=DF_training_and_DF_validation[target] #one column df, of the target for the first period\n","y_test=DF_test[target] #one column df of the target for the next period\n","\n","\n","final_model.fit(X_train , y_train)\n","\n","predicted_val = final_model.predict(X_test)\n","\n","name=\"CatBoost\"\n","d=ErrorCalculator(name,y_test,predicted_val)\n","print(d)"]},{"cell_type":"markdown","metadata":{"id":"aDRBZVyWIAnR"},"source":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"00BVmpFpcar0","executionInfo":{"status":"ok","timestamp":1769014995391,"user_tz":-60,"elapsed":663,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/","height":499},"outputId":"c029fcc4-03d1-462a-862a-5c34b9fc1a13"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='timestamp'>"]},"metadata":{},"execution_count":27},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["predicted_DF = pd.DataFrame(predicted_val , index=DF_test.index, columns=[\"CatBoost\"])\n","\n","predicted_DF = predicted_DF.join(y_test)\n","\n","predicted_DF=predicted_DF.loc[DF_test.index]\n","\n","predicted_DF.columns = [\"CatBoost\", \"target\"]\n","\n","\n","predicted_DF[:300].plot()"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"pihCwffEc-2b","executionInfo":{"status":"ok","timestamp":1769014995394,"user_tz":-60,"elapsed":7,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"outputs":[],"source":["# Ensure it's a Timestamp / datetime\n","test_date_ts = pd.to_datetime(test_date)\n","\n","# Format without forbidden chars (:, etc.)\n","test_date_str = test_date_ts.strftime(\"%Y-%m-%d_%H-%M-%S\")  # e.g. 2025-09-19_00-00-00\n","\n","test_ts = f\"{test_date_str}_CatBoost.csv\"\n","test_filepath = os.path.join(path, test_ts)\n","\n","predicted_DF[\"CatBoost\"].to_csv(test_filepath, index=True)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b6a5ba7219984275a84a25291af09b32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5e45a7cb0034ebbbf33d8c53649de5a","IPY_MODEL_57a69e3e2a2e4221a1f97b1b02aa7507","IPY_MODEL_8fd1becba2274420b99658a0823cc60b"],"layout":"IPY_MODEL_7a6e98119dd4492b9d3d66b66646a02b"}},"a5e45a7cb0034ebbbf33d8c53649de5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73a99106d24e4efbac2e67da635e4d14","placeholder":"â€‹","style":"IPY_MODEL_0a7420353cae49079aae1b09c068bf99","value":"Bestâ€‡trial:â€‡8.â€‡Bestâ€‡value:â€‡0.329099:â€‡100%"}},"57a69e3e2a2e4221a1f97b1b02aa7507":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2ce56365c2b4b6db143f4d247d0d0a5","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b517c6ee06446f4bc368451a0d9b963","value":15}},"8fd1becba2274420b99658a0823cc60b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb506c2878cf4b5c873cd521b22ee96f","placeholder":"â€‹","style":"IPY_MODEL_a4d56b6adb18455cbddcfe9062ee67ac","value":"â€‡15/15â€‡[40:49&lt;00:00,â€‡91.05s/it]"}},"7a6e98119dd4492b9d3d66b66646a02b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73a99106d24e4efbac2e67da635e4d14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a7420353cae49079aae1b09c068bf99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2ce56365c2b4b6db143f4d247d0d0a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b517c6ee06446f4bc368451a0d9b963":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb506c2878cf4b5c873cd521b22ee96f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4d56b6adb18455cbddcfe9062ee67ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}