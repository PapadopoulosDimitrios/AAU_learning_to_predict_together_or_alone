{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1157,"status":"ok","timestamp":1769012232614,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"_Yk55RhvJw8G","outputId":"529af80e-2459-469d-cff6-4ff62e522f5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13713,"status":"ok","timestamp":1769012246330,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"nOjXGVk9VjH8","outputId":"0ea612b9-c0d6-4774-b69c-403d20989435"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.7.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"]}],"source":["pip install optuna"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12660,"status":"ok","timestamp":1769012258995,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"MYh81eBXKDOP","outputId":"90fc0cde-aa8d-49a6-8e73-e7d4164eb194"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: feature-engine in /usr/local/lib/python3.12/dist-packages (1.9.3)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (2.0.2)\n","Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (2.2.2)\n","Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (1.6.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (1.16.3)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (0.14.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2025.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->feature-engine) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->feature-engine) (3.6.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.11.1->feature-engine) (1.0.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.11.1->feature-engine) (25.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->feature-engine) (1.17.0)\n"]}],"source":["pip install feature-engine"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14192,"status":"ok","timestamp":1769012273190,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"jpFSgeWnKJVP","outputId":"d47f165b-d2cc-4525-b1a6-802c32948773"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sktime in /usr/local/lib/python3.12/dist-packages (0.40.1)\n","Requirement already satisfied: joblib<1.6,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.5.3)\n","Requirement already satisfied: numpy<2.4,>=1.21 in /usr/local/lib/python3.12/dist-packages (from sktime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from sktime) (25.0)\n","Requirement already satisfied: pandas<2.4.0,>=1.1 in /usr/local/lib/python3.12/dist-packages (from sktime) (2.2.2)\n","Requirement already satisfied: scikit-base<0.14.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from sktime) (0.13.0)\n","Requirement already satisfied: scikit-learn<1.8.0,>=0.24 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.6.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.16.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2025.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=0.24->sktime) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=1.1->sktime) (1.17.0)\n"]}],"source":["pip install sktime"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":75,"status":"ok","timestamp":1769012273271,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"Y1lHHjOIJ3fY"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","#import cmaes\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import logging\n","logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from feature_engine.datetime import DatetimeFeatures\n","from feature_engine.creation import CyclicalFeatures\n","from feature_engine.timeseries.forecasting import ExpandingWindowFeatures,LagFeatures\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","from sktime.transformations.series.fourier import FourierFeatures\n","from feature_engine.timeseries.forecasting import WindowFeatures\n","import holidays\n","from sklearn.ensemble import RandomForestRegressor\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":79,"status":"ok","timestamp":1769012273353,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"dvcVDWpOKRN3"},"outputs":[],"source":["def sliding_window_forecast_fixed_size(modelname, fcst, DF_training_scaled, DF_validation_scaled, scaler_target,\n","                                       prediction_horizon_steps=96, fixed_training_size=8832):\n","    \"\"\"\n","    Perform a sliding window forecast with a fixed-size training set.\n","\n","    Parameters:\n","    fcst (MLForecast): The forecast model.\n","    DF_training_scaled (pd.DataFrame): Scaled initial training data.\n","    DF_validation_scaled (pd.DataFrame): Scaled validation data for future predictions.\n","    scaler_target (MinMaxScaler): Scaler used to inverse transform the target variable.\n","    prediction_horizon_steps (int): Number of steps ahead to predict (default: 96).\n","    fixed_training_size (int): Fixed size of the rolling training window.\n","\n","    Returns:\n","    pd.DataFrame: A DataFrame containing the day-ahead predictions for each step.\n","    \"\"\"\n","    # Create an empty DataFrame to store all predictions\n","    all_preds = pd.DataFrame()\n","\n","    # Sliding window loop: run as long as there are enough validation points left\n","    num_iterations = len(DF_validation_scaled) // prediction_horizon_steps\n","\n","    for i in range(num_iterations):\n","        # Step 1: Fit the model on the current training data (empty static features)\n","        fcst.fit(DF_training_scaled, static_features=[])\n","\n","        # Step 2: Predict the next 'prediction_horizon_steps' (e.g., 96 steps)\n","        # Ensure only the next prediction_horizon_steps rows are passed to X_df\n","        X_df = DF_validation_scaled.drop(columns=[\"y\"], axis=1).iloc[:prediction_horizon_steps]\n","        preds = fcst.predict(h=prediction_horizon_steps, X_df=X_df)\n","\n","        # Step 3: Reshape and inverse transform the predictions to original scale\n","        predictions_reshaped = preds[modelname].to_numpy().reshape(-1, 1)\n","        predictions_original_scale = scaler_target.inverse_transform(predictions_reshaped).flatten()\n","\n","        # Step 4: Assign the predictions to the original DataFrame (store the time index 'ds' and unscaled predictions)\n","        preds[modelname+\"_unscaled\"] = predictions_original_scale\n","\n","        # Step 5: Append predictions to the results DataFrame\n","        all_preds = pd.concat([all_preds, preds], axis=0)\n","\n","        # Step 6: Update the training data by appending new validation data\n","        new_data = DF_validation_scaled.iloc[:prediction_horizon_steps]\n","\n","        # Remove the newly added data from DF_validation_scaled after each iteration\n","        DF_validation_scaled = DF_validation_scaled.iloc[prediction_horizon_steps:]\n","\n","        # Step 7: Maintain a fixed training size by appending new data and dropping the oldest data\n","        DF_training_scaled = pd.concat([DF_training_scaled, new_data], axis=0)\n","        if len(DF_training_scaled) > fixed_training_size:\n","            DF_training_scaled = DF_training_scaled.iloc[-fixed_training_size:]  # Keep only the latest entries\n","\n","    return all_preds\n","\n","def plot_predictions(model_name, df_validation_y, all_preds_unscaled):\n","    plt.figure(figsize=(14, 7))\n","\n","    # Plot actual values\n","    plt.plot(df_validation_y.index, df_validation_y.values, label='Actual Values', color='blue', linewidth=2)\n","\n","    # Plot predicted values\n","    plt.plot(all_preds_unscaled.index, all_preds_unscaled.values, label=f'Predicted Values ({model_name})', color='red', linestyle='-', linewidth=2)\n","\n","    # Add labels and title\n","    plt.xlabel('Time')\n","    plt.ylabel('Net Load')\n","    plt.title(f'Actual vs Predicted Values ({model_name})')\n","\n","    # Add legend\n","    plt.legend()\n","\n","    # Rotate x-ticks for better readability\n","    plt.xticks(rotation=45)\n","\n","    # Show the plot\n","    plt.tight_layout()\n","    plt.show()\n","\n","def CreateWorkHourFeature(input_data):\n","    \"\"\"\n","    Receives as input a DataFrame or Series and outputs a DataFrame with the working hours during the day.\n","    When the day of the week is larger than 4, it is considered a weekend (1), otherwise, it's a workday (0).\n","    During workdays and between 8:00 and 17:00, it is considered a working hour.\n","\n","    Parameters:\n","    input_data (DataFrame or Series): Input data with a DatetimeIndex.\n","\n","    Returns:\n","    DataFrame: DataFrame with the added \"WorkingHour_flag\" column.\n","    \"\"\"\n","    if isinstance(input_data, pd.Series):\n","        input_df = pd.DataFrame(input_data)\n","    elif isinstance(input_data, pd.DataFrame):\n","        input_df = input_data\n","    else:\n","        raise ValueError(\"Input must be a DataFrame or Series.\")\n","\n","    assert isinstance(input_df.index, pd.DatetimeIndex), \"Index must be a datetime index.\"\n","\n","    input_df[\"dayOfWeek\"] = input_df.index.dayofweek\n","    input_df.loc[input_df[\"dayOfWeek\"] > 4, \"weekendFlag\"] = 1\n","    input_df.loc[input_df[\"dayOfWeek\"] < 5, \"weekendFlag\"] = 0\n","    input_df[\"hour\"] = input_df.index.hour\n","    input_df[\"WorkingHour_flag\"] = 0\n","    input_df.loc[((input_df[\"hour\"] > 8) & (input_df[\"hour\"] < 17) & (input_df[\"weekendFlag\"] == 0)), \"WorkingHour_flag\"] = 1\n","    input_df.drop([\"hour\", \"dayOfWeek\", \"weekendFlag\"], axis=1, inplace=True)\n","\n","    return input_df\n","\n","\n","def ListCreatorFlagger(df, substrings=['flag', 'cos', 'sin','day_of_week', 'day_of_month', 'weekend', 'days_in_month', 'hour', 'minute']):\n","    \"\"\"\n","    A function that separates the columns containing specified substrings from those that don't.\n","    df is the dataframe in question and the substring is a list.\n","    \"\"\"\n","    flag_columns = [col for col in df.columns if any(substring in col for substring in substrings)]\n","\n","    if not flag_columns:\n","        print(\"No columns with the specified substrings found.\")\n","        return None, None\n","\n","    non_flag_columns = [col for col in df.columns if col not in flag_columns]\n","\n","    return non_flag_columns, flag_columns\n","\n","\n","def HolidayFeatureCreator(input_data):\n","    \"\"\"\n","    Receives as input a DataFrame or Series and creates a column named \"Holidays_flag\" with 1 if there is a holiday and with 0 if no holidays exist.\n","    Holidays derived from Germany.\n","    \"\"\"\n","    if isinstance(input_data, pd.Series):\n","        input_df = pd.DataFrame(input_data)\n","    elif isinstance(input_data, pd.DataFrame):\n","        input_df = input_data\n","    else:\n","        raise ValueError(\"Input must be a DataFrame or Series.\")\n","\n","    assert isinstance(input_df.index, pd.DatetimeIndex), \"Index must be a datetime index.\"\n","\n","    national_holidays_all = holidays.DE(years=[2014,2015,2016,2017,2018,2019,2020, 2021, 2022, 2023, 2024, 2025, 2026]).items()\n","    national_holidays = [items[0] for items in national_holidays_all]  # this is a list\n","\n","    # Create a new column for holidays flag\n","    input_df[\"Holidays_flag\"] = 0\n","\n","    # Iterate over the index and set holiday flag to 1 if the date matches any national holiday\n","    for index_date in input_df.index:\n","        if index_date.date() in national_holidays:\n","            input_df.at[index_date, \"Holidays_flag\"] = 1\n","\n","    return input_df\n","\n","\n","\n","\n","def TimeRelatedFeatureConstructor(df):\n","  \"\"\"\n","  Works only in a dataframe as input: run the other functions first.\n","  Extracts time-related features\n","  \"\"\"\n","  TimeFeaturesToExtract=[\"day_of_week\",\"weekend\",\"hour\",] #consider to add more\n","  dtfs=DatetimeFeatures(variables=\"index\", features_to_extract=TimeFeaturesToExtract, drop_original=False)\n","  df=dtfs.fit_transform(df)\n","\n","  CyclicalFeaturesToExtract=[\"day_of_week\",\"hour\",]\n","  cyclical_dtfs=CyclicalFeatures(variables=CyclicalFeaturesToExtract,drop_original=False)\n","  df=cyclical_dtfs.fit_transform(df)\n","  return df\n","\n","\n","def FourierFeatureConstructor(df, granularity, fourier_terms_list):\n","    # Extract numerical part of granularity\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    number_int = int(number_part) if number_part else 1  # Fallback to 1 to avoid division by zero\n","\n","    # Calculate minutes per hour, ensuring no division by zero\n","    minutes4hour = 60 / number_int if number_int != 0 else 60\n","\n","    # Define seasonal periods (sp_list) for Fourier transformation\n","    sp_list = [\n","        max(minutes4hour, 4),                 # Hourly - for 15min, this should be 4\n","        max(24 * minutes4hour, 96),           # Daily - for 15min, this should be 96\n","        max(24 * 7 * minutes4hour, 672),      # Weekly - for 15min, this should be 672\n","        max(24 * 30 * minutes4hour, 2880)     # Monthly - for 15min, this should be 2880\n","    ]\n","\n","    # Fourier transformer setup\n","    Fourier_Transformer = FourierFeatures(\n","        sp_list=sp_list,\n","        fourier_terms_list=fourier_terms_list,\n","        freq=granularity,\n","        keep_original_columns=True\n","    )\n","\n","    # Apply Fourier transformation\n","    Fourier_Transformer.fit(df)\n","    df = Fourier_Transformer.transform(df)\n","    return df\n","\n","\n","\n","def WindowFeaturesConstructor(df, granularity, ListWithNoFlags):\n","    \"\"\"\n","    This is a function that makes a list of 4 window features starting from double the granularity and following by doubling the previous value\n","    \"\"\"\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    number_int = int(number_part)\n","    double_granularity = 2 * number_int\n","    time_intervals = [double_granularity]\n","\n","    # Calculate subsequent values\n","    for i in range(3):\n","        time_intervals.append(time_intervals[-1] * 2)\n","\n","    windowlist = [interval // number_int for interval in time_intervals]  # Corrected division\n","    functionsList = [\"mean\", \"std\"]\n","    WindownFeatureTransformer = WindowFeatures(variables=ListWithNoFlags,\n","                                               functions=functionsList,\n","                                               window=windowlist,\n","                                               freq=granularity,\n","                                               drop_original=False)\n","\n","    df = WindownFeatureTransformer.fit_transform(df)\n","    return df\n","\n","def ExpandingWindowFeatureConstructor(df,ListWithNoFlags):\n","  functionsList=[\"mean\",\"std\"]\n","  frequency = pd.infer_freq(df.index) #infer the frequency from the dataframe\n","  ExpandingWindownFeatureTransformer=ExpandingWindowFeatures(variables=ListWithNoFlags,\n","                                                           functions=functionsList,\n","                                                           freq=frequency, #I put the freq to shift it down! but now it is performed automatically!\n","                                                           drop_original=False)\n","  df=ExpandingWindownFeatureTransformer.fit_transform(df)\n","  return df\n","\n","def WeightedLinearFeatureMaker(df,ListWithNoFlags,granularity):\n","  \"\"\"\n","  This is a function that takes the original DF and modifies the continious value columns\n","  Inputs: Dataframe, List of columns that are continous values, daily window to slide, weights of the values\n","  \"\"\"\n","  number_part = ''.join(filter(str.isdigit, granularity))\n","  Minutedensity=int(number_part)\n","  Window=int((60/Minutedensity)*24) #288 means a daily window\n","  weights=np.arange(1,Window+1)\n","\n","  # if i had hourly data then i would have had np.arange(1,24*7) for a weekly window\n","\n","  def weighted_mean (x,weights):\n","    return (weights*x).sum()/weights.sum()\n","\n","  def weighted_std(x,weights):\n","    mean_w= weighted_mean(x, weights)\n","    var_w= (weights* (x-mean_w)**2).sum()/weights.sum()\n","    return np.sqrt(var_w)\n","\n","  # LETS make the weighted mean column\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=Window) #here we pick a window size. Needs to be the same as the len(weights)\n","        .apply(weighted_mean, args=(weights,))\n","        .shift(1)#shift by 1 to avoid data leakage\n","        .to_frame()#convert series to df\n","        )\n","\n","    result.columns=[str(i)+\"_weighted_\"+str(Window)+\"_mean\"]\n","    df=df.join(result)\n","\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=Window) #here we pick a window size. Needs to be the same as the len(weights)\n","        .apply(weighted_std, args=(weights,))\n","        .shift(1)#shift by 1 to avoid data leakage\n","        .to_frame()#convert series to df\n","        )\n","\n","    result.columns=[str(i)+\"_weighted_\"+str(Window)+\"_std\"]\n","    df=df.join(result)\n","  return df\n","\n","def ExpWeightMeanMaker(df,ListWithNoFlags,granularity):\n","  \"\"\"\n","  This is a function that makes exp weighted average with a sliding window approach\n","  \"\"\"\n","  number_part = ''.join(filter(str.isdigit, granularity))\n","  Minutedensity=int(number_part)\n","  Window=int((60/Minutedensity)*24) #288 means a daily window\n","\n","  def exp_weights(alpha,window_size):\n","    \"\"\"\n","    a function to calculate the weights for every single component of our sliding windown\n","    \"\"\"\n","    weights=np.ones(window_size) #initializing weights\n","    for ix in range(window_size):\n","      weights[ix]=(1-alpha)**(window_size-1-ix)\n","    return weights\n","\n","  def exp_weighted_mean(x):\n","    \"\"\"\n","    a functions that calculates the exp weigted mean\n","    \"\"\"\n","\n","    weights=exp_weights(alpha=0.05, window_size=len(x)) # HERE WE SET THE ALPHA\n","    return (weights*x).sum()/weights.sum()\n","\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=int(Window))\n","        .agg([exp_weighted_mean])\n","        .shift(1)\n","    )\n","\n","\n","    result.columns=[str(i)+\"_Exp_weighted_\"+str(Window)+\"_SL.win\"]\n","    df=df.join(result)\n","  return df\n","\n","def WeightedExponentialExpandingWindow(df,ListWithNoFlags,alpha):\n","  \"\"\"\n","  This is a funtion that takes as input the df,a list of continuous values and the alpha.\n","  Outputs: all continuous features on the df that are \"mean\" and \"std\"\n","  \"\"\"\n","\n","  for i in ListWithNoFlags:\n","    df[[str(i)+\"_ewm_mean_expanding.win\",str(i)+\"ewm_std_expanding.win\"]]= (\n","                                              df[i].ewm(alpha=alpha).\n","                                              agg([\"mean\",\"std\"])\n","                                              .shift(1)\n","                                            )\n","  return df\n","\n","def FeatureLagger(df,ListOfFeatures,granularity,PredictionHorizon):\n","\n","    time_intervals = []\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    Minutedensity=int(number_part)\n","    end_in_day=int((PredictionHorizon)/(Minutedensity))\n","    for i in range(1, 1+end_in_day):  # 24 hours * 60 minutes / 15 minutes = 96 intervals\n","        time_intervals.append(f\"{i * 15}min\")\n","\n","    lag_transformer= LagFeatures(variables=ListOfFeatures,\n","                                freq=time_intervals,\n","                                drop_original=False) #make a lagger transformer drop all original features\n","\n","    df=lag_transformer.fit_transform(df) # transform the features to DF joined\n","    return df\n","\n","\n","def ErrorCalculator(name, y_true, y_pred):\n","    errors = {\"Pipelines\": name,\n","              \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n","              \"MAE\": mean_absolute_error(y_true, y_pred),\n","              \"MSE\": mean_squared_error(y_true, y_pred),\n","\n","             }\n","    return errors\n","\n","\n","def separate_future_past_features(df_columns):\n","    \"\"\"\n","    Separates future and past features from a list of dataframe columns.\n","\n","    Args:\n","        df_columns (list): A list of column names from the dataframe.\n","\n","    Returns:\n","        dict: A dictionary with keys 'future_features' and 'past_features', containing the respective lists of column names.\n","    \"\"\"\n","    future_keywords = ['sin', 'cos', 'weekend', 'hour', 'holiday', 'minute', 'day','+']\n","\n","    future_features = []\n","    past_features = []\n","\n","    for col in df_columns:\n","        # Check if the column contains \"+\" in its name to classify as a past feature\n","        if any(keyword in col.lower() for keyword in future_keywords):\n","            future_features.append(col)\n","        # Columns that don't meet the above conditions are considered past features by default\n","        else:\n","            past_features.append(col)\n","\n","    return future_features, past_features\n","\n","\n","def plot_errors (ErrorSeries):\n","  \"\"\"\n","  This is a function that plots the features that are not\n","  \"\"\"\n","  import matplotlib as mpl\n","  import matplotlib.pyplot as plt\n","  import matplotlib.path as mpath\n","  import numpy as np\n","\n","  import matplotlib.pyplot as plt\n","  import numpy as np\n","\n","  x = np.arange(len(ErrorSeries.index))\n","  y = ErrorSeries.values\n","  labels = ErrorSeries.index\n","\n","  plt.figure(1,figsize=(13,5))\n","  plt.style.use(\"seaborn-v0_8-whitegrid\")\n","  plt.plot(x, y)\n","\n","  plt.xticks(x, labels, rotation =40)\n","  plt.ylabel('RMSE [â‚¬/MWh]', wrap=True)\n","  plt.xlabel('Features', wrap=True)\n","\n","\n","  plt.margins(0.05)\n","\n","  plt.subplots_adjust(bottom = 0.05)\n","  plt.show()\n","\n","\n","def select_features_minimum_plus_others(series):\n","    \"\"\"\n","    Takes a pandas Series and selects the features that:\n","    - Include all features up to the minimum error.\n","    - After the minimum error, only include features that reduce the error compared to the previous one.\n","    - Ensures no duplicate features are added.\n","\n","    Parameters:\n","    - series: A pandas Series where index are feature names and values are errors.\n","\n","    Returns:\n","    - A list of selected feature names without duplicates.\n","    \"\"\"\n","    # Find the index of the minimum value\n","    min_idx = series.idxmin()\n","\n","    # Select all features up to and including the minimum\n","    selected_features = list(dict.fromkeys(series[:min_idx].index.tolist() + [min_idx]))\n","\n","    # After the minimum, keep only the features that decrease the error\n","    after_min_series = series[min_idx:]\n","\n","    # Loop through the series after the minimum value and add features that decrease the error\n","    for i in range(1, len(after_min_series)):\n","        if after_min_series[i] < after_min_series[i - 1]:\n","            feature = after_min_series.index[i]\n","            if feature not in selected_features:\n","                selected_features.append(feature)\n","\n","    return selected_features\n","\n","def keep_indices_till_min(series):\n","    \"\"\"\n","    Keeps all index values from the series up to and including the minimum value using a for loop,\n","    while ensuring no duplicates are added.\n","\n","    Parameters:\n","    - series: A pandas Series where the index are feature names and the values are errors.\n","\n","    Returns:\n","    - A list of unique index values (features) up to and including the minimum error value.\n","    \"\"\"\n","    # Initialize an empty list to store the selected indices\n","    selected_features = []\n","\n","    # Find the minimum value in the series\n","    min_value = series.min()\n","\n","    # Loop over the series\n","    for idx, value in series.items():\n","        # Add the current index to the selected features only if it's not already present\n","        if idx not in selected_features:\n","            selected_features.append(idx)\n","\n","        # If the current value is the minimum, stop the loop\n","        if value == min_value:\n","            break\n","\n","    return selected_features\n","\n","def laggedColumnCreator(df,columnName,lagStart, lagInterval, lagEnd):\n","  for i in range(lagStart, lagEnd+1, lagInterval):\n","     newColumnName = columnName + \"-\" + str(i) + \"step\" #you gotta put it in string\n","     df[newColumnName] = df[columnName].shift(i)\n","  return df\n","\n","\n","def make_splits(\n","    test_start_str: str,\n","    freq: str = \"15min\",      # your timestep\n","    val_days: int = 14,\n","    train_steps: int = 7000,\n","    test_days: int = 14,       # length of test period\n","):\n","    step = pd.to_timedelta(freq)\n","\n","    # TEST\n","    test_start = pd.Timestamp(test_start_str)\n","    # If you slice df.loc[start:end] (inclusive), use -step to get exactly `test_days` worth of data\n","    test_end = test_start + pd.Timedelta(days=test_days)\n","\n","    # VALIDATION (ends one step before test_start)\n","    validation_end = test_start - step\n","    # `val_days` long, inclusive: end - start = val_days days - step\n","    validation_start = validation_end - pd.Timedelta(days=val_days) + step\n","\n","    # TRAIN (ends one step before validation_start)\n","    train_end = validation_start - step\n","    # exactly `train_steps` steps long: end - start = (train_steps - 1) * step\n","    train_start = validation_start - train_steps * step\n","\n","    return {\n","        \"train_start\": train_start,\n","        \"train_end\": train_end,\n","        \"validation_start\": validation_start,\n","        \"validation_end\": validation_end,\n","        \"test_start\": test_start,\n","        \"test_end\": test_end,\n","    }\n","\n","\n","def FeatureSelection(regressor, DF_features, DF_target, ordered_features_list, test_size=672, tolerance=400):\n","    \"\"\"\n","    This function receives a regressor model, the features that the model was trained with,\n","    and the target that it had to forecast. Starting from the most important feature,\n","    we find the error of the TimeSeries Cross-Validation with a fixed test size.\n","    By adding features, we find the new error of the forecast.\n","\n","    Parameters:\n","    - regressor: The regression model to use for training and prediction.\n","    - DF_features: DataFrame containing the features.\n","    - DF_target: Series containing the target variable.\n","    - ordered_features_list: List of features ordered by importance (e.g., from SHAP analysis).\n","    - test_size: Number of steps to use in the test set (default is 672).\n","    - tolerance: Number of features to add before stopping if no improvement in error (default is 20).\n","\n","    Returns:\n","    - ErrorSeries: A pandas Series with the errors for each step of feature addition.\n","    \"\"\"\n","\n","    feature_list = []  # Empty list of features\n","    error_list = []  # Empty list to store errors for each set of features\n","    total_samples = len(DF_features)  # Total number of samples in the dataset\n","    n_splits = 5  # Number of splits (fixed)\n","    no_improvement_count = 0  # Count features added without improvement\n","    min_error = float('inf')  # Start with a large error to track the minimum error\n","\n","    for i in ordered_features_list:\n","        # Start the loop with the best feature and append the next ones\n","        feature_list.append(i)\n","\n","        X = DF_features[feature_list].to_numpy()\n","        y = DF_target.to_numpy()\n","\n","        #print(f\"Performing feature selection with features: {feature_list}\")\n","\n","        # Custom logic to create splits with a fixed test size of 672\n","        splits = []\n","        start_train_size = total_samples - (n_splits * test_size)  # Calculate where to start training\n","\n","        for split in range(n_splits):\n","            train_end = start_train_size + split * test_size\n","            test_start = train_end\n","            test_end = test_start + test_size\n","\n","            if test_end <= total_samples:  # Ensure the test set is within the bounds\n","                splits.append((list(range(0, train_end)), list(range(test_start, test_end))))\n","\n","        TimeSeriesCVerror = []  # MSE errors for each fold\n","\n","        # Time series cross-validation with fixed test size\n","        for train_index, test_index in splits:\n","            #print(f\"TRAIN: {train_index}, TEST: {test_index}\")\n","            X_train, X_test = X[train_index], X[test_index]\n","            y_train, y_test = y[train_index], y[test_index]\n","\n","            # Train the regressor and predict\n","            regressor.fit(X_train, y_train)\n","            predicted_val = regressor.predict(X_test)\n","\n","            # Calculate the error for this fold\n","            Error = np.sqrt(mean_squared_error(y_test, predicted_val))\n","            TimeSeriesCVerror.append(Error)\n","            #print(f\"This is the error for one TS iteration: {Error}\")\n","\n","        # Calculate the average error across all splits\n","        TS_CV_error = sum(TimeSeriesCVerror) / len(TimeSeriesCVerror)\n","        #print(f\"Cumulative error of the last steps: {TS_CV_error}\")\n","        error_list.append(TS_CV_error)  # Store the error for this set of features\n","\n","        # Check if the error improved\n","        if TS_CV_error < min_error:\n","            min_error = TS_CV_error  # Update the minimum error\n","            no_improvement_count = 0  # Reset the no-improvement count\n","        else:\n","            no_improvement_count += 1  # Increment if there's no improvement\n","\n","        # Break the loop if no improvement is observed after 20 features\n","        if no_improvement_count >= tolerance:\n","            print(f\"No improvement after {tolerance} features. Stopping early.\")\n","            break\n","\n","    # Create a pandas Series to store the error associated with each feature\n","    ErrorSeries = pd.Series(error_list, index=feature_list)\n","\n","    # Plot the errors using a custom plot function\n","    plot_errors(ErrorSeries)\n","\n","    return ErrorSeries"]},{"cell_type":"markdown","metadata":{"id":"jncuxW1sR5BZ"},"source":["# start"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16326,"status":"ok","timestamp":1769012289684,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"i9hNWTTUR4fm","outputId":"fab6a173-5348-44e4-d49e-a94f448c4985"},"outputs":[{"output_type":"stream","name":"stdout","text":["this is the prediction horizon in steps 144\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"Holidays_flag\"] = 0\n","/tmp/ipython-input-2329344273.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"dayOfWeek\"] = input_df.index.dayofweek\n","/tmp/ipython-input-2329344273.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df.loc[input_df[\"dayOfWeek\"] > 4, \"weekendFlag\"] = 1\n","/tmp/ipython-input-2329344273.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"hour\"] = input_df.index.hour\n","/tmp/ipython-input-2329344273.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"WorkingHour_flag\"] = 0\n"]}],"source":["filename=\"NO2_price_10min_2024_2025.xlsx\"\n","#define the path of the folder with the data\n","path=\"/content/gdrive/MyDrive/IEEE-EEM2026/\"\n","#join the folder with the name of the file I want to study\n","\n","df = pd.read_excel(os.path.join(path,filename), parse_dates=[0]).set_index('timestamp')\n","df = df[~df.index.duplicated(keep='first')] # Drop duplicate timestamps before setting frequency\n","df = df.asfreq('10min') # Set the frequency of the index\n","\n","OriginalFeatures=df.columns.to_list()\n","\n","df[\"target\"]=df[\"NO2 price (NOK/kWh)\"]\n","target=\"target\"\n","\n","OutputPath = r\"C:\\Users\\User\\Desktop\\_badenova_forecaster\\outputs\"\n","\n","granularity=\"10min\"\n","prediction_horizon=\"1440min\"\n","\n","number_part_hor = ''.join(filter(str.isdigit, prediction_horizon))\n","PredictionHorizon=int(number_part_hor)\n","number_part = ''.join(filter(str.isdigit, granularity))\n","Minutedensity=int(number_part)\n","fourier_terms_list=[2,2,2,2]\n","prediction_horizon_steps=PredictionHorizon//Minutedensity # this is 96\n","print(\"this is the prediction horizon in steps\", prediction_horizon_steps)\n","# lets make some features\n","lagStart = prediction_horizon_steps          # Start lagging from 1 step\n","lagInterval = 1       # Interval of 1 step\n","lagEnd = prediction_horizon_steps *2\n","\n","for feature in OriginalFeatures:\n","    df = laggedColumnCreator(df, feature, lagStart, lagInterval, lagEnd)\n","#lets build the target and the features\n","df=HolidayFeatureCreator(df)\n","df=CreateWorkHourFeature(df)\n","df=TimeRelatedFeatureConstructor(df)\n","df=FourierFeatureConstructor(df,granularity,fourier_terms_list)\n","\n","df=df.drop(columns=OriginalFeatures)\n","\n","df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":146,"status":"ok","timestamp":1769012289835,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"IZ-YxhBlV0ub"},"outputs":[],"source":["#test_date=\"2025-06-01 00:00:00\" #summer\n","test_date=\"2025-02-01 00:00:00\" #winter\n","\n","\n","# Example\n","splits = make_splits(test_date, freq=\"10min\", val_days=14, train_steps=5000)\n","\n","train_start=splits[\"train_start\"]\n","train_end=splits[\"train_end\"]\n","validation_start=splits[\"validation_start\"]\n","validation_end=splits[\"validation_end\"]\n","test_start=splits[\"test_start\"]\n","test_end =splits[\"test_end\"]\n","\n","#lets split them\n","DF_training = df[train_start:train_end]  # Include up to train_end_date\n","DF_validation = df[validation_start:validation_end]  # Start after train_end_date\n","DF_test = df[test_start:test_end]  # Start after validation_end_date\n","\n","\n","DF_training_and_DF_validation=pd.concat([DF_training,DF_validation])\n","Selected_Features=DF_training_and_DF_validation.drop([target],axis=1) # df, all features except target in a dataframe for the first period\n","DF_target=DF_training_and_DF_validation[target] #one column df of the target for the next period\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55906,"status":"ok","timestamp":1769012345778,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"15e45e85","outputId":"4e75c910-c84a-4b3d-bab2-0a42bd008c92"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE scores for each fold: [np.float64(0.1962185626478349), np.float64(0.5340214581008883), np.float64(0.6597155659544419), np.float64(1.5852812759142878), np.float64(0.659322533971524)]\n","Average RMSE across all folds: 0.7269118793177953\n"]}],"source":["from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","from sklearn.neural_network import MLPRegressor\n","\n","# Define features (X) and target (y)\n","X = Selected_Features\n","y = DF_target\n","\n","# Initialize MLPRegressor\n","model = MLPRegressor()\n","\n","# Initialize TimeSeriesSplit\n","# n_splits determines the number of train/test splits to generate.\n","# Each split's training set grows, and its test set is a fixed size (the last part of the data).\n","# For example, if n_splits=5, there will be 5 splits.\n","# The first split might use 20% for train, 20% for test, and the last uses 80% for train, 20% for test.\n","tscv = TimeSeriesSplit(n_splits=5)\n","\n","rmse_scores = []\n","\n","# Perform Time Series Cross-Validation\n","for train_index, test_index in tscv.split(X):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate RMSE and store it\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","    rmse_scores.append(rmse)\n","\n","print(f\"RMSE scores for each fold: {rmse_scores}\")\n","print(f\"Average RMSE across all folds: {np.mean(rmse_scores)}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1769012345997,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"4b40e176","outputId":"a6a8a6b1-59fb-4674-d90a-863c68d9ae94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Optuna objective function 'objective' defined successfully.\n"]}],"source":["import optuna\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","\n","def objective(trial):\n","    # Suggest hyperparameters for MLPRegressor\n","    param = {\n","        'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic']),\n","        'solver': trial.suggest_categorical('solver', ['adam', 'sgd']),\n","        'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","        'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","        'max_iter': trial.suggest_int('max_iter', 200, 1000),\n","        'random_state': 42\n","    }\n","\n","    # Initialize an MLPRegressor model using the suggested hyperparameters\n","    model = MLPRegressor(**param)\n","\n","    # Instantiate TimeSeriesSplit\n","    tscv = TimeSeriesSplit(n_splits=5)\n","\n","    # Initialize an empty list to store RMSE scores for each fold\n","    rmse_scores = []\n","\n","    # Use the globally available X (Selected_Features) and y (DF_target)\n","    X = Selected_Features\n","    y = DF_target\n","\n","    # Loop through the splits generated by TimeSeriesSplit\n","    for train_index, test_index in tscv.split(X):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","        # Train the model\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # Calculate RMSE for each fold and append it to the rmse_scores list\n","        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","        rmse_scores.append(rmse)\n","\n","    # Calculate the mean of the rmse_scores\n","    mean_rmse = np.mean(rmse_scores)\n","\n","    # Return the calculated mean RMSE\n","    return mean_rmse\n","\n","print(\"Optuna objective function 'objective' defined successfully.\")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e5ed72050bfa4a56bae418bb78d64e7e","bc2fde9091344ae5b2342984913d1f47","8576b51843324b6f9724f76cc4bbeeee","34d15a901e21415888f1c96fcbc22510","ff28f01bb7b74c06925ec983da746beb","fc9c4e63892c4a9b959d6d25e24cd187","22db2c2f43674b44a948cb456e26b5fb","de661984c0684cffbef5a399c9fb50c4","4aefb873559a470fb69a65c0e86edb59","5d5e8fdbc2604fcd999c63ee7ae308d1","bdb68cd7850a4a31ad160b135728c163"]},"executionInfo":{"elapsed":3208273,"status":"ok","timestamp":1769015554261,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"c62d71e9","outputId":"25179e82-582d-4b9d-b417-4d10c45f1072"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2026-01-21 16:19:06,590] A new study created in memory with name: no-name-7bcc00da-26a5-4144-a51c-649e2e6ac6e0\n"]},{"output_type":"stream","name":"stdout","text":["Starting Optuna optimization...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5ed72050bfa4a56bae418bb78d64e7e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:20:29,397] Trial 0 finished with value: 0.6718261008240611 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.006796578090758156, 'learning_rate_init': 0.00010994335574766199, 'max_iter': 976}. Best is trial 0 with value: 0.6718261008240611.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (493) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:21:58,076] Trial 1 finished with value: 0.6580303279356422 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 3.613894271216525e-05, 'learning_rate_init': 0.0003839629299804173, 'max_iter': 493}. Best is trial 1 with value: 0.6580303279356422.\n","[I 2026-01-21 16:22:26,533] Trial 2 finished with value: 0.6698302989877492 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.06245139574743072, 'learning_rate_init': 0.00853618986286683, 'max_iter': 847}. Best is trial 1 with value: 0.6580303279356422.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:23:17,411] Trial 3 finished with value: 0.6572360008931348 and parameters: {'hidden_layer_sizes': (50, 50), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.004467752817973905, 'learning_rate_init': 0.0004201672054372534, 'max_iter': 616}. Best is trial 3 with value: 0.6572360008931348.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:24:16,657] Trial 4 finished with value: 0.6694447970847659 and parameters: {'hidden_layer_sizes': (50, 50), 'activation': 'relu', 'solver': 'adam', 'alpha': 6.080390190296599e-05, 'learning_rate_init': 0.00012315571723666037, 'max_iter': 460}. Best is trial 3 with value: 0.6572360008931348.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:25:12,609] Trial 5 finished with value: 0.6348635656882993 and parameters: {'hidden_layer_sizes': (50, 50), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.08862326508576249, 'learning_rate_init': 0.0035033984911586884, 'max_iter': 359}. Best is trial 5 with value: 0.6348635656882993.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:26:04,227] Trial 6 finished with value: 0.626030566884313 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0031130959561221226, 'learning_rate_init': 0.0004589824181495653, 'max_iter': 250}. Best is trial 6 with value: 0.626030566884313.\n","[I 2026-01-21 16:26:51,380] Trial 7 finished with value: 0.674582119561124 and parameters: {'hidden_layer_sizes': (50, 50), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0017583640270008513, 'learning_rate_init': 0.003482846706526885, 'max_iter': 595}. Best is trial 6 with value: 0.626030566884313.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:28:41,105] Trial 8 finished with value: 0.6790198898475911 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 9.935023909063687e-05, 'learning_rate_init': 0.000661859559718348, 'max_iter': 805}. Best is trial 6 with value: 0.626030566884313.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:28:59,459] Trial 9 finished with value: 0.653540275310131 and parameters: {'hidden_layer_sizes': (50, 50), 'activation': 'relu', 'solver': 'adam', 'alpha': 5.575453980775367e-05, 'learning_rate_init': 0.006097025297491433, 'max_iter': 632}. Best is trial 6 with value: 0.626030566884313.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:29:16,503] Trial 10 finished with value: 0.6536170170519346 and parameters: {'hidden_layer_sizes': (100, 50, 25), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0003828746556909452, 'learning_rate_init': 0.0013527769084615443, 'max_iter': 231}. Best is trial 6 with value: 0.626030566884313.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (208) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (208) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:30:26,323] Trial 11 finished with value: 0.6524804000938741 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0922676522914623, 'learning_rate_init': 0.0018521240633905289, 'max_iter': 208}. Best is trial 6 with value: 0.626030566884313.\n","[I 2026-01-21 16:31:06,921] Trial 12 finished with value: 0.6179570793321854 and parameters: {'hidden_layer_sizes': (100, 50, 25), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.01923349162835074, 'learning_rate_init': 0.002489492117914173, 'max_iter': 339}. Best is trial 12 with value: 0.6179570793321854.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (379) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:32:59,509] Trial 13 finished with value: 0.6534257248940967 and parameters: {'hidden_layer_sizes': (100, 50, 25), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.014566096837677395, 'learning_rate_init': 0.00025197003914717017, 'max_iter': 379}. Best is trial 12 with value: 0.6179570793321854.\n","[I 2026-01-21 16:33:30,671] Trial 14 finished with value: 0.6513139615893241 and parameters: {'hidden_layer_sizes': (100, 50, 25), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.0005923680697586678, 'learning_rate_init': 0.0008019201463150692, 'max_iter': 324}. Best is trial 12 with value: 0.6179570793321854.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:34:41,990] Trial 15 finished with value: 0.649588126830839 and parameters: {'hidden_layer_sizes': (100, 50, 25), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0188803361855522, 'learning_rate_init': 0.002379353796059856, 'max_iter': 289}. Best is trial 12 with value: 0.6179570793321854.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:35:20,262] Trial 16 finished with value: 0.5945820208113703 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0019849608206120857, 'learning_rate_init': 0.0010253591871612492, 'max_iter': 458}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:36:35,795] Trial 17 finished with value: 0.6469941537511422 and parameters: {'hidden_layer_sizes': (100, 50, 25), 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.01852051978996418, 'learning_rate_init': 0.0010840942739958749, 'max_iter': 474}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (547) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:38:31,681] Trial 18 finished with value: 0.6801395255817904 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0001850183402327211, 'learning_rate_init': 0.003937410179353935, 'max_iter': 547}. Best is trial 16 with value: 0.5945820208113703.\n","[I 2026-01-21 16:39:02,902] Trial 19 finished with value: 0.6781279474661503 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'logistic', 'solver': 'adam', 'alpha': 1.604195280519389e-05, 'learning_rate_init': 0.0018140837457893864, 'max_iter': 715}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (402) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:40:08,994] Trial 20 finished with value: 0.6429679480283537 and parameters: {'hidden_layer_sizes': (100, 50, 25), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.001642180074828899, 'learning_rate_init': 0.005511324751284091, 'max_iter': 402}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (299) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (299) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:41:12,040] Trial 21 finished with value: 0.635059700133608 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.003916848831910836, 'learning_rate_init': 0.0005447151057319282, 'max_iter': 299}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (420) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:42:24,070] Trial 22 finished with value: 0.6215064784510795 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0022876446926764524, 'learning_rate_init': 0.00023045254190652806, 'max_iter': 420}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (427) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:43:36,397] Trial 23 finished with value: 0.6215433922706831 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0009349236060392305, 'learning_rate_init': 0.00021619285907183565, 'max_iter': 427}. Best is trial 16 with value: 0.5945820208113703.\n","[I 2026-01-21 16:44:13,497] Trial 24 finished with value: 0.5957037704120846 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.011855174303369253, 'learning_rate_init': 0.0008970112080918536, 'max_iter': 526}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:45:00,468] Trial 25 finished with value: 0.5949030702754875 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.008131095290595355, 'learning_rate_init': 0.001083191218314782, 'max_iter': 527}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:45:47,216] Trial 26 finished with value: 0.5948828285626112 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.011162332074120637, 'learning_rate_init': 0.0010876307775528088, 'max_iter': 678}. Best is trial 16 with value: 0.5945820208113703.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (705) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:47:15,730] Trial 27 finished with value: 0.5945511433075061 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.03641446229145665, 'learning_rate_init': 0.0012359004974597477, 'max_iter': 705}. Best is trial 27 with value: 0.5945511433075061.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (691) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:48:44,985] Trial 28 finished with value: 0.5962801046228642 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.046703388724034234, 'learning_rate_init': 0.0012987986185487947, 'max_iter': 691}. Best is trial 27 with value: 0.5945511433075061.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (924) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:50:36,782] Trial 29 finished with value: 0.6189643909619058 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.038822165281899544, 'learning_rate_init': 0.0015801692663451926, 'max_iter': 924}. Best is trial 27 with value: 0.5945511433075061.\n","[I 2026-01-21 16:51:17,613] Trial 30 finished with value: 0.5966317287137499 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.006247045103007048, 'learning_rate_init': 0.0008362834679684716, 'max_iter': 747}. Best is trial 27 with value: 0.5945511433075061.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (672) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:52:39,720] Trial 31 finished with value: 0.5922257712575842 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.009060434279358393, 'learning_rate_init': 0.0011272831604031703, 'max_iter': 672}. Best is trial 31 with value: 0.5922257712575842.\n","[I 2026-01-21 16:53:19,863] Trial 32 finished with value: 0.5994076499982521 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.028840821060025085, 'learning_rate_init': 0.0006559019301373896, 'max_iter': 671}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (785) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:55:29,005] Trial 33 finished with value: 0.6625046462608264 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.007567888410467813, 'learning_rate_init': 0.002229100708999377, 'max_iter': 785}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (884) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:56:42,594] Trial 34 finished with value: 0.6044844209121323 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.03064958465181089, 'learning_rate_init': 0.0013114985871182428, 'max_iter': 884}. Best is trial 31 with value: 0.5922257712575842.\n","[I 2026-01-21 16:57:14,732] Trial 35 finished with value: 0.6145080099916163 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.01074028627073775, 'learning_rate_init': 0.00029569022683342534, 'max_iter': 600}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:57:48,542] Trial 36 finished with value: 0.6004538662173441 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0054674641275553795, 'learning_rate_init': 0.0006283117405672953, 'max_iter': 744}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:58:20,802] Trial 37 finished with value: 0.6086387513588931 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.003194577852548857, 'learning_rate_init': 0.00039243656363575056, 'max_iter': 664}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 16:59:05,448] Trial 38 finished with value: 0.5946691277523387 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.05511040219250386, 'learning_rate_init': 0.0010457213240616212, 'max_iter': 814}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:00:06,168] Trial 39 finished with value: 0.6495119318006005 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.06688691656664211, 'learning_rate_init': 0.00010488101410479353, 'max_iter': 978}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:00:47,015] Trial 40 finished with value: 0.6288830228602179 and parameters: {'hidden_layer_sizes': (50, 50), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0009198539807781866, 'learning_rate_init': 0.0007786194873620919, 'max_iter': 829}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:01:30,893] Trial 41 finished with value: 0.5945548670933777 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.05581017163198682, 'learning_rate_init': 0.0010621497973768426, 'max_iter': 778}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (769) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:03:08,563] Trial 42 finished with value: 0.6099128855851573 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.053405067121138156, 'learning_rate_init': 0.001575058332993001, 'max_iter': 769}. Best is trial 31 with value: 0.5922257712575842.\n","[I 2026-01-21 17:03:45,839] Trial 43 finished with value: 0.6043264761123905 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.029613977691043843, 'learning_rate_init': 0.0005015339400704675, 'max_iter': 854}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:05:32,736] Trial 44 finished with value: 0.6673101925582057 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.09217573497053493, 'learning_rate_init': 0.003004813185454531, 'max_iter': 932}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (574) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:07:09,226] Trial 45 finished with value: 0.6204963732772976 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.06617814884365573, 'learning_rate_init': 0.0019415213484667699, 'max_iter': 574}. Best is trial 31 with value: 0.5922257712575842.\n","[I 2026-01-21 17:08:01,343] Trial 46 finished with value: 0.6533164494321733 and parameters: {'hidden_layer_sizes': (50, 50), 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.025401668926471832, 'learning_rate_init': 0.0009601491280273865, 'max_iter': 819}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (634) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:09:22,700] Trial 47 finished with value: 0.5973759702015501 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.04528092563800132, 'learning_rate_init': 0.0014580768310414134, 'max_iter': 634}. Best is trial 31 with value: 0.5922257712575842.\n","[I 2026-01-21 17:11:33,189] Trial 48 finished with value: 0.659542429115605 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.017733322120852713, 'learning_rate_init': 0.001161978142048667, 'max_iter': 736}. Best is trial 31 with value: 0.5922257712575842.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:8: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n","  'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50, 25)]),\n","/tmp/ipython-input-1562137406.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n","/tmp/ipython-input-1562137406.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 17:12:01,692] Trial 49 finished with value: 0.6010393041588594 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.00033152872801247153, 'learning_rate_init': 0.0007134810751974056, 'max_iter': 865}. Best is trial 31 with value: 0.5922257712575842.\n","Optuna optimization finished.\n","\n","Best trial:\n","  Value (Mean RMSE): 0.5922\n","  Params:\n","    hidden_layer_sizes: (100,)\n","    activation: logistic\n","    solver: sgd\n","    alpha: 0.009060434279358393\n","    learning_rate_init: 0.0011272831604031703\n","    max_iter: 672\n","\n","Training final MLPRegressor model with best parameters...\n","{'Pipelines': 'MLPRegressor', 'RMSE': np.float64(0.6649437744510682), 'MAE': 0.4963249069701441, 'MSE': 0.4421502231812331}\n"]}],"source":["import joblib\n","import optuna\n","\n","# 1. Create an Optuna study\n","# Using a TPE sampler with a seed for reproducibility\n","sampler = optuna.samplers.TPESampler(seed=42)\n","study = optuna.create_study(direction='minimize', sampler=sampler)\n","\n","# 2. Run the optimization process\n","# You can adjust n_trials based on computational resources and desired exploration\n","print(\"Starting Optuna optimization...\")\n","study.optimize(objective, n_trials=50, show_progress_bar=True)\n","print(\"Optuna optimization finished.\")\n","\n","# 3. Print the best trial's value and parameters\n","print(\"\\nBest trial:\")\n","trial = study.best_trial\n","print(f\"  Value (Mean RMSE): {trial.value:.4f}\")\n","print(\"  Params:\")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")\n","\n","# 4. Retrieve the best hyperparameters from the Optuna study\n","best_params = study.best_params\n","\n","# 5. Train a final XGBRegressor model with the best parameters\n","print(\"\\nTraining final MLPRegressor model with best parameters...\")\n","final_model = MLPRegressor(**best_params, random_state=42)\n","\n","\n","X_train=DF_training_and_DF_validation.drop([target],axis=1) # df, all features except target in a dataframe for the first period\n","X_test=DF_test.drop([target],axis=1) #df , all feature except target (same as before but for the next available period period)\n","y_train=DF_training_and_DF_validation[target] #one column df, of the target for the first period\n","y_test=DF_test[target] #one column df of the target for the next period\n","\n","\n","final_model.fit(X_train , y_train)\n","\n","predicted_val = final_model.predict(X_test)\n","\n","name=\"MLPRegressor\"\n","d=ErrorCalculator(name,y_test,predicted_val)\n","print(d)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":690,"status":"ok","timestamp":1769015554959,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"00BVmpFpcar0","outputId":"c2091acc-89d7-4005-e764-37b63764609d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='timestamp'>"]},"metadata":{},"execution_count":25},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["predicted_DF = pd.DataFrame(predicted_val , index=DF_test.index, columns=[\"MLPRegressor\"])\n","\n","predicted_DF = predicted_DF.join(y_test)\n","\n","predicted_DF=predicted_DF.loc[DF_test.index]\n","\n","predicted_DF.columns = [\"MLPRegressor\", \"target\"]\n","\n","\n","predicted_DF[:300].plot()"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1769015554961,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"},"user_tz":-60},"id":"pihCwffEc-2b"},"outputs":[],"source":["# Ensure it's a Timestamp / datetime\n","test_date_ts = pd.to_datetime(test_date)\n","\n","# Format without forbidden chars (:, etc.)\n","test_date_str = test_date_ts.strftime(\"%Y-%m-%d_%H-%M-%S\")  # e.g. 2025-09-19_00-00-00\n","\n","test_ts = f\"{test_date_str}_MLPRegressor.csv\"\n","test_filepath = os.path.join(path, test_ts)\n","\n","predicted_DF[\"MLPRegressor\"].to_csv(test_filepath, index=True)"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyOQTFnUjmh9mvgGbDOmsAhm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e5ed72050bfa4a56bae418bb78d64e7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc2fde9091344ae5b2342984913d1f47","IPY_MODEL_8576b51843324b6f9724f76cc4bbeeee","IPY_MODEL_34d15a901e21415888f1c96fcbc22510"],"layout":"IPY_MODEL_ff28f01bb7b74c06925ec983da746beb"}},"bc2fde9091344ae5b2342984913d1f47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc9c4e63892c4a9b959d6d25e24cd187","placeholder":"â€‹","style":"IPY_MODEL_22db2c2f43674b44a948cb456e26b5fb","value":"Bestâ€‡trial:â€‡31.â€‡Bestâ€‡value:â€‡0.592226:â€‡100%"}},"8576b51843324b6f9724f76cc4bbeeee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de661984c0684cffbef5a399c9fb50c4","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4aefb873559a470fb69a65c0e86edb59","value":50}},"34d15a901e21415888f1c96fcbc22510":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d5e8fdbc2604fcd999c63ee7ae308d1","placeholder":"â€‹","style":"IPY_MODEL_bdb68cd7850a4a31ad160b135728c163","value":"â€‡50/50â€‡[52:55&lt;00:00,â€‡72.06s/it]"}},"ff28f01bb7b74c06925ec983da746beb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc9c4e63892c4a9b959d6d25e24cd187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22db2c2f43674b44a948cb456e26b5fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de661984c0684cffbef5a399c9fb50c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aefb873559a470fb69a65c0e86edb59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d5e8fdbc2604fcd999c63ee7ae308d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdb68cd7850a4a31ad160b135728c163":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}