{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNhuylUzW7Pij6JMrIr3Z8/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Yk55RhvJw8G","executionInfo":{"status":"ok","timestamp":1768994768291,"user_tz":-60,"elapsed":1235,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"ae085136-841f-4ee1-ee51-dbf0fb1e42a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOjXGVk9VjH8","executionInfo":{"status":"ok","timestamp":1768994782071,"user_tz":-60,"elapsed":13775,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"ab36fd6c-44ee-42b5-af1b-89124db922e8"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.7.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"]}]},{"cell_type":"code","source":["pip install feature-engine"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MYh81eBXKDOP","executionInfo":{"status":"ok","timestamp":1768994794972,"user_tz":-60,"elapsed":12897,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"57814706-e17d-4434-f895-b87e294d1e2c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: feature-engine in /usr/local/lib/python3.12/dist-packages (1.9.3)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (2.0.2)\n","Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (2.2.2)\n","Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (1.6.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (1.16.3)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (0.14.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2025.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->feature-engine) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->feature-engine) (3.6.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.11.1->feature-engine) (1.0.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.11.1->feature-engine) (25.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->feature-engine) (1.17.0)\n"]}]},{"cell_type":"code","source":["pip install sktime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpFSgeWnKJVP","executionInfo":{"status":"ok","timestamp":1768994807036,"user_tz":-60,"elapsed":12066,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"fe701d13-f9ed-4ed5-dae7-dc6e21b49bec"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sktime in /usr/local/lib/python3.12/dist-packages (0.40.1)\n","Requirement already satisfied: joblib<1.6,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.5.3)\n","Requirement already satisfied: numpy<2.4,>=1.21 in /usr/local/lib/python3.12/dist-packages (from sktime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from sktime) (25.0)\n","Requirement already satisfied: pandas<2.4.0,>=1.1 in /usr/local/lib/python3.12/dist-packages (from sktime) (2.2.2)\n","Requirement already satisfied: scikit-base<0.14.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from sktime) (0.13.0)\n","Requirement already satisfied: scikit-learn<1.8.0,>=0.24 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.6.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.16.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2025.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=0.24->sktime) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=1.1->sktime) (1.17.0)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","#import cmaes\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import logging\n","logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from feature_engine.datetime import DatetimeFeatures\n","from feature_engine.creation import CyclicalFeatures\n","from feature_engine.timeseries.forecasting import ExpandingWindowFeatures,LagFeatures\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","from sktime.transformations.series.fourier import FourierFeatures\n","from feature_engine.timeseries.forecasting import WindowFeatures\n","import holidays\n","from sklearn.ensemble import RandomForestRegressor\n"],"metadata":{"id":"Y1lHHjOIJ3fY","executionInfo":{"status":"ok","timestamp":1768994807065,"user_tz":-60,"elapsed":26,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def sliding_window_forecast_fixed_size(modelname, fcst, DF_training_scaled, DF_validation_scaled, scaler_target,\n","                                       prediction_horizon_steps=96, fixed_training_size=8832):\n","    \"\"\"\n","    Perform a sliding window forecast with a fixed-size training set.\n","\n","    Parameters:\n","    fcst (MLForecast): The forecast model.\n","    DF_training_scaled (pd.DataFrame): Scaled initial training data.\n","    DF_validation_scaled (pd.DataFrame): Scaled validation data for future predictions.\n","    scaler_target (MinMaxScaler): Scaler used to inverse transform the target variable.\n","    prediction_horizon_steps (int): Number of steps ahead to predict (default: 96).\n","    fixed_training_size (int): Fixed size of the rolling training window.\n","\n","    Returns:\n","    pd.DataFrame: A DataFrame containing the day-ahead predictions for each step.\n","    \"\"\"\n","    # Create an empty DataFrame to store all predictions\n","    all_preds = pd.DataFrame()\n","\n","    # Sliding window loop: run as long as there are enough validation points left\n","    num_iterations = len(DF_validation_scaled) // prediction_horizon_steps\n","\n","    for i in range(num_iterations):\n","        # Step 1: Fit the model on the current training data (empty static features)\n","        fcst.fit(DF_training_scaled, static_features=[])\n","\n","        # Step 2: Predict the next 'prediction_horizon_steps' (e.g., 96 steps)\n","        # Ensure only the next prediction_horizon_steps rows are passed to X_df\n","        X_df = DF_validation_scaled.drop(columns=[\"y\"], axis=1).iloc[:prediction_horizon_steps]\n","        preds = fcst.predict(h=prediction_horizon_steps, X_df=X_df)\n","\n","        # Step 3: Reshape and inverse transform the predictions to original scale\n","        predictions_reshaped = preds[modelname].to_numpy().reshape(-1, 1)\n","        predictions_original_scale = scaler_target.inverse_transform(predictions_reshaped).flatten()\n","\n","        # Step 4: Assign the predictions to the original DataFrame (store the time index 'ds' and unscaled predictions)\n","        preds[modelname+\"_unscaled\"] = predictions_original_scale\n","\n","        # Step 5: Append predictions to the results DataFrame\n","        all_preds = pd.concat([all_preds, preds], axis=0)\n","\n","        # Step 6: Update the training data by appending new validation data\n","        new_data = DF_validation_scaled.iloc[:prediction_horizon_steps]\n","\n","        # Remove the newly added data from DF_validation_scaled after each iteration\n","        DF_validation_scaled = DF_validation_scaled.iloc[prediction_horizon_steps:]\n","\n","        # Step 7: Maintain a fixed training size by appending new data and dropping the oldest data\n","        DF_training_scaled = pd.concat([DF_training_scaled, new_data], axis=0)\n","        if len(DF_training_scaled) > fixed_training_size:\n","            DF_training_scaled = DF_training_scaled.iloc[-fixed_training_size:]  # Keep only the latest entries\n","\n","    return all_preds\n","\n","def plot_predictions(model_name, df_validation_y, all_preds_unscaled):\n","    plt.figure(figsize=(14, 7))\n","\n","    # Plot actual values\n","    plt.plot(df_validation_y.index, df_validation_y.values, label='Actual Values', color='blue', linewidth=2)\n","\n","    # Plot predicted values\n","    plt.plot(all_preds_unscaled.index, all_preds_unscaled.values, label=f'Predicted Values ({model_name})', color='red', linestyle='-', linewidth=2)\n","\n","    # Add labels and title\n","    plt.xlabel('Time')\n","    plt.ylabel('Net Load')\n","    plt.title(f'Actual vs Predicted Values ({model_name})')\n","\n","    # Add legend\n","    plt.legend()\n","\n","    # Rotate x-ticks for better readability\n","    plt.xticks(rotation=45)\n","\n","    # Show the plot\n","    plt.tight_layout()\n","    plt.show()\n","\n","def CreateWorkHourFeature(input_data):\n","    \"\"\"\n","    Receives as input a DataFrame or Series and outputs a DataFrame with the working hours during the day.\n","    When the day of the week is larger than 4, it is considered a weekend (1), otherwise, it's a workday (0).\n","    During workdays and between 8:00 and 17:00, it is considered a working hour.\n","\n","    Parameters:\n","    input_data (DataFrame or Series): Input data with a DatetimeIndex.\n","\n","    Returns:\n","    DataFrame: DataFrame with the added \"WorkingHour_flag\" column.\n","    \"\"\"\n","    if isinstance(input_data, pd.Series):\n","        input_df = pd.DataFrame(input_data)\n","    elif isinstance(input_data, pd.DataFrame):\n","        input_df = input_data\n","    else:\n","        raise ValueError(\"Input must be a DataFrame or Series.\")\n","\n","    assert isinstance(input_df.index, pd.DatetimeIndex), \"Index must be a datetime index.\"\n","\n","    input_df[\"dayOfWeek\"] = input_df.index.dayofweek\n","    input_df.loc[input_df[\"dayOfWeek\"] > 4, \"weekendFlag\"] = 1\n","    input_df.loc[input_df[\"dayOfWeek\"] < 5, \"weekendFlag\"] = 0\n","    input_df[\"hour\"] = input_df.index.hour\n","    input_df[\"WorkingHour_flag\"] = 0\n","    input_df.loc[((input_df[\"hour\"] > 8) & (input_df[\"hour\"] < 17) & (input_df[\"weekendFlag\"] == 0)), \"WorkingHour_flag\"] = 1\n","    input_df.drop([\"hour\", \"dayOfWeek\", \"weekendFlag\"], axis=1, inplace=True)\n","\n","    return input_df\n","\n","\n","def ListCreatorFlagger(df, substrings=['flag', 'cos', 'sin','day_of_week', 'day_of_month', 'weekend', 'days_in_month', 'hour', 'minute']):\n","    \"\"\"\n","    A function that separates the columns containing specified substrings from those that don't.\n","    df is the dataframe in question and the substring is a list.\n","    \"\"\"\n","    flag_columns = [col for col in df.columns if any(substring in col for substring in substrings)]\n","\n","    if not flag_columns:\n","        print(\"No columns with the specified substrings found.\")\n","        return None, None\n","\n","    non_flag_columns = [col for col in df.columns if col not in flag_columns]\n","\n","    return non_flag_columns, flag_columns\n","\n","\n","def HolidayFeatureCreator(input_data):\n","    \"\"\"\n","    Receives as input a DataFrame or Series and creates a column named \"Holidays_flag\" with 1 if there is a holiday and with 0 if no holidays exist.\n","    Holidays derived from Germany.\n","    \"\"\"\n","    if isinstance(input_data, pd.Series):\n","        input_df = pd.DataFrame(input_data)\n","    elif isinstance(input_data, pd.DataFrame):\n","        input_df = input_data\n","    else:\n","        raise ValueError(\"Input must be a DataFrame or Series.\")\n","\n","    assert isinstance(input_df.index, pd.DatetimeIndex), \"Index must be a datetime index.\"\n","\n","    national_holidays_all = holidays.DE(years=[2014,2015,2016,2017,2018,2019,2020, 2021, 2022, 2023, 2024, 2025, 2026]).items()\n","    national_holidays = [items[0] for items in national_holidays_all]  # this is a list\n","\n","    # Create a new column for holidays flag\n","    input_df[\"Holidays_flag\"] = 0\n","\n","    # Iterate over the index and set holiday flag to 1 if the date matches any national holiday\n","    for index_date in input_df.index:\n","        if index_date.date() in national_holidays:\n","            input_df.at[index_date, \"Holidays_flag\"] = 1\n","\n","    return input_df\n","\n","\n","\n","\n","def TimeRelatedFeatureConstructor(df):\n","  \"\"\"\n","  Works only in a dataframe as input: run the other functions first.\n","  Extracts time-related features\n","  \"\"\"\n","  TimeFeaturesToExtract=[\"day_of_week\",\"weekend\",\"hour\",] #consider to add more\n","  dtfs=DatetimeFeatures(variables=\"index\", features_to_extract=TimeFeaturesToExtract, drop_original=False)\n","  df=dtfs.fit_transform(df)\n","\n","  CyclicalFeaturesToExtract=[\"day_of_week\",\"hour\",]\n","  cyclical_dtfs=CyclicalFeatures(variables=CyclicalFeaturesToExtract,drop_original=False)\n","  df=cyclical_dtfs.fit_transform(df)\n","  return df\n","\n","\n","def FourierFeatureConstructor(df, granularity, fourier_terms_list):\n","    # Extract numerical part of granularity\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    number_int = int(number_part) if number_part else 1  # Fallback to 1 to avoid division by zero\n","\n","    # Calculate minutes per hour, ensuring no division by zero\n","    minutes4hour = 60 / number_int if number_int != 0 else 60\n","\n","    # Define seasonal periods (sp_list) for Fourier transformation\n","    sp_list = [\n","        max(minutes4hour, 4),                 # Hourly - for 15min, this should be 4\n","        max(24 * minutes4hour, 96),           # Daily - for 15min, this should be 96\n","        max(24 * 7 * minutes4hour, 672),      # Weekly - for 15min, this should be 672\n","        max(24 * 30 * minutes4hour, 2880)     # Monthly - for 15min, this should be 2880\n","    ]\n","\n","    # Fourier transformer setup\n","    Fourier_Transformer = FourierFeatures(\n","        sp_list=sp_list,\n","        fourier_terms_list=fourier_terms_list,\n","        freq=granularity,\n","        keep_original_columns=True\n","    )\n","\n","    # Apply Fourier transformation\n","    Fourier_Transformer.fit(df)\n","    df = Fourier_Transformer.transform(df)\n","    return df\n","\n","\n","\n","def WindowFeaturesConstructor(df, granularity, ListWithNoFlags):\n","    \"\"\"\n","    This is a function that makes a list of 4 window features starting from double the granularity and following by doubling the previous value\n","    \"\"\"\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    number_int = int(number_part)\n","    double_granularity = 2 * number_int\n","    time_intervals = [double_granularity]\n","\n","    # Calculate subsequent values\n","    for i in range(3):\n","        time_intervals.append(time_intervals[-1] * 2)\n","\n","    windowlist = [interval // number_int for interval in time_intervals]  # Corrected division\n","    functionsList = [\"mean\", \"std\"]\n","    WindownFeatureTransformer = WindowFeatures(variables=ListWithNoFlags,\n","                                               functions=functionsList,\n","                                               window=windowlist,\n","                                               freq=granularity,\n","                                               drop_original=False)\n","\n","    df = WindownFeatureTransformer.fit_transform(df)\n","    return df\n","\n","def ExpandingWindowFeatureConstructor(df,ListWithNoFlags):\n","  functionsList=[\"mean\",\"std\"]\n","  frequency = pd.infer_freq(df.index) #infer the frequency from the dataframe\n","  ExpandingWindownFeatureTransformer=ExpandingWindowFeatures(variables=ListWithNoFlags,\n","                                                           functions=functionsList,\n","                                                           freq=frequency, #I put the freq to shift it down! but now it is performed automatically!\n","                                                           drop_original=False)\n","  df=ExpandingWindownFeatureTransformer.fit_transform(df)\n","  return df\n","\n","def WeightedLinearFeatureMaker(df,ListWithNoFlags,granularity):\n","  \"\"\"\n","  This is a function that takes the original DF and modifies the continious value columns\n","  Inputs: Dataframe, List of columns that are continous values, daily window to slide, weights of the values\n","  \"\"\"\n","  number_part = ''.join(filter(str.isdigit, granularity))\n","  Minutedensity=int(number_part)\n","  Window=int((60/Minutedensity)*24) #288 means a daily window\n","  weights=np.arange(1,Window+1)\n","\n","  # if i had hourly data then i would have had np.arange(1,24*7) for a weekly window\n","\n","  def weighted_mean (x,weights):\n","    return (weights*x).sum()/weights.sum()\n","\n","  def weighted_std(x,weights):\n","    mean_w= weighted_mean(x, weights)\n","    var_w= (weights* (x-mean_w)**2).sum()/weights.sum()\n","    return np.sqrt(var_w)\n","\n","  # LETS make the weighted mean column\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=Window) #here we pick a window size. Needs to be the same as the len(weights)\n","        .apply(weighted_mean, args=(weights,))\n","        .shift(1)#shift by 1 to avoid data leakage\n","        .to_frame()#convert series to df\n","        )\n","\n","    result.columns=[str(i)+\"_weighted_\"+str(Window)+\"_mean\"]\n","    df=df.join(result)\n","\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=Window) #here we pick a window size. Needs to be the same as the len(weights)\n","        .apply(weighted_std, args=(weights,))\n","        .shift(1)#shift by 1 to avoid data leakage\n","        .to_frame()#convert series to df\n","        )\n","\n","    result.columns=[str(i)+\"_weighted_\"+str(Window)+\"_std\"]\n","    df=df.join(result)\n","  return df\n","\n","def ExpWeightMeanMaker(df,ListWithNoFlags,granularity):\n","  \"\"\"\n","  This is a function that makes exp weighted average with a sliding window approach\n","  \"\"\"\n","  number_part = ''.join(filter(str.isdigit, granularity))\n","  Minutedensity=int(number_part)\n","  Window=int((60/Minutedensity)*24) #288 means a daily window\n","\n","  def exp_weights(alpha,window_size):\n","    \"\"\"\n","    a function to calculate the weights for every single component of our sliding windown\n","    \"\"\"\n","    weights=np.ones(window_size) #initializing weights\n","    for ix in range(window_size):\n","      weights[ix]=(1-alpha)**(window_size-1-ix)\n","    return weights\n","\n","  def exp_weighted_mean(x):\n","    \"\"\"\n","    a functions that calculates the exp weigted mean\n","    \"\"\"\n","\n","    weights=exp_weights(alpha=0.05, window_size=len(x)) # HERE WE SET THE ALPHA\n","    return (weights*x).sum()/weights.sum()\n","\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=int(Window))\n","        .agg([exp_weighted_mean])\n","        .shift(1)\n","    )\n","\n","\n","    result.columns=[str(i)+\"_Exp_weighted_\"+str(Window)+\"_SL.win\"]\n","    df=df.join(result)\n","  return df\n","\n","def WeightedExponentialExpandingWindow(df,ListWithNoFlags,alpha):\n","  \"\"\"\n","  This is a funtion that takes as input the df,a list of continuous values and the alpha.\n","  Outputs: all continuous features on the df that are \"mean\" and \"std\"\n","  \"\"\"\n","\n","  for i in ListWithNoFlags:\n","    df[[str(i)+\"_ewm_mean_expanding.win\",str(i)+\"ewm_std_expanding.win\"]]= (\n","                                              df[i].ewm(alpha=alpha).\n","                                              agg([\"mean\",\"std\"])\n","                                              .shift(1)\n","                                            )\n","  return df\n","\n","def FeatureLagger(df,ListOfFeatures,granularity,PredictionHorizon):\n","\n","    time_intervals = []\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    Minutedensity=int(number_part)\n","    end_in_day=int((PredictionHorizon)/(Minutedensity))\n","    for i in range(1, 1+end_in_day):  # 24 hours * 60 minutes / 15 minutes = 96 intervals\n","        time_intervals.append(f\"{i * 15}min\")\n","\n","    lag_transformer= LagFeatures(variables=ListOfFeatures,\n","                                freq=time_intervals,\n","                                drop_original=False) #make a lagger transformer drop all original features\n","\n","    df=lag_transformer.fit_transform(df) # transform the features to DF joined\n","    return df\n","\n","\n","def ErrorCalculator(name, y_true, y_pred):\n","    errors = {\"Pipelines\": name,\n","              \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n","              \"MAE\": mean_absolute_error(y_true, y_pred),\n","              \"MSE\": mean_squared_error(y_true, y_pred),\n","\n","             }\n","    return errors\n","\n","\n","def separate_future_past_features(df_columns):\n","    \"\"\"\n","    Separates future and past features from a list of dataframe columns.\n","\n","    Args:\n","        df_columns (list): A list of column names from the dataframe.\n","\n","    Returns:\n","        dict: A dictionary with keys 'future_features' and 'past_features', containing the respective lists of column names.\n","    \"\"\"\n","    future_keywords = ['sin', 'cos', 'weekend', 'hour', 'holiday', 'minute', 'day','+']\n","\n","    future_features = []\n","    past_features = []\n","\n","    for col in df_columns:\n","        # Check if the column contains \"+\" in its name to classify as a past feature\n","        if any(keyword in col.lower() for keyword in future_keywords):\n","            future_features.append(col)\n","        # Columns that don't meet the above conditions are considered past features by default\n","        else:\n","            past_features.append(col)\n","\n","    return future_features, past_features\n","\n","\n","def plot_errors (ErrorSeries):\n","  \"\"\"\n","  This is a function that plots the features that are not\n","  \"\"\"\n","  import matplotlib as mpl\n","  import matplotlib.pyplot as plt\n","  import matplotlib.path as mpath\n","  import numpy as np\n","\n","  import matplotlib.pyplot as plt\n","  import numpy as np\n","\n","  x = np.arange(len(ErrorSeries.index))\n","  y = ErrorSeries.values\n","  labels = ErrorSeries.index\n","\n","  plt.figure(1,figsize=(13,5))\n","  plt.style.use(\"seaborn-v0_8-whitegrid\")\n","  plt.plot(x, y)\n","\n","  plt.xticks(x, labels, rotation =40)\n","  plt.ylabel('RMSE [â‚¬/MWh]', wrap=True)\n","  plt.xlabel('Features', wrap=True)\n","\n","\n","  plt.margins(0.05)\n","\n","  plt.subplots_adjust(bottom = 0.05)\n","  plt.show()\n","\n","\n","def select_features_minimum_plus_others(series):\n","    \"\"\"\n","    Takes a pandas Series and selects the features that:\n","    - Include all features up to the minimum error.\n","    - After the minimum error, only include features that reduce the error compared to the previous one.\n","    - Ensures no duplicate features are added.\n","\n","    Parameters:\n","    - series: A pandas Series where index are feature names and values are errors.\n","\n","    Returns:\n","    - A list of selected feature names without duplicates.\n","    \"\"\"\n","    # Find the index of the minimum value\n","    min_idx = series.idxmin()\n","\n","    # Select all features up to and including the minimum\n","    selected_features = list(dict.fromkeys(series[:min_idx].index.tolist() + [min_idx]))\n","\n","    # After the minimum, keep only the features that decrease the error\n","    after_min_series = series[min_idx:]\n","\n","    # Loop through the series after the minimum value and add features that decrease the error\n","    for i in range(1, len(after_min_series)):\n","        if after_min_series[i] < after_min_series[i - 1]:\n","            feature = after_min_series.index[i]\n","            if feature not in selected_features:\n","                selected_features.append(feature)\n","\n","    return selected_features\n","\n","def keep_indices_till_min(series):\n","    \"\"\"\n","    Keeps all index values from the series up to and including the minimum value using a for loop,\n","    while ensuring no duplicates are added.\n","\n","    Parameters:\n","    - series: A pandas Series where the index are feature names and the values are errors.\n","\n","    Returns:\n","    - A list of unique index values (features) up to and including the minimum error value.\n","    \"\"\"\n","    # Initialize an empty list to store the selected indices\n","    selected_features = []\n","\n","    # Find the minimum value in the series\n","    min_value = series.min()\n","\n","    # Loop over the series\n","    for idx, value in series.items():\n","        # Add the current index to the selected features only if it's not already present\n","        if idx not in selected_features:\n","            selected_features.append(idx)\n","\n","        # If the current value is the minimum, stop the loop\n","        if value == min_value:\n","            break\n","\n","    return selected_features\n","\n","def laggedColumnCreator(df,columnName,lagStart, lagInterval, lagEnd):\n","  for i in range(lagStart, lagEnd+1, lagInterval):\n","     newColumnName = columnName + \"-\" + str(i) + \"step\" #you gotta put it in string\n","     df[newColumnName] = df[columnName].shift(i)\n","  return df\n","\n","\n","def make_splits(\n","    test_start_str: str,\n","    freq: str = \"15min\",      # your timestep\n","    val_days: int = 14,\n","    train_steps: int = 7000,\n","    test_days: int = 14,       # length of test period\n","):\n","    step = pd.to_timedelta(freq)\n","\n","    # TEST\n","    test_start = pd.Timestamp(test_start_str)\n","    # If you slice df.loc[start:end] (inclusive), use -step to get exactly `test_days` worth of data\n","    test_end = test_start + pd.Timedelta(days=test_days)\n","\n","    # VALIDATION (ends one step before test_start)\n","    validation_end = test_start - step\n","    # `val_days` long, inclusive: end - start = val_days days - step\n","    validation_start = validation_end - pd.Timedelta(days=val_days) + step\n","\n","    # TRAIN (ends one step before validation_start)\n","    train_end = validation_start - step\n","    # exactly `train_steps` steps long: end - start = (train_steps - 1) * step\n","    train_start = validation_start - train_steps * step\n","\n","    return {\n","        \"train_start\": train_start,\n","        \"train_end\": train_end,\n","        \"validation_start\": validation_start,\n","        \"validation_end\": validation_end,\n","        \"test_start\": test_start,\n","        \"test_end\": test_end,\n","    }\n","\n","\n","def FeatureSelection(regressor, DF_features, DF_target, ordered_features_list, test_size=672, tolerance=400):\n","    \"\"\"\n","    This function receives a regressor model, the features that the model was trained with,\n","    and the target that it had to forecast. Starting from the most important feature,\n","    we find the error of the TimeSeries Cross-Validation with a fixed test size.\n","    By adding features, we find the new error of the forecast.\n","\n","    Parameters:\n","    - regressor: The regression model to use for training and prediction.\n","    - DF_features: DataFrame containing the features.\n","    - DF_target: Series containing the target variable.\n","    - ordered_features_list: List of features ordered by importance (e.g., from SHAP analysis).\n","    - test_size: Number of steps to use in the test set (default is 672).\n","    - tolerance: Number of features to add before stopping if no improvement in error (default is 20).\n","\n","    Returns:\n","    - ErrorSeries: A pandas Series with the errors for each step of feature addition.\n","    \"\"\"\n","\n","    feature_list = []  # Empty list of features\n","    error_list = []  # Empty list to store errors for each set of features\n","    total_samples = len(DF_features)  # Total number of samples in the dataset\n","    n_splits = 5  # Number of splits (fixed)\n","    no_improvement_count = 0  # Count features added without improvement\n","    min_error = float('inf')  # Start with a large error to track the minimum error\n","\n","    for i in ordered_features_list:\n","        # Start the loop with the best feature and append the next ones\n","        feature_list.append(i)\n","\n","        X = DF_features[feature_list].to_numpy()\n","        y = DF_target.to_numpy()\n","\n","        #print(f\"Performing feature selection with features: {feature_list}\")\n","\n","        # Custom logic to create splits with a fixed test size of 672\n","        splits = []\n","        start_train_size = total_samples - (n_splits * test_size)  # Calculate where to start training\n","\n","        for split in range(n_splits):\n","            train_end = start_train_size + split * test_size\n","            test_start = train_end\n","            test_end = test_start + test_size\n","\n","            if test_end <= total_samples:  # Ensure the test set is within the bounds\n","                splits.append((list(range(0, train_end)), list(range(test_start, test_end))))\n","\n","        TimeSeriesCVerror = []  # MSE errors for each fold\n","\n","        # Time series cross-validation with fixed test size\n","        for train_index, test_index in splits:\n","            #print(f\"TRAIN: {train_index}, TEST: {test_index}\")\n","            X_train, X_test = X[train_index], X[test_index]\n","            y_train, y_test = y[train_index], y[test_index]\n","\n","            # Train the regressor and predict\n","            regressor.fit(X_train, y_train)\n","            predicted_val = regressor.predict(X_test)\n","\n","            # Calculate the error for this fold\n","            Error = np.sqrt(mean_squared_error(y_test, predicted_val))\n","            TimeSeriesCVerror.append(Error)\n","            #print(f\"This is the error for one TS iteration: {Error}\")\n","\n","        # Calculate the average error across all splits\n","        TS_CV_error = sum(TimeSeriesCVerror) / len(TimeSeriesCVerror)\n","        #print(f\"Cumulative error of the last steps: {TS_CV_error}\")\n","        error_list.append(TS_CV_error)  # Store the error for this set of features\n","\n","        # Check if the error improved\n","        if TS_CV_error < min_error:\n","            min_error = TS_CV_error  # Update the minimum error\n","            no_improvement_count = 0  # Reset the no-improvement count\n","        else:\n","            no_improvement_count += 1  # Increment if there's no improvement\n","\n","        # Break the loop if no improvement is observed after 20 features\n","        if no_improvement_count >= tolerance:\n","            print(f\"No improvement after {tolerance} features. Stopping early.\")\n","            break\n","\n","    # Create a pandas Series to store the error associated with each feature\n","    ErrorSeries = pd.Series(error_list, index=feature_list)\n","\n","    # Plot the errors using a custom plot function\n","    plot_errors(ErrorSeries)\n","\n","    return ErrorSeries"],"metadata":{"id":"dvcVDWpOKRN3","executionInfo":{"status":"ok","timestamp":1768994807284,"user_tz":-60,"elapsed":217,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# start"],"metadata":{"id":"jncuxW1sR5BZ"}},{"cell_type":"code","source":["filename=\"NO2_price_10min_2024_2025.xlsx\"\n","#define the path of the folder with the data\n","path=\"/content/gdrive/MyDrive/IEEE-EEM2026/\"\n","#join the folder with the name of the file I want to study\n","\n","df = pd.read_excel(os.path.join(path,filename), parse_dates=[0]).set_index('timestamp')\n","df = df[~df.index.duplicated(keep='first')] # Drop duplicate timestamps before setting frequency\n","df = df.asfreq('10min') # Set the frequency of the index\n","\n","OriginalFeatures=df.columns.to_list()\n","\n","df[\"target\"]=df[\"NO2 price (NOK/kWh)\"]\n","target=\"target\"\n","\n","OutputPath = r\"C:\\Users\\User\\Desktop\\_badenova_forecaster\\outputs\"\n","\n","granularity=\"10min\"\n","prediction_horizon=\"1440min\"\n","\n","number_part_hor = ''.join(filter(str.isdigit, prediction_horizon))\n","PredictionHorizon=int(number_part_hor)\n","number_part = ''.join(filter(str.isdigit, granularity))\n","Minutedensity=int(number_part)\n","fourier_terms_list=[2,2,2,2]\n","prediction_horizon_steps=PredictionHorizon//Minutedensity # this is 96\n","print(\"this is the prediction horizon in steps\", prediction_horizon_steps)\n","# lets make some features\n","lagStart = prediction_horizon_steps          # Start lagging from 1 step\n","lagInterval = 1       # Interval of 1 step\n","lagEnd = prediction_horizon_steps *2\n","\n","for feature in OriginalFeatures:\n","    df = laggedColumnCreator(df, feature, lagStart, lagInterval, lagEnd)\n","#lets build the target and the features\n","df=HolidayFeatureCreator(df)\n","df=CreateWorkHourFeature(df)\n","df=TimeRelatedFeatureConstructor(df)\n","df=FourierFeatureConstructor(df,granularity,fourier_terms_list)\n","\n","df=df.drop(columns=OriginalFeatures)\n","\n","df.dropna(inplace=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjkvTEnRlzBu","executionInfo":{"status":"ok","timestamp":1768994823085,"user_tz":-60,"elapsed":15798,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"bbbc4c97-613e-4805-bc43-19c3ed9d05c2"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["this is the prediction horizon in steps 144\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"Holidays_flag\"] = 0\n","/tmp/ipython-input-2329344273.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"dayOfWeek\"] = input_df.index.dayofweek\n","/tmp/ipython-input-2329344273.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df.loc[input_df[\"dayOfWeek\"] > 4, \"weekendFlag\"] = 1\n","/tmp/ipython-input-2329344273.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"hour\"] = input_df.index.hour\n","/tmp/ipython-input-2329344273.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"WorkingHour_flag\"] = 0\n"]}]},{"cell_type":"code","source":["\"\"\"filename=\"Meter integration_steps1_5_CLEANED without STL for energy.xlsx\"\n","#define the path of the folder with the data\n","path=\"/content/gdrive/MyDrive/IEEE-EEM2026/\"\n","#join the folder with the name of the file I want to study\n","\n","df = pd.read_excel(os.path.join(path,filename), parse_dates=[0]).set_index('Timestamp')\n","\n","\n","OriginalFeatures=df.columns.to_list()\n","\n","df[\"target\"]=df[\"Energy_Meter\"]\n","target=\"target\"\n","\n","OutputPath = r\"C:\\Users\\User\\Desktop\\_badenova_forecaster\\outputs\"\n","\n","granularity=\"10min\"\n","prediction_horizon=\"1440min\"\n","\n","number_part_hor = ''.join(filter(str.isdigit, prediction_horizon))\n","PredictionHorizon=int(number_part_hor)\n","number_part = ''.join(filter(str.isdigit, granularity))\n","Minutedensity=int(number_part)\n","fourier_terms_list=[2,2,2,2]\n","prediction_horizon_steps=PredictionHorizon//Minutedensity # this is 96\n","print(\"this is the prediction horizon in steps\", prediction_horizon_steps)\n","# lets make some features\n","lagStart = prediction_horizon_steps          # Start lagging from 1 step\n","lagInterval = 1       # Interval of 1 step\n","lagEnd = prediction_horizon_steps *2\n","\n","for feature in OriginalFeatures:\n","    df = laggedColumnCreator(df, feature, lagStart, lagInterval, lagEnd)\n","#lets build the target and the features\n","df=HolidayFeatureCreator(df)\n","df=CreateWorkHourFeature(df)\n","df=TimeRelatedFeatureConstructor(df)\n","df=FourierFeatureConstructor(df,granularity,fourier_terms_list)\n","\n","df=df.drop(columns=OriginalFeatures)\n","\n","df.dropna(inplace=True)\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"i9hNWTTUR4fm","executionInfo":{"status":"error","timestamp":1768994823095,"user_tz":-60,"elapsed":119,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"9f4f92d8-bee0-4dfd-c5b1-ccb7385d4bfb"},"execution_count":22,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"(unicode error) 'unicodeescape' codec can't decode bytes in position 419-420: truncated \\UXXXXXXXX escape (ipython-input-1671364098.py, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1671364098.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"filename=\"Meter integration_steps1_5_CLEANED without STL for energy.xlsx\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 419-420: truncated \\UXXXXXXXX escape\n"]}]},{"cell_type":"code","source":["test_date=\"2025-06-01 00:00:00\" #summer\n","#test_date=\"2025-02-01 00:00:00\" #winter\n","\n","\n","# Example\n","splits = make_splits(test_date, freq=\"10min\", val_days=14, train_steps=5000)\n","\n","train_start=splits[\"train_start\"]\n","train_end=splits[\"train_end\"]\n","validation_start=splits[\"validation_start\"]\n","validation_end=splits[\"validation_end\"]\n","test_start=splits[\"test_start\"]\n","test_end =splits[\"test_end\"]\n","\n","#lets split them\n","DF_training = df[train_start:train_end]  # Include up to train_end_date\n","DF_validation = df[validation_start:validation_end]  # Start after train_end_date\n","DF_test = df[test_start:test_end]  # Start after validation_end_date\n","\n","\n","DF_training_and_DF_validation=pd.concat([DF_training,DF_validation])\n","Selected_Features=DF_training_and_DF_validation.drop([target],axis=1) # df, all features except target in a dataframe for the first period\n","DF_target=DF_training_and_DF_validation[target] #one column df of the target for the next period\n"],"metadata":{"id":"IZ-YxhBlV0ub","executionInfo":{"status":"ok","timestamp":1768995261423,"user_tz":-60,"elapsed":35,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15e45e85","executionInfo":{"status":"ok","timestamp":1768995285755,"user_tz":-60,"elapsed":24306,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"ba927948-0fc1-4aef-964f-647f5ed241b7"},"source":["from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","from xgboost import XGBRegressor\n","\n","# Define features (X) and target (y)\n","X = Selected_Features\n","y = DF_target\n","\n","# Initialize XGBRegressor\n","model = XGBRegressor()\n","\n","# Initialize TimeSeriesSplit\n","# n_splits determines the number of train/test splits to generate.\n","# Each split's training set grows, and its test set is a fixed size (the last part of the data).\n","# For example, if n_splits=5, there will be 5 splits.\n","# The first split might use 20% for train, 20% for test, and the last uses 80% for train, 20% for test.\n","tscv = TimeSeriesSplit(n_splits=5)\n","\n","rmse_scores = []\n","\n","# Perform Time Series Cross-Validation\n","for train_index, test_index in tscv.split(X):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate RMSE and store it\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","    rmse_scores.append(rmse)\n","\n","print(f\"RMSE scores for each fold: {rmse_scores}\")\n","print(f\"Average RMSE across all folds: {np.mean(rmse_scores)}\")"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE scores for each fold: [np.float64(0.5698553035487611), np.float64(0.4350204557578628), np.float64(0.38829053867783064), np.float64(0.2503795565524707), np.float64(0.3397412222739681)]\n","Average RMSE across all folds: 0.3966574153621787\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4b40e176","executionInfo":{"status":"ok","timestamp":1768995285756,"user_tz":-60,"elapsed":5,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"69d51457-368f-4e57-d846-85813452f175"},"source":["import optuna\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","\n","def objective(trial):\n","    # 3. Suggest hyperparameters for XGBoost\n","    param = {\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n","        'max_depth': trial.suggest_int('max_depth', 3, 9),\n","        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n","        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n","        'gamma': trial.suggest_float('gamma', 0.0, 0.5),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n","        'random_state': 42\n","    }\n","\n","    # 4. Initialize an XGBRegressor model using the suggested hyperparameters\n","    model = XGBRegressor(**param)\n","\n","    # 5. Instantiate TimeSeriesSplit\n","    tscv = TimeSeriesSplit(n_splits=5)\n","\n","    # 6. Initialize an empty list to store RMSE scores for each fold\n","    rmse_scores = []\n","\n","    # Use the globally available X (Selected_Features) and y (DF_target)\n","    X = Selected_Features\n","    y = DF_target\n","\n","    # 7. Loop through the splits generated by TimeSeriesSplit\n","    for train_index, test_index in tscv.split(X):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","        # 8. Train the model and make predictions\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # 9. Calculate RMSE for each fold and append it to the rmse_scores list\n","        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","        rmse_scores.append(rmse)\n","\n","    # 10. Calculate the mean of the rmse_scores\n","    mean_rmse = np.mean(rmse_scores)\n","\n","    # 11. Return the calculated mean RMSE\n","    return mean_rmse\n","\n","print(\"Optuna objective function 'objective' defined successfully.\")"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Optuna objective function 'objective' defined successfully.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c62d71e9","executionInfo":{"status":"ok","timestamp":1768996559961,"user_tz":-60,"elapsed":1274205,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"db86e141-d5af-4e1d-a637-890f7711d1f0"},"source":["import joblib\n","import optuna\n","from xgboost import XGBRegressor\n","\n","# 1. Create an Optuna study\n","# Using a TPE sampler with a seed for reproducibility\n","sampler = optuna.samplers.TPESampler(seed=42)\n","study = optuna.create_study(direction='minimize', sampler=sampler)\n","\n","# 2. Run the optimization process\n","# You can adjust n_trials based on computational resources and desired exploration\n","print(\"Starting Optuna optimization...\")\n","study.optimize(objective, n_trials=50, show_progress_bar=True)\n","print(\"Optuna optimization finished.\")\n","\n","# 3. Print the best trial's value and parameters\n","print(\"\\nBest trial:\")\n","trial = study.best_trial\n","print(f\"  Value (Mean RMSE): {trial.value:.4f}\")\n","print(\"  Params:\")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")\n","\n","# 4. Retrieve the best hyperparameters from the Optuna study\n","best_params = study.best_params\n","\n","# 5. Train a final XGBRegressor model with the best parameters\n","print(\"\\nTraining final XGBoost model with best parameters...\")\n","final_model = XGBRegressor(**best_params, random_state=42)\n","\n","\n","X_train=DF_training_and_DF_validation.drop([target],axis=1) # df, all features except target in a dataframe for the first period\n","X_test=DF_test.drop([target],axis=1) #df , all feature except target (same as before but for the next available period period)\n","y_train=DF_training_and_DF_validation[target] #one column df, of the target for the first period\n","y_test=DF_test[target] #one column df of the target for the next period\n","\n","\n","final_model.fit(X_train , y_train)\n","\n","predicted_val = final_model.predict(X_test)\n","\n","name=\"XGBoost\"\n","d=ErrorCalculator(name,y_test,predicted_val)\n","print(d)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2026-01-21 11:34:46,475] A new study created in memory with name: no-name-9934d7a2-1ba1-4e87-8b8e-d84c798208ab\n"]},{"output_type":"stream","name":"stdout","text":["Starting Optuna optimization...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24765f3829c44c46bca9c1c9def89bbd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:35:02,565] Trial 0 finished with value: 0.38656465352389147 and parameters: {'n_estimators': 437, 'max_depth': 9, 'learning_rate': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'gamma': 0.07799726016810132, 'min_child_weight': 1}. Best is trial 0 with value: 0.38656465352389147.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:35:24,469] Trial 1 finished with value: 0.3692953289324069 and parameters: {'n_estimators': 880, 'max_depth': 7, 'learning_rate': 0.11114989443094977, 'subsample': 0.608233797718321, 'colsample_bytree': 0.9879639408647978, 'gamma': 0.41622132040021087, 'min_child_weight': 3}. Best is trial 1 with value: 0.3692953289324069.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:35:44,063] Trial 2 finished with value: 0.35604315950236964 and parameters: {'n_estimators': 263, 'max_depth': 4, 'learning_rate': 0.028145092716060652, 'subsample': 0.8099025726528951, 'colsample_bytree': 0.7727780074568463, 'gamma': 0.14561457009902096, 'min_child_weight': 7}. Best is trial 2 with value: 0.35604315950236964.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:36:04,466] Trial 3 finished with value: 0.3645882217352136 and parameters: {'n_estimators': 225, 'max_depth': 5, 'learning_rate': 0.03476649150592621, 'subsample': 0.7824279936868144, 'colsample_bytree': 0.9140703845572055, 'gamma': 0.09983689107917987, 'min_child_weight': 6}. Best is trial 2 with value: 0.35604315950236964.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:36:17,284] Trial 4 finished with value: 0.3388984408345573 and parameters: {'n_estimators': 633, 'max_depth': 3, 'learning_rate': 0.07896186801026692, 'subsample': 0.6682096494749166, 'colsample_bytree': 0.6260206371941118, 'gamma': 0.4744427686266666, 'min_child_weight': 10}. Best is trial 4 with value: 0.3388984408345573.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:37:19,003] Trial 5 finished with value: 0.3683020070364626 and parameters: {'n_estimators': 828, 'max_depth': 5, 'learning_rate': 0.013940346079873234, 'subsample': 0.8736932106048627, 'colsample_bytree': 0.7760609974958406, 'gamma': 0.06101911742238941, 'min_child_weight': 5}. Best is trial 4 with value: 0.3388984408345573.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:37:53,951] Trial 6 finished with value: 0.3673515030101303 and parameters: {'n_estimators': 130, 'max_depth': 9, 'learning_rate': 0.024112898115291985, 'subsample': 0.8650089137415928, 'colsample_bytree': 0.7246844304357644, 'gamma': 0.2600340105889054, 'min_child_weight': 6}. Best is trial 4 with value: 0.3388984408345573.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:38:03,426] Trial 7 finished with value: 0.392612575538165 and parameters: {'n_estimators': 266, 'max_depth': 9, 'learning_rate': 0.13962563737015762, 'subsample': 0.9757995766256756, 'colsample_bytree': 0.9579309401710595, 'gamma': 0.29894998940554257, 'min_child_weight': 10}. Best is trial 4 with value: 0.3388984408345573.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:38:18,470] Trial 8 finished with value: 0.3472878241413413 and parameters: {'n_estimators': 179, 'max_depth': 4, 'learning_rate': 0.011662890273931383, 'subsample': 0.7301321323053057, 'colsample_bytree': 0.7554709158757928, 'gamma': 0.13567451588694796, 'min_child_weight': 9}. Best is trial 4 with value: 0.3388984408345573.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:38:39,521] Trial 9 finished with value: 0.3661525001527318 and parameters: {'n_estimators': 421, 'max_depth': 4, 'learning_rate': 0.06333268775321842, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'gamma': 0.03727532183988541, 'min_child_weight': 10}. Best is trial 4 with value: 0.3388984408345573.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:38:51,789] Trial 10 finished with value: 0.358007869770232 and parameters: {'n_estimators': 675, 'max_depth': 3, 'learning_rate': 0.27047297227177763, 'subsample': 0.6998501323364759, 'colsample_bytree': 0.6058163500649457, 'gamma': 0.4538323976412588, 'min_child_weight': 8}. Best is trial 4 with value: 0.3388984408345573.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:39:24,047] Trial 11 finished with value: 0.33741202985857405 and parameters: {'n_estimators': 645, 'max_depth': 3, 'learning_rate': 0.010233318617812301, 'subsample': 0.7232128117232646, 'colsample_bytree': 0.8469817891972085, 'gamma': 0.1948969760611503, 'min_child_weight': 9}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:39:41,622] Trial 12 finished with value: 0.3431726819928818 and parameters: {'n_estimators': 672, 'max_depth': 3, 'learning_rate': 0.05846028156236148, 'subsample': 0.7261145263607007, 'colsample_bytree': 0.8548132432909736, 'gamma': 0.3645910242108623, 'min_child_weight': 8}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:40:00,839] Trial 13 finished with value: 0.3743264870304375 and parameters: {'n_estimators': 642, 'max_depth': 7, 'learning_rate': 0.08528025774740962, 'subsample': 0.6193891606892246, 'colsample_bytree': 0.8488073013225127, 'gamma': 0.20274715173215227, 'min_child_weight': 10}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:40:11,748] Trial 14 finished with value: 0.35645308615124294 and parameters: {'n_estimators': 524, 'max_depth': 3, 'learning_rate': 0.193914898884689, 'subsample': 0.6778972814632855, 'colsample_bytree': 0.6898693025872835, 'gamma': 0.49824831528997665, 'min_child_weight': 8}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:40:55,651] Trial 15 finished with value: 0.3627422504963401 and parameters: {'n_estimators': 995, 'max_depth': 6, 'learning_rate': 0.01845106052028737, 'subsample': 0.7641985619676263, 'colsample_bytree': 0.8525822976515653, 'gamma': 0.32084726229277105, 'min_child_weight': 9}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:41:19,648] Trial 16 finished with value: 0.352924564558751 and parameters: {'n_estimators': 797, 'max_depth': 5, 'learning_rate': 0.0423222846026257, 'subsample': 0.6577039151126512, 'colsample_bytree': 0.6082858712967962, 'gamma': 0.20678901277172781, 'min_child_weight': 4}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:41:45,347] Trial 17 finished with value: 0.356210265520789 and parameters: {'n_estimators': 553, 'max_depth': 3, 'learning_rate': 0.07650814662600473, 'subsample': 0.930573919743892, 'colsample_bytree': 0.8280109881978687, 'gamma': 0.002370059826544646, 'min_child_weight': 9}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:42:16,278] Trial 18 finished with value: 0.3517573070370138 and parameters: {'n_estimators': 379, 'max_depth': 4, 'learning_rate': 0.01018545405622195, 'subsample': 0.7552255034619454, 'colsample_bytree': 0.8937243027997998, 'gamma': 0.369648695685988, 'min_child_weight': 7}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:42:39,180] Trial 19 finished with value: 0.36075597281769733 and parameters: {'n_estimators': 743, 'max_depth': 6, 'learning_rate': 0.043262238858322886, 'subsample': 0.7039846606973359, 'colsample_bytree': 0.6490634765682267, 'gamma': 0.21593903975613526, 'min_child_weight': 1}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:43:25,523] Trial 20 finished with value: 0.3634079886951298 and parameters: {'n_estimators': 523, 'max_depth': 7, 'learning_rate': 0.017321060152818785, 'subsample': 0.644394359044199, 'colsample_bytree': 0.720645297058875, 'gamma': 0.14041389381371158, 'min_child_weight': 7}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:43:40,811] Trial 21 finished with value: 0.33897800055435107 and parameters: {'n_estimators': 632, 'max_depth': 3, 'learning_rate': 0.0544086971411878, 'subsample': 0.7298422871334832, 'colsample_bytree': 0.8132895760469891, 'gamma': 0.37447666812353636, 'min_child_weight': 8}. Best is trial 11 with value: 0.33741202985857405.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:43:53,739] Trial 22 finished with value: 0.3370095150993643 and parameters: {'n_estimators': 632, 'max_depth': 3, 'learning_rate': 0.16246185022301976, 'subsample': 0.7346962951509844, 'colsample_bytree': 0.8119011094573535, 'gamma': 0.4878978334662621, 'min_child_weight': 9}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:44:03,818] Trial 23 finished with value: 0.35089631154100837 and parameters: {'n_estimators': 589, 'max_depth': 4, 'learning_rate': 0.19124904963270992, 'subsample': 0.8079781006572402, 'colsample_bytree': 0.7969308389241148, 'gamma': 0.48580443997596645, 'min_child_weight': 10}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:44:22,595] Trial 24 finished with value: 0.34282918250190697 and parameters: {'n_estimators': 729, 'max_depth': 3, 'learning_rate': 0.1690920472834063, 'subsample': 0.6941624187959704, 'colsample_bytree': 0.8930424201314591, 'gamma': 0.431274864903862, 'min_child_weight': 9}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:44:40,287] Trial 25 finished with value: 0.36805682406577567 and parameters: {'n_estimators': 934, 'max_depth': 4, 'learning_rate': 0.26439125768353683, 'subsample': 0.7554321542531295, 'colsample_bytree': 0.7399644017682999, 'gamma': 0.317178429226323, 'min_child_weight': 9}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:44:52,978] Trial 26 finished with value: 0.3526315365331351 and parameters: {'n_estimators': 474, 'max_depth': 5, 'learning_rate': 0.09014656521799501, 'subsample': 0.6398490606957885, 'colsample_bytree': 0.7916411466893118, 'gamma': 0.45792186867269397, 'min_child_weight': 10}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:45:00,721] Trial 27 finished with value: 0.3440706760286818 and parameters: {'n_estimators': 346, 'max_depth': 3, 'learning_rate': 0.09668901638312032, 'subsample': 0.6754509400699001, 'colsample_bytree': 0.8223638006736039, 'gamma': 0.40510745336665976, 'min_child_weight': 3}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:45:22,662] Trial 28 finished with value: 0.3749446111377743 and parameters: {'n_estimators': 752, 'max_depth': 8, 'learning_rate': 0.1411884240069839, 'subsample': 0.7148596649474817, 'colsample_bytree': 0.6931098414141448, 'gamma': 0.25473477248696075, 'min_child_weight': 7}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:45:37,108] Trial 29 finished with value: 0.3778239522184491 and parameters: {'n_estimators': 599, 'max_depth': 6, 'learning_rate': 0.1163238128384985, 'subsample': 0.8206382772661867, 'colsample_bytree': 0.6493683700479093, 'gamma': 0.17563931011015704, 'min_child_weight': 8}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:45:51,025] Trial 30 finished with value: 0.3558509563878982 and parameters: {'n_estimators': 455, 'max_depth': 4, 'learning_rate': 0.06893101051445573, 'subsample': 0.7807709953064131, 'colsample_bytree': 0.8782947246006407, 'gamma': 0.28507591314899, 'min_child_weight': 9}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:46:08,450] Trial 31 finished with value: 0.3389524429508252 and parameters: {'n_estimators': 666, 'max_depth': 3, 'learning_rate': 0.05251671049899771, 'subsample': 0.7437044968175406, 'colsample_bytree': 0.819254770169607, 'gamma': 0.36989544649946293, 'min_child_weight': 8}. Best is trial 22 with value: 0.3370095150993643.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:46:28,774] Trial 32 finished with value: 0.3363550756808928 and parameters: {'n_estimators': 706, 'max_depth': 3, 'learning_rate': 0.024797944516010192, 'subsample': 0.7367655269059235, 'colsample_bytree': 0.8363862000683678, 'gamma': 0.46500948176791573, 'min_child_weight': 10}. Best is trial 32 with value: 0.3363550756808928.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:46:53,746] Trial 33 finished with value: 0.33396419618544393 and parameters: {'n_estimators': 814, 'max_depth': 3, 'learning_rate': 0.02521007215919529, 'subsample': 0.600558315413456, 'colsample_bytree': 0.9549772951275722, 'gamma': 0.4639240676039269, 'min_child_weight': 10}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:47:21,328] Trial 34 finished with value: 0.3490806839413653 and parameters: {'n_estimators': 856, 'max_depth': 4, 'learning_rate': 0.024072346971824487, 'subsample': 0.6119286936394165, 'colsample_bytree': 0.994098845652604, 'gamma': 0.4179573012054634, 'min_child_weight': 10}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:47:46,532] Trial 35 finished with value: 0.3403362351374628 and parameters: {'n_estimators': 792, 'max_depth': 3, 'learning_rate': 0.03150713181666843, 'subsample': 0.786693663204837, 'colsample_bytree': 0.9470710856444996, 'gamma': 0.4436399695173033, 'min_child_weight': 9}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:48:20,400] Trial 36 finished with value: 0.35367031390601883 and parameters: {'n_estimators': 908, 'max_depth': 4, 'learning_rate': 0.017000715592865062, 'subsample': 0.8362673721525016, 'colsample_bytree': 0.9722227652031007, 'gamma': 0.3983793363036492, 'min_child_weight': 10}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:48:48,298] Trial 37 finished with value: 0.3599245643762937 and parameters: {'n_estimators': 716, 'max_depth': 5, 'learning_rate': 0.02558707691668594, 'subsample': 0.8755018207309047, 'colsample_bytree': 0.9311031290458487, 'gamma': 0.49914179308300166, 'min_child_weight': 5}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:49:14,317] Trial 38 finished with value: 0.3349951939395518 and parameters: {'n_estimators': 784, 'max_depth': 3, 'learning_rate': 0.021042335453493287, 'subsample': 0.6280696125188847, 'colsample_bytree': 0.8711707916960797, 'gamma': 0.34037898086747775, 'min_child_weight': 7}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:49:53,746] Trial 39 finished with value: 0.36396784867243615 and parameters: {'n_estimators': 819, 'max_depth': 8, 'learning_rate': 0.021482886375755492, 'subsample': 0.601633889254141, 'colsample_bytree': 0.8745512680705486, 'gamma': 0.46246343877695784, 'min_child_weight': 7}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:50:15,216] Trial 40 finished with value: 0.3505759183718006 and parameters: {'n_estimators': 874, 'max_depth': 4, 'learning_rate': 0.03563150904085565, 'subsample': 0.6338007061866716, 'colsample_bytree': 0.7732665573046109, 'gamma': 0.4749959597638071, 'min_child_weight': 6}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:50:44,823] Trial 41 finished with value: 0.3351714549135014 and parameters: {'n_estimators': 770, 'max_depth': 3, 'learning_rate': 0.013954466163900753, 'subsample': 0.6845999096622835, 'colsample_bytree': 0.83868868248382, 'gamma': 0.346809181146677, 'min_child_weight': 9}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:51:17,154] Trial 42 finished with value: 0.3346072974952771 and parameters: {'n_estimators': 774, 'max_depth': 3, 'learning_rate': 0.014128194805772768, 'subsample': 0.6262525025608777, 'colsample_bytree': 0.8729028748521833, 'gamma': 0.3326153753856823, 'min_child_weight': 10}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:51:51,584] Trial 43 finished with value: 0.33492866953611156 and parameters: {'n_estimators': 784, 'max_depth': 3, 'learning_rate': 0.012696500474651613, 'subsample': 0.6258945044189204, 'colsample_bytree': 0.8922186461015428, 'gamma': 0.3249213182987264, 'min_child_weight': 10}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:52:29,338] Trial 44 finished with value: 0.33478889430868625 and parameters: {'n_estimators': 925, 'max_depth': 3, 'learning_rate': 0.012994567052985916, 'subsample': 0.6249868712460229, 'colsample_bytree': 0.9163390352745451, 'gamma': 0.33722032165534416, 'min_child_weight': 10}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:53:05,891] Trial 45 finished with value: 0.3498917290841776 and parameters: {'n_estimators': 994, 'max_depth': 4, 'learning_rate': 0.013516953681371745, 'subsample': 0.6248222876300942, 'colsample_bytree': 0.9068965441379474, 'gamma': 0.33775244954170475, 'min_child_weight': 10}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:53:44,975] Trial 46 finished with value: 0.334956877116943 and parameters: {'n_estimators': 936, 'max_depth': 3, 'learning_rate': 0.012443976506288262, 'subsample': 0.6610992710297577, 'colsample_bytree': 0.9338123907602571, 'gamma': 0.2907427257003492, 'min_child_weight': 3}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:54:30,000] Trial 47 finished with value: 0.35082548711994116 and parameters: {'n_estimators': 928, 'max_depth': 4, 'learning_rate': 0.012351769730189328, 'subsample': 0.6515226641801007, 'colsample_bytree': 0.9379499165165096, 'gamma': 0.2633270305708084, 'min_child_weight': 2}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:55:14,509] Trial 48 finished with value: 0.35676688191322975 and parameters: {'n_estimators': 958, 'max_depth': 5, 'learning_rate': 0.01534132818730232, 'subsample': 0.6013243695529953, 'colsample_bytree': 0.9702673073431352, 'gamma': 0.2972751114410838, 'min_child_weight': 4}. Best is trial 33 with value: 0.33396419618544393.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-711183834.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:55:54,064] Trial 49 finished with value: 0.3386157226823918 and parameters: {'n_estimators': 868, 'max_depth': 3, 'learning_rate': 0.011088873642242323, 'subsample': 0.6610802568824525, 'colsample_bytree': 0.9103099443690699, 'gamma': 0.22979416456614155, 'min_child_weight': 10}. Best is trial 33 with value: 0.33396419618544393.\n","Optuna optimization finished.\n","\n","Best trial:\n","  Value (Mean RMSE): 0.3340\n","  Params:\n","    n_estimators: 814\n","    max_depth: 3\n","    learning_rate: 0.02521007215919529\n","    subsample: 0.600558315413456\n","    colsample_bytree: 0.9549772951275722\n","    gamma: 0.4639240676039269\n","    min_child_weight: 10\n","\n","Training final XGBoost model with best parameters...\n","{'Pipelines': 'XGBoost', 'RMSE': np.float64(0.24224314870091196), 'MAE': 0.17665083851813085, 'MSE': 0.05868174309253214}\n"]}]},{"cell_type":"code","source":["predicted_DF = pd.DataFrame(predicted_val , index=DF_test.index, columns=[\"XGBoost\"])\n","\n","predicted_DF = predicted_DF.join(y_test)\n","\n","predicted_DF=predicted_DF.loc[DF_test.index]\n","\n","predicted_DF.columns = [\"XGBoost\", \"target\"]\n","\n","\n","predicted_DF[:300].plot()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":499},"id":"00BVmpFpcar0","executionInfo":{"status":"ok","timestamp":1768996560888,"user_tz":-60,"elapsed":921,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"be2754a5-a7e7-48fb-dcaa-be586a7e115d"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='timestamp'>"]},"metadata":{},"execution_count":27},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Ensure it's a Timestamp / datetime\n","test_date_ts = pd.to_datetime(test_date)\n","\n","# Format without forbidden chars (:, etc.)\n","test_date_str = test_date_ts.strftime(\"%Y-%m-%d_%H-%M-%S\")  # e.g. 2025-09-19_00-00-00\n","\n","test_ts = f\"{test_date_str}_xgboost.csv\"\n","test_filepath = os.path.join(path, test_ts)\n","\n","predicted_DF[\"XGBoost\"].to_csv(test_filepath, index=True)"],"metadata":{"id":"pihCwffEc-2b","executionInfo":{"status":"ok","timestamp":1768996560895,"user_tz":-60,"elapsed":4,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"execution_count":28,"outputs":[]}]}