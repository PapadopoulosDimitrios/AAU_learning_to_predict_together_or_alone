{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNuzgnPH61EYEgx2Z22paq9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d5f3374b2a8e46c1b2559225c1022882":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_16eb8054eeab401084956cb7093bf4df","IPY_MODEL_8486f49f289747988c43895cee31832d","IPY_MODEL_a7b596ad5a7244a0a18be942e2a7b28b"],"layout":"IPY_MODEL_d191e48f6be543709c06b4eaf3fed9ee"}},"16eb8054eeab401084956cb7093bf4df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_857e0007c6db45b7ad5bdf7cef343be1","placeholder":"​","style":"IPY_MODEL_4a61b1e38e884e3ea045f4d6d2f7a85f","value":"Best trial: 28. Best value: 0.338133: 100%"}},"8486f49f289747988c43895cee31832d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1288985638b44ab3ab91335da722feb2","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47c5a8441a8f4ce3af48aa772de44cff","value":30}},"a7b596ad5a7244a0a18be942e2a7b28b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3efbe83418e54665bc79f0168b4fc651","placeholder":"​","style":"IPY_MODEL_9ce7259834804e3f82455398cd783717","value":" 30/30 [54:01&lt;00:00, 21.15s/it]"}},"d191e48f6be543709c06b4eaf3fed9ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"857e0007c6db45b7ad5bdf7cef343be1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a61b1e38e884e3ea045f4d6d2f7a85f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1288985638b44ab3ab91335da722feb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47c5a8441a8f4ce3af48aa772de44cff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3efbe83418e54665bc79f0168b4fc651":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ce7259834804e3f82455398cd783717":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Yk55RhvJw8G","executionInfo":{"status":"ok","timestamp":1768996317581,"user_tz":-60,"elapsed":21607,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"outputId":"b061cd93-db22-44c1-9ff2-da348adc6f51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["pip install optuna"],"metadata":{"id":"nOjXGVk9VjH8","executionInfo":{"status":"ok","timestamp":1768996324414,"user_tz":-60,"elapsed":6840,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3abe6a44-7a69-474d-e5b1-6707e4052d6e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n","Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, optuna\n","Successfully installed colorlog-6.10.1 optuna-4.7.0\n"]}]},{"cell_type":"code","source":["pip install feature-engine"],"metadata":{"id":"MYh81eBXKDOP","executionInfo":{"status":"ok","timestamp":1768996334258,"user_tz":-60,"elapsed":9841,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cabcd435-a82f-481a-db3b-997e77bea2f5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting feature-engine\n","  Downloading feature_engine-1.9.3-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (2.0.2)\n","Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (2.2.2)\n","Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (1.6.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (1.16.3)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from feature-engine) (0.14.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->feature-engine) (2025.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->feature-engine) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->feature-engine) (3.6.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.11.1->feature-engine) (1.0.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.11.1->feature-engine) (25.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->feature-engine) (1.17.0)\n","Downloading feature_engine-1.9.3-py3-none-any.whl (229 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: feature-engine\n","Successfully installed feature-engine-1.9.3\n"]}]},{"cell_type":"code","source":["pip install sktime"],"metadata":{"id":"jpFSgeWnKJVP","executionInfo":{"status":"ok","timestamp":1768996356032,"user_tz":-60,"elapsed":21770,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"51a5fba5-2090-4070-a467-d563a671678f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sktime\n","  Downloading sktime-0.40.1-py3-none-any.whl.metadata (33 kB)\n","Requirement already satisfied: joblib<1.6,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.5.3)\n","Requirement already satisfied: numpy<2.4,>=1.21 in /usr/local/lib/python3.12/dist-packages (from sktime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from sktime) (25.0)\n","Requirement already satisfied: pandas<2.4.0,>=1.1 in /usr/local/lib/python3.12/dist-packages (from sktime) (2.2.2)\n","Collecting scikit-base<0.14.0,>=0.6.1 (from sktime)\n","  Downloading scikit_base-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: scikit-learn<1.8.0,>=0.24 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.6.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.12/dist-packages (from sktime) (1.16.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=1.1->sktime) (2025.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=0.24->sktime) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=1.1->sktime) (1.17.0)\n","Downloading sktime-0.40.1-py3-none-any.whl (36.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_base-0.13.0-py3-none-any.whl (151 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-base, sktime\n","Successfully installed scikit-base-0.13.0 sktime-0.40.1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","#import cmaes\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import logging\n","logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from feature_engine.datetime import DatetimeFeatures\n","from feature_engine.creation import CyclicalFeatures\n","from feature_engine.timeseries.forecasting import ExpandingWindowFeatures,LagFeatures\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","from sktime.transformations.series.fourier import FourierFeatures\n","from feature_engine.timeseries.forecasting import WindowFeatures\n","import holidays\n","from sklearn.ensemble import RandomForestRegressor\n"],"metadata":{"id":"Y1lHHjOIJ3fY","executionInfo":{"status":"ok","timestamp":1768996365087,"user_tz":-60,"elapsed":9050,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def sliding_window_forecast_fixed_size(modelname, fcst, DF_training_scaled, DF_validation_scaled, scaler_target,\n","                                       prediction_horizon_steps=96, fixed_training_size=8832):\n","    \"\"\"\n","    Perform a sliding window forecast with a fixed-size training set.\n","\n","    Parameters:\n","    fcst (MLForecast): The forecast model.\n","    DF_training_scaled (pd.DataFrame): Scaled initial training data.\n","    DF_validation_scaled (pd.DataFrame): Scaled validation data for future predictions.\n","    scaler_target (MinMaxScaler): Scaler used to inverse transform the target variable.\n","    prediction_horizon_steps (int): Number of steps ahead to predict (default: 96).\n","    fixed_training_size (int): Fixed size of the rolling training window.\n","\n","    Returns:\n","    pd.DataFrame: A DataFrame containing the day-ahead predictions for each step.\n","    \"\"\"\n","    # Create an empty DataFrame to store all predictions\n","    all_preds = pd.DataFrame()\n","\n","    # Sliding window loop: run as long as there are enough validation points left\n","    num_iterations = len(DF_validation_scaled) // prediction_horizon_steps\n","\n","    for i in range(num_iterations):\n","        # Step 1: Fit the model on the current training data (empty static features)\n","        fcst.fit(DF_training_scaled, static_features=[])\n","\n","        # Step 2: Predict the next 'prediction_horizon_steps' (e.g., 96 steps)\n","        # Ensure only the next prediction_horizon_steps rows are passed to X_df\n","        X_df = DF_validation_scaled.drop(columns=[\"y\"], axis=1).iloc[:prediction_horizon_steps]\n","        preds = fcst.predict(h=prediction_horizon_steps, X_df=X_df)\n","\n","        # Step 3: Reshape and inverse transform the predictions to original scale\n","        predictions_reshaped = preds[modelname].to_numpy().reshape(-1, 1)\n","        predictions_original_scale = scaler_target.inverse_transform(predictions_reshaped).flatten()\n","\n","        # Step 4: Assign the predictions to the original DataFrame (store the time index 'ds' and unscaled predictions)\n","        preds[modelname+\"_unscaled\"] = predictions_original_scale\n","\n","        # Step 5: Append predictions to the results DataFrame\n","        all_preds = pd.concat([all_preds, preds], axis=0)\n","\n","        # Step 6: Update the training data by appending new validation data\n","        new_data = DF_validation_scaled.iloc[:prediction_horizon_steps]\n","\n","        # Remove the newly added data from DF_validation_scaled after each iteration\n","        DF_validation_scaled = DF_validation_scaled.iloc[prediction_horizon_steps:]\n","\n","        # Step 7: Maintain a fixed training size by appending new data and dropping the oldest data\n","        DF_training_scaled = pd.concat([DF_training_scaled, new_data], axis=0)\n","        if len(DF_training_scaled) > fixed_training_size:\n","            DF_training_scaled = DF_training_scaled.iloc[-fixed_training_size:]  # Keep only the latest entries\n","\n","    return all_preds\n","\n","def plot_predictions(model_name, df_validation_y, all_preds_unscaled):\n","    plt.figure(figsize=(14, 7))\n","\n","    # Plot actual values\n","    plt.plot(df_validation_y.index, df_validation_y.values, label='Actual Values', color='blue', linewidth=2)\n","\n","    # Plot predicted values\n","    plt.plot(all_preds_unscaled.index, all_preds_unscaled.values, label=f'Predicted Values ({model_name})', color='red', linestyle='-', linewidth=2)\n","\n","    # Add labels and title\n","    plt.xlabel('Time')\n","    plt.ylabel('Net Load')\n","    plt.title(f'Actual vs Predicted Values ({model_name})')\n","\n","    # Add legend\n","    plt.legend()\n","\n","    # Rotate x-ticks for better readability\n","    plt.xticks(rotation=45)\n","\n","    # Show the plot\n","    plt.tight_layout()\n","    plt.show()\n","\n","def CreateWorkHourFeature(input_data):\n","    \"\"\"\n","    Receives as input a DataFrame or Series and outputs a DataFrame with the working hours during the day.\n","    When the day of the week is larger than 4, it is considered a weekend (1), otherwise, it's a workday (0).\n","    During workdays and between 8:00 and 17:00, it is considered a working hour.\n","\n","    Parameters:\n","    input_data (DataFrame or Series): Input data with a DatetimeIndex.\n","\n","    Returns:\n","    DataFrame: DataFrame with the added \"WorkingHour_flag\" column.\n","    \"\"\"\n","    if isinstance(input_data, pd.Series):\n","        input_df = pd.DataFrame(input_data)\n","    elif isinstance(input_data, pd.DataFrame):\n","        input_df = input_data\n","    else:\n","        raise ValueError(\"Input must be a DataFrame or Series.\")\n","\n","    assert isinstance(input_df.index, pd.DatetimeIndex), \"Index must be a datetime index.\"\n","\n","    input_df[\"dayOfWeek\"] = input_df.index.dayofweek\n","    input_df.loc[input_df[\"dayOfWeek\"] > 4, \"weekendFlag\"] = 1\n","    input_df.loc[input_df[\"dayOfWeek\"] < 5, \"weekendFlag\"] = 0\n","    input_df[\"hour\"] = input_df.index.hour\n","    input_df[\"WorkingHour_flag\"] = 0\n","    input_df.loc[((input_df[\"hour\"] > 8) & (input_df[\"hour\"] < 17) & (input_df[\"weekendFlag\"] == 0)), \"WorkingHour_flag\"] = 1\n","    input_df.drop([\"hour\", \"dayOfWeek\", \"weekendFlag\"], axis=1, inplace=True)\n","\n","    return input_df\n","\n","\n","def ListCreatorFlagger(df, substrings=['flag', 'cos', 'sin','day_of_week', 'day_of_month', 'weekend', 'days_in_month', 'hour', 'minute']):\n","    \"\"\"\n","    A function that separates the columns containing specified substrings from those that don't.\n","    df is the dataframe in question and the substring is a list.\n","    \"\"\"\n","    flag_columns = [col for col in df.columns if any(substring in col for substring in substrings)]\n","\n","    if not flag_columns:\n","        print(\"No columns with the specified substrings found.\")\n","        return None, None\n","\n","    non_flag_columns = [col for col in df.columns if col not in flag_columns]\n","\n","    return non_flag_columns, flag_columns\n","\n","\n","def HolidayFeatureCreator(input_data):\n","    \"\"\"\n","    Receives as input a DataFrame or Series and creates a column named \"Holidays_flag\" with 1 if there is a holiday and with 0 if no holidays exist.\n","    Holidays derived from Germany.\n","    \"\"\"\n","    if isinstance(input_data, pd.Series):\n","        input_df = pd.DataFrame(input_data)\n","    elif isinstance(input_data, pd.DataFrame):\n","        input_df = input_data\n","    else:\n","        raise ValueError(\"Input must be a DataFrame or Series.\")\n","\n","    assert isinstance(input_df.index, pd.DatetimeIndex), \"Index must be a datetime index.\"\n","\n","    national_holidays_all = holidays.DE(years=[2014,2015,2016,2017,2018,2019,2020, 2021, 2022, 2023, 2024, 2025, 2026]).items()\n","    national_holidays = [items[0] for items in national_holidays_all]  # this is a list\n","\n","    # Create a new column for holidays flag\n","    input_df[\"Holidays_flag\"] = 0\n","\n","    # Iterate over the index and set holiday flag to 1 if the date matches any national holiday\n","    for index_date in input_df.index:\n","        if index_date.date() in national_holidays:\n","            input_df.at[index_date, \"Holidays_flag\"] = 1\n","\n","    return input_df\n","\n","\n","\n","\n","def TimeRelatedFeatureConstructor(df):\n","  \"\"\"\n","  Works only in a dataframe as input: run the other functions first.\n","  Extracts time-related features\n","  \"\"\"\n","  TimeFeaturesToExtract=[\"day_of_week\",\"weekend\",\"hour\",] #consider to add more\n","  dtfs=DatetimeFeatures(variables=\"index\", features_to_extract=TimeFeaturesToExtract, drop_original=False)\n","  df=dtfs.fit_transform(df)\n","\n","  CyclicalFeaturesToExtract=[\"day_of_week\",\"hour\",]\n","  cyclical_dtfs=CyclicalFeatures(variables=CyclicalFeaturesToExtract,drop_original=False)\n","  df=cyclical_dtfs.fit_transform(df)\n","  return df\n","\n","\n","def FourierFeatureConstructor(df, granularity, fourier_terms_list):\n","    # Extract numerical part of granularity\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    number_int = int(number_part) if number_part else 1  # Fallback to 1 to avoid division by zero\n","\n","    # Calculate minutes per hour, ensuring no division by zero\n","    minutes4hour = 60 / number_int if number_int != 0 else 60\n","\n","    # Define seasonal periods (sp_list) for Fourier transformation\n","    sp_list = [\n","        max(minutes4hour, 4),                 # Hourly - for 15min, this should be 4\n","        max(24 * minutes4hour, 96),           # Daily - for 15min, this should be 96\n","        max(24 * 7 * minutes4hour, 672),      # Weekly - for 15min, this should be 672\n","        max(24 * 30 * minutes4hour, 2880)     # Monthly - for 15min, this should be 2880\n","    ]\n","\n","    # Fourier transformer setup\n","    Fourier_Transformer = FourierFeatures(\n","        sp_list=sp_list,\n","        fourier_terms_list=fourier_terms_list,\n","        freq=granularity,\n","        keep_original_columns=True\n","    )\n","\n","    # Apply Fourier transformation\n","    Fourier_Transformer.fit(df)\n","    df = Fourier_Transformer.transform(df)\n","    return df\n","\n","\n","\n","def WindowFeaturesConstructor(df, granularity, ListWithNoFlags):\n","    \"\"\"\n","    This is a function that makes a list of 4 window features starting from double the granularity and following by doubling the previous value\n","    \"\"\"\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    number_int = int(number_part)\n","    double_granularity = 2 * number_int\n","    time_intervals = [double_granularity]\n","\n","    # Calculate subsequent values\n","    for i in range(3):\n","        time_intervals.append(time_intervals[-1] * 2)\n","\n","    windowlist = [interval // number_int for interval in time_intervals]  # Corrected division\n","    functionsList = [\"mean\", \"std\"]\n","    WindownFeatureTransformer = WindowFeatures(variables=ListWithNoFlags,\n","                                               functions=functionsList,\n","                                               window=windowlist,\n","                                               freq=granularity,\n","                                               drop_original=False)\n","\n","    df = WindownFeatureTransformer.fit_transform(df)\n","    return df\n","\n","def ExpandingWindowFeatureConstructor(df,ListWithNoFlags):\n","  functionsList=[\"mean\",\"std\"]\n","  frequency = pd.infer_freq(df.index) #infer the frequency from the dataframe\n","  ExpandingWindownFeatureTransformer=ExpandingWindowFeatures(variables=ListWithNoFlags,\n","                                                           functions=functionsList,\n","                                                           freq=frequency, #I put the freq to shift it down! but now it is performed automatically!\n","                                                           drop_original=False)\n","  df=ExpandingWindownFeatureTransformer.fit_transform(df)\n","  return df\n","\n","def WeightedLinearFeatureMaker(df,ListWithNoFlags,granularity):\n","  \"\"\"\n","  This is a function that takes the original DF and modifies the continious value columns\n","  Inputs: Dataframe, List of columns that are continous values, daily window to slide, weights of the values\n","  \"\"\"\n","  number_part = ''.join(filter(str.isdigit, granularity))\n","  Minutedensity=int(number_part)\n","  Window=int((60/Minutedensity)*24) #288 means a daily window\n","  weights=np.arange(1,Window+1)\n","\n","  # if i had hourly data then i would have had np.arange(1,24*7) for a weekly window\n","\n","  def weighted_mean (x,weights):\n","    return (weights*x).sum()/weights.sum()\n","\n","  def weighted_std(x,weights):\n","    mean_w= weighted_mean(x, weights)\n","    var_w= (weights* (x-mean_w)**2).sum()/weights.sum()\n","    return np.sqrt(var_w)\n","\n","  # LETS make the weighted mean column\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=Window) #here we pick a window size. Needs to be the same as the len(weights)\n","        .apply(weighted_mean, args=(weights,))\n","        .shift(1)#shift by 1 to avoid data leakage\n","        .to_frame()#convert series to df\n","        )\n","\n","    result.columns=[str(i)+\"_weighted_\"+str(Window)+\"_mean\"]\n","    df=df.join(result)\n","\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=Window) #here we pick a window size. Needs to be the same as the len(weights)\n","        .apply(weighted_std, args=(weights,))\n","        .shift(1)#shift by 1 to avoid data leakage\n","        .to_frame()#convert series to df\n","        )\n","\n","    result.columns=[str(i)+\"_weighted_\"+str(Window)+\"_std\"]\n","    df=df.join(result)\n","  return df\n","\n","def ExpWeightMeanMaker(df,ListWithNoFlags,granularity):\n","  \"\"\"\n","  This is a function that makes exp weighted average with a sliding window approach\n","  \"\"\"\n","  number_part = ''.join(filter(str.isdigit, granularity))\n","  Minutedensity=int(number_part)\n","  Window=int((60/Minutedensity)*24) #288 means a daily window\n","\n","  def exp_weights(alpha,window_size):\n","    \"\"\"\n","    a function to calculate the weights for every single component of our sliding windown\n","    \"\"\"\n","    weights=np.ones(window_size) #initializing weights\n","    for ix in range(window_size):\n","      weights[ix]=(1-alpha)**(window_size-1-ix)\n","    return weights\n","\n","  def exp_weighted_mean(x):\n","    \"\"\"\n","    a functions that calculates the exp weigted mean\n","    \"\"\"\n","\n","    weights=exp_weights(alpha=0.05, window_size=len(x)) # HERE WE SET THE ALPHA\n","    return (weights*x).sum()/weights.sum()\n","\n","  for i in ListWithNoFlags:\n","    result=(\n","        df[i]\n","        .rolling(window=int(Window))\n","        .agg([exp_weighted_mean])\n","        .shift(1)\n","    )\n","\n","\n","    result.columns=[str(i)+\"_Exp_weighted_\"+str(Window)+\"_SL.win\"]\n","    df=df.join(result)\n","  return df\n","\n","def WeightedExponentialExpandingWindow(df,ListWithNoFlags,alpha):\n","  \"\"\"\n","  This is a funtion that takes as input the df,a list of continuous values and the alpha.\n","  Outputs: all continuous features on the df that are \"mean\" and \"std\"\n","  \"\"\"\n","\n","  for i in ListWithNoFlags:\n","    df[[str(i)+\"_ewm_mean_expanding.win\",str(i)+\"ewm_std_expanding.win\"]]= (\n","                                              df[i].ewm(alpha=alpha).\n","                                              agg([\"mean\",\"std\"])\n","                                              .shift(1)\n","                                            )\n","  return df\n","\n","def FeatureLagger(df,ListOfFeatures,granularity,PredictionHorizon):\n","\n","    time_intervals = []\n","    number_part = ''.join(filter(str.isdigit, granularity))\n","    Minutedensity=int(number_part)\n","    end_in_day=int((PredictionHorizon)/(Minutedensity))\n","    for i in range(1, 1+end_in_day):  # 24 hours * 60 minutes / 15 minutes = 96 intervals\n","        time_intervals.append(f\"{i * 15}min\")\n","\n","    lag_transformer= LagFeatures(variables=ListOfFeatures,\n","                                freq=time_intervals,\n","                                drop_original=False) #make a lagger transformer drop all original features\n","\n","    df=lag_transformer.fit_transform(df) # transform the features to DF joined\n","    return df\n","\n","\n","def ErrorCalculator(name, y_true, y_pred):\n","    errors = {\"Pipelines\": name,\n","              \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n","              \"MAE\": mean_absolute_error(y_true, y_pred),\n","              \"MSE\": mean_squared_error(y_true, y_pred),\n","\n","             }\n","    return errors\n","\n","\n","def separate_future_past_features(df_columns):\n","    \"\"\"\n","    Separates future and past features from a list of dataframe columns.\n","\n","    Args:\n","        df_columns (list): A list of column names from the dataframe.\n","\n","    Returns:\n","        dict: A dictionary with keys 'future_features' and 'past_features', containing the respective lists of column names.\n","    \"\"\"\n","    future_keywords = ['sin', 'cos', 'weekend', 'hour', 'holiday', 'minute', 'day','+']\n","\n","    future_features = []\n","    past_features = []\n","\n","    for col in df_columns:\n","        # Check if the column contains \"+\" in its name to classify as a past feature\n","        if any(keyword in col.lower() for keyword in future_keywords):\n","            future_features.append(col)\n","        # Columns that don't meet the above conditions are considered past features by default\n","        else:\n","            past_features.append(col)\n","\n","    return future_features, past_features\n","\n","\n","def plot_errors (ErrorSeries):\n","  \"\"\"\n","  This is a function that plots the features that are not\n","  \"\"\"\n","  import matplotlib as mpl\n","  import matplotlib.pyplot as plt\n","  import matplotlib.path as mpath\n","  import numpy as np\n","\n","  import matplotlib.pyplot as plt\n","  import numpy as np\n","\n","  x = np.arange(len(ErrorSeries.index))\n","  y = ErrorSeries.values\n","  labels = ErrorSeries.index\n","\n","  plt.figure(1,figsize=(13,5))\n","  plt.style.use(\"seaborn-v0_8-whitegrid\")\n","  plt.plot(x, y)\n","\n","  plt.xticks(x, labels, rotation =40)\n","  plt.ylabel('RMSE [€/MWh]', wrap=True)\n","  plt.xlabel('Features', wrap=True)\n","\n","\n","  plt.margins(0.05)\n","\n","  plt.subplots_adjust(bottom = 0.05)\n","  plt.show()\n","\n","\n","def select_features_minimum_plus_others(series):\n","    \"\"\"\n","    Takes a pandas Series and selects the features that:\n","    - Include all features up to the minimum error.\n","    - After the minimum error, only include features that reduce the error compared to the previous one.\n","    - Ensures no duplicate features are added.\n","\n","    Parameters:\n","    - series: A pandas Series where index are feature names and values are errors.\n","\n","    Returns:\n","    - A list of selected feature names without duplicates.\n","    \"\"\"\n","    # Find the index of the minimum value\n","    min_idx = series.idxmin()\n","\n","    # Select all features up to and including the minimum\n","    selected_features = list(dict.fromkeys(series[:min_idx].index.tolist() + [min_idx]))\n","\n","    # After the minimum, keep only the features that decrease the error\n","    after_min_series = series[min_idx:]\n","\n","    # Loop through the series after the minimum value and add features that decrease the error\n","    for i in range(1, len(after_min_series)):\n","        if after_min_series[i] < after_min_series[i - 1]:\n","            feature = after_min_series.index[i]\n","            if feature not in selected_features:\n","                selected_features.append(feature)\n","\n","    return selected_features\n","\n","def keep_indices_till_min(series):\n","    \"\"\"\n","    Keeps all index values from the series up to and including the minimum value using a for loop,\n","    while ensuring no duplicates are added.\n","\n","    Parameters:\n","    - series: A pandas Series where the index are feature names and the values are errors.\n","\n","    Returns:\n","    - A list of unique index values (features) up to and including the minimum error value.\n","    \"\"\"\n","    # Initialize an empty list to store the selected indices\n","    selected_features = []\n","\n","    # Find the minimum value in the series\n","    min_value = series.min()\n","\n","    # Loop over the series\n","    for idx, value in series.items():\n","        # Add the current index to the selected features only if it's not already present\n","        if idx not in selected_features:\n","            selected_features.append(idx)\n","\n","        # If the current value is the minimum, stop the loop\n","        if value == min_value:\n","            break\n","\n","    return selected_features\n","\n","def laggedColumnCreator(df,columnName,lagStart, lagInterval, lagEnd):\n","  for i in range(lagStart, lagEnd+1, lagInterval):\n","     newColumnName = columnName + \"-\" + str(i) + \"step\" #you gotta put it in string\n","     df[newColumnName] = df[columnName].shift(i)\n","  return df\n","\n","\n","def make_splits(\n","    test_start_str: str,\n","    freq: str = \"15min\",      # your timestep\n","    val_days: int = 14,\n","    train_steps: int = 7000,\n","    test_days: int = 14,       # length of test period\n","):\n","    step = pd.to_timedelta(freq)\n","\n","    # TEST\n","    test_start = pd.Timestamp(test_start_str)\n","    # If you slice df.loc[start:end] (inclusive), use -step to get exactly `test_days` worth of data\n","    test_end = test_start + pd.Timedelta(days=test_days)\n","\n","    # VALIDATION (ends one step before test_start)\n","    validation_end = test_start - step\n","    # `val_days` long, inclusive: end - start = val_days days - step\n","    validation_start = validation_end - pd.Timedelta(days=val_days) + step\n","\n","    # TRAIN (ends one step before validation_start)\n","    train_end = validation_start - step\n","    # exactly `train_steps` steps long: end - start = (train_steps - 1) * step\n","    train_start = validation_start - train_steps * step\n","\n","    return {\n","        \"train_start\": train_start,\n","        \"train_end\": train_end,\n","        \"validation_start\": validation_start,\n","        \"validation_end\": validation_end,\n","        \"test_start\": test_start,\n","        \"test_end\": test_end,\n","    }\n","\n","\n","def FeatureSelection(regressor, DF_features, DF_target, ordered_features_list, test_size=672, tolerance=400):\n","    \"\"\"\n","    This function receives a regressor model, the features that the model was trained with,\n","    and the target that it had to forecast. Starting from the most important feature,\n","    we find the error of the TimeSeries Cross-Validation with a fixed test size.\n","    By adding features, we find the new error of the forecast.\n","\n","    Parameters:\n","    - regressor: The regression model to use for training and prediction.\n","    - DF_features: DataFrame containing the features.\n","    - DF_target: Series containing the target variable.\n","    - ordered_features_list: List of features ordered by importance (e.g., from SHAP analysis).\n","    - test_size: Number of steps to use in the test set (default is 672).\n","    - tolerance: Number of features to add before stopping if no improvement in error (default is 20).\n","\n","    Returns:\n","    - ErrorSeries: A pandas Series with the errors for each step of feature addition.\n","    \"\"\"\n","\n","    feature_list = []  # Empty list of features\n","    error_list = []  # Empty list to store errors for each set of features\n","    total_samples = len(DF_features)  # Total number of samples in the dataset\n","    n_splits = 5  # Number of splits (fixed)\n","    no_improvement_count = 0  # Count features added without improvement\n","    min_error = float('inf')  # Start with a large error to track the minimum error\n","\n","    for i in ordered_features_list:\n","        # Start the loop with the best feature and append the next ones\n","        feature_list.append(i)\n","\n","        X = DF_features[feature_list].to_numpy()\n","        y = DF_target.to_numpy()\n","\n","        #print(f\"Performing feature selection with features: {feature_list}\")\n","\n","        # Custom logic to create splits with a fixed test size of 672\n","        splits = []\n","        start_train_size = total_samples - (n_splits * test_size)  # Calculate where to start training\n","\n","        for split in range(n_splits):\n","            train_end = start_train_size + split * test_size\n","            test_start = train_end\n","            test_end = test_start + test_size\n","\n","            if test_end <= total_samples:  # Ensure the test set is within the bounds\n","                splits.append((list(range(0, train_end)), list(range(test_start, test_end))))\n","\n","        TimeSeriesCVerror = []  # MSE errors for each fold\n","\n","        # Time series cross-validation with fixed test size\n","        for train_index, test_index in splits:\n","            #print(f\"TRAIN: {train_index}, TEST: {test_index}\")\n","            X_train, X_test = X[train_index], X[test_index]\n","            y_train, y_test = y[train_index], y[test_index]\n","\n","            # Train the regressor and predict\n","            regressor.fit(X_train, y_train)\n","            predicted_val = regressor.predict(X_test)\n","\n","            # Calculate the error for this fold\n","            Error = np.sqrt(mean_squared_error(y_test, predicted_val))\n","            TimeSeriesCVerror.append(Error)\n","            #print(f\"This is the error for one TS iteration: {Error}\")\n","\n","        # Calculate the average error across all splits\n","        TS_CV_error = sum(TimeSeriesCVerror) / len(TimeSeriesCVerror)\n","        #print(f\"Cumulative error of the last steps: {TS_CV_error}\")\n","        error_list.append(TS_CV_error)  # Store the error for this set of features\n","\n","        # Check if the error improved\n","        if TS_CV_error < min_error:\n","            min_error = TS_CV_error  # Update the minimum error\n","            no_improvement_count = 0  # Reset the no-improvement count\n","        else:\n","            no_improvement_count += 1  # Increment if there's no improvement\n","\n","        # Break the loop if no improvement is observed after 20 features\n","        if no_improvement_count >= tolerance:\n","            print(f\"No improvement after {tolerance} features. Stopping early.\")\n","            break\n","\n","    # Create a pandas Series to store the error associated with each feature\n","    ErrorSeries = pd.Series(error_list, index=feature_list)\n","\n","    # Plot the errors using a custom plot function\n","    plot_errors(ErrorSeries)\n","\n","    return ErrorSeries"],"metadata":{"id":"dvcVDWpOKRN3","executionInfo":{"status":"ok","timestamp":1768996365360,"user_tz":-60,"elapsed":266,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# start"],"metadata":{"id":"jncuxW1sR5BZ"}},{"cell_type":"code","source":["filename=\"NO2_price_10min_2024_2025.xlsx\"\n","#define the path of the folder with the data\n","path=\"/content/gdrive/MyDrive/IEEE-EEM2026/\"\n","#join the folder with the name of the file I want to study\n","\n","df = pd.read_excel(os.path.join(path,filename), parse_dates=[0]).set_index('timestamp')\n","df = df[~df.index.duplicated(keep='first')] # Drop duplicate timestamps before setting frequency\n","df = df.asfreq('10min') # Set the frequency of the index\n","\n","OriginalFeatures=df.columns.to_list()\n","\n","df[\"target\"]=df[\"NO2 price (NOK/kWh)\"]\n","target=\"target\"\n","\n","OutputPath = r\"C:\\Users\\User\\Desktop\\_badenova_forecaster\\outputs\"\n","\n","granularity=\"10min\"\n","prediction_horizon=\"1440min\"\n","\n","number_part_hor = ''.join(filter(str.isdigit, prediction_horizon))\n","PredictionHorizon=int(number_part_hor)\n","number_part = ''.join(filter(str.isdigit, granularity))\n","Minutedensity=int(number_part)\n","fourier_terms_list=[2,2,2,2]\n","prediction_horizon_steps=PredictionHorizon//Minutedensity # this is 96\n","print(\"this is the prediction horizon in steps\", prediction_horizon_steps)\n","# lets make some features\n","lagStart = prediction_horizon_steps          # Start lagging from 1 step\n","lagInterval = 1       # Interval of 1 step\n","lagEnd = prediction_horizon_steps *2\n","\n","for feature in OriginalFeatures:\n","    df = laggedColumnCreator(df, feature, lagStart, lagInterval, lagEnd)\n","#lets build the target and the features\n","df=HolidayFeatureCreator(df)\n","df=CreateWorkHourFeature(df)\n","df=TimeRelatedFeatureConstructor(df)\n","df=FourierFeatureConstructor(df,granularity,fourier_terms_list)\n","\n","df=df.drop(columns=OriginalFeatures)\n","\n","df.dropna(inplace=True)"],"metadata":{"id":"i9hNWTTUR4fm","executionInfo":{"status":"ok","timestamp":1768996386973,"user_tz":-60,"elapsed":21465,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b1b37f6-d8b1-4bdd-b347-780ad2feccae"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["this is the prediction horizon in steps 144\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:482: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[newColumnName] = df[columnName].shift(i)\n","/tmp/ipython-input-2329344273.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"Holidays_flag\"] = 0\n","/tmp/ipython-input-2329344273.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"dayOfWeek\"] = input_df.index.dayofweek\n","/tmp/ipython-input-2329344273.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df.loc[input_df[\"dayOfWeek\"] > 4, \"weekendFlag\"] = 1\n","/tmp/ipython-input-2329344273.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"hour\"] = input_df.index.hour\n","/tmp/ipython-input-2329344273.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  input_df[\"WorkingHour_flag\"] = 0\n"]}]},{"cell_type":"code","source":["test_date=\"2025-06-01 00:00:00\" #summer\n","#test_date=\"2025-02-01 00:00:00\" #winter\n","\n","\n","# Example\n","splits = make_splits(test_date, freq=\"10min\", val_days=14, train_steps=5000)\n","\n","train_start=splits[\"train_start\"]\n","train_end=splits[\"train_end\"]\n","validation_start=splits[\"validation_start\"]\n","validation_end=splits[\"validation_end\"]\n","test_start=splits[\"test_start\"]\n","test_end =splits[\"test_end\"]\n","\n","#lets split them\n","DF_training = df[train_start:train_end]  # Include up to train_end_date\n","DF_validation = df[validation_start:validation_end]  # Start after train_end_date\n","DF_test = df[test_start:test_end]  # Start after validation_end_date\n","\n","\n","DF_training_and_DF_validation=pd.concat([DF_training,DF_validation])\n","Selected_Features=DF_training_and_DF_validation.drop([target],axis=1) # df, all features except target in a dataframe for the first period\n","DF_target=DF_training_and_DF_validation[target] #one column df of the target for the next period\n"],"metadata":{"id":"IZ-YxhBlV0ub","executionInfo":{"status":"ok","timestamp":1768996386981,"user_tz":-60,"elapsed":2,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"15e45e85","executionInfo":{"status":"ok","timestamp":1768996453055,"user_tz":-60,"elapsed":66071,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"19cb3923-9deb-4270-99eb-6851533184b1"},"source":["from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","# Define features (X) and target (y)\n","X = Selected_Features\n","y = DF_target\n","\n","# Initialize GradientBoostingRegressor\n","model = GradientBoostingRegressor()\n","\n","# Initialize TimeSeriesSplit\n","# n_splits determines the number of train/test splits to generate.\n","# Each split's training set grows, and its test set is a fixed size (the last part of the data).\n","# For example, if n_splits=5, there will be 5 splits.\n","# The first split might use 20% for train, 20% for test, and the last uses 80% for train, 20% for test.\n","tscv = TimeSeriesSplit(n_splits=5)\n","\n","rmse_scores = []\n","\n","# Perform Time Series Cross-Validation\n","for train_index, test_index in tscv.split(X):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate RMSE and store it\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","    rmse_scores.append(rmse)\n","\n","print(f\"RMSE scores for each fold: {rmse_scores}\")\n","print(f\"Average RMSE across all folds: {np.mean(rmse_scores)}\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE scores for each fold: [np.float64(0.4895493480610696), np.float64(0.3874805967311951), np.float64(0.2915172991879452), np.float64(0.276142678717892), np.float64(0.29506903251487054)]\n","Average RMSE across all folds: 0.34795179104259455\n"]}]},{"cell_type":"code","metadata":{"id":"4b40e176","executionInfo":{"status":"ok","timestamp":1768996453250,"user_tz":-60,"elapsed":199,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9b9d2d2-a9ae-45bb-ea30-2662248a7974"},"source":["import optuna\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import GradientBoostingRegressor # Ensure GradientBoostingRegressor is imported\n","\n","def objective(trial):\n","    # 3. Suggest hyperparameters for GradientBoostingRegressor\n","    param = {\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n","        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n","        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n","        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n","        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]), # 'auto' removed\n","        'random_state': 42\n","    }\n","\n","    # 4. Initialize a GradientBoostingRegressor model using the suggested hyperparameters\n","    model = GradientBoostingRegressor(**param)\n","\n","    # 5. Instantiate TimeSeriesSplit\n","    tscv = TimeSeriesSplit(n_splits=5)\n","\n","    # 6. Initialize an empty list to store RMSE scores for each fold\n","    rmse_scores = []\n","\n","    # Use the globally available X (Selected_Features) and y (DF_target)\n","    X = Selected_Features\n","    y = DF_target\n","\n","    # 7. Loop through the splits generated by TimeSeriesSplit\n","    for train_index, test_index in tscv.split(X):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","        # 8. Train the model and make predictions\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # 9. Calculate RMSE for each fold and append it to the rmse_scores list\n","        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","        rmse_scores.append(rmse)\n","\n","    # 10. Calculate the mean of the rmse_scores\n","    mean_rmse = np.mean(rmse_scores)\n","\n","    # 11. Return the calculated mean RMSE\n","    return mean_rmse\n","\n","print(\"Optuna objective function 'objective' defined successfully.\")"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Optuna objective function 'objective' defined successfully.\n"]}]},{"cell_type":"code","metadata":{"id":"c62d71e9","executionInfo":{"status":"ok","timestamp":1768999700386,"user_tz":-60,"elapsed":3247135,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d5f3374b2a8e46c1b2559225c1022882","16eb8054eeab401084956cb7093bf4df","8486f49f289747988c43895cee31832d","a7b596ad5a7244a0a18be942e2a7b28b","d191e48f6be543709c06b4eaf3fed9ee","857e0007c6db45b7ad5bdf7cef343be1","4a61b1e38e884e3ea045f4d6d2f7a85f","1288985638b44ab3ab91335da722feb2","47c5a8441a8f4ce3af48aa772de44cff","3efbe83418e54665bc79f0168b4fc651","9ce7259834804e3f82455398cd783717"]},"outputId":"6f542c46-452e-4b46-c9a1-12a7f4bf9557"},"source":["import joblib\n","import optuna\n","\n","# 1. Create an Optuna study\n","# Using a TPE sampler with a seed for reproducibility\n","sampler = optuna.samplers.TPESampler(seed=42)\n","study = optuna.create_study(direction='minimize', sampler=sampler)\n","\n","# 2. Run the optimization process\n","# You can adjust n_trials based on computational resources and desired exploration\n","print(\"Starting Optuna optimization...\")\n","study.optimize(objective, n_trials=30, show_progress_bar=True) # Increased n_trials for better optimization\n","print(\"Optuna optimization finished.\")\n","\n","# 3. Print the best trial's value and parameters\n","print(\"\\nBest trial:\")\n","trial = study.best_trial\n","print(f\"  Value (Mean RMSE): {trial.value:.4f}\")\n","print(\"  Params:\")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")\n","\n","# 4. Retrieve the best hyperparameters from the Optuna study\n","best_params = study.best_params\n","\n","# 5. Train a final GradientBoostingRegressor model with the best parameters\n","print(\"\\nTraining final GradientBoostingRegressor model with best parameters...\")\n","# Corrected: Use GradientBoostingRegressor instead of LGBMRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","final_model = GradientBoostingRegressor(**best_params, random_state=42)\n","\n","X_train=DF_training_and_DF_validation.drop([target],axis=1) # df, all features except target in a dataframe for the first period\n","X_test=DF_test.drop([target],axis=1) #df , all feature except target (same as before but for the next available period period)\n","y_train=DF_training_and_DF_validation[target] #one column df, of the target for the first period\n","y_test=DF_test[target] #one column df of the target for the next period\n","\n","\n","final_model.fit(X_train , y_train)\n","\n","predicted_val = final_model.predict(X_test)\n","\n","name=\"GradientBoosting\"\n","d=ErrorCalculator(name,y_test,predicted_val)\n","print(d)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2026-01-21 11:54:13,886] A new study created in memory with name: no-name-0891d995-8941-427b-9891-a7cb7532f332\n"]},{"output_type":"stream","name":"stdout","text":["Starting Optuna optimization...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5f3374b2a8e46c1b2559225c1022882"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 11:54:42,834] Trial 0 finished with value: 0.36424969473938373 and parameters: {'n_estimators': 437, 'learning_rate': 0.17254716573280354, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 4, 'subsample': 0.662397808134481, 'max_features': 'log2'}. Best is trial 0 with value: 0.36424969473938373.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:13:25,942] Trial 1 finished with value: 0.43953272801005544 and parameters: {'n_estimators': 737, 'learning_rate': 0.010636066512540286, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 5, 'subsample': 0.6727299868828402, 'max_features': None}. Best is trial 0 with value: 0.36424969473938373.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:13:55,499] Trial 2 finished with value: 0.3457819221749202 and parameters: {'n_estimators': 489, 'learning_rate': 0.023927528765580644, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7465447373174767, 'max_features': 'log2'}. Best is trial 2 with value: 0.3457819221749202.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:14:11,403] Trial 3 finished with value: 0.3481043335754977 and parameters: {'n_estimators': 563, 'learning_rate': 0.05898602410432694, 'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 4, 'subsample': 0.6260206371941118, 'max_features': 'log2'}. Best is trial 2 with value: 0.3457819221749202.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:14:37,570] Trial 4 finished with value: 0.3472896263654713 and parameters: {'n_estimators': 374, 'learning_rate': 0.013399060561509796, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3, 'subsample': 0.798070764044508, 'max_features': 'log2'}. Best is trial 2 with value: 0.3457819221749202.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:15:27,455] Trial 5 finished with value: 0.3477509316659694 and parameters: {'n_estimators': 696, 'learning_rate': 0.02544166090938368, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 4, 'subsample': 0.9878338511058234, 'max_features': 'log2'}. Best is trial 2 with value: 0.3457819221749202.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:21:18,494] Trial 6 finished with value: 0.3642115962443156 and parameters: {'n_estimators': 638, 'learning_rate': 0.15826541904647565, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.7301321323053057, 'max_features': None}. Best is trial 2 with value: 0.3457819221749202.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:21:56,370] Trial 7 finished with value: 0.3479693991433289 and parameters: {'n_estimators': 421, 'learning_rate': 0.023200867504756827, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 17, 'subsample': 0.6298202574719083, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.3457819221749202.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:24:00,179] Trial 8 finished with value: 0.38282290286016296 and parameters: {'n_estimators': 104, 'learning_rate': 0.11506408247250169, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 16, 'subsample': 0.6296178606936361, 'max_features': None}. Best is trial 2 with value: 0.3457819221749202.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:24:21,923] Trial 9 finished with value: 0.3448033977746117 and parameters: {'n_estimators': 661, 'learning_rate': 0.026946865572417687, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.8918424713352255, 'max_features': 'log2'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:25:47,276] Trial 10 finished with value: 0.35509035491273483 and parameters: {'n_estimators': 962, 'learning_rate': 0.05868829572187741, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 11, 'subsample': 0.9407901565064135, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:26:29,817] Trial 11 finished with value: 0.35201425491014404 and parameters: {'n_estimators': 863, 'learning_rate': 0.027263309051458535, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8752105786173419, 'max_features': 'log2'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:26:40,950] Trial 12 finished with value: 0.34814536253638095 and parameters: {'n_estimators': 227, 'learning_rate': 0.03618276288001496, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.8208104960302076, 'max_features': 'log2'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:27:11,719] Trial 13 finished with value: 0.34585409999005645 and parameters: {'n_estimators': 806, 'learning_rate': 0.016684235943740956, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 12, 'subsample': 0.7588937953517324, 'max_features': 'log2'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:28:03,401] Trial 14 finished with value: 0.3452670468244123 and parameters: {'n_estimators': 563, 'learning_rate': 0.04677264774635739, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.8816262900890811, 'max_features': 'log2'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:29:46,299] Trial 15 finished with value: 0.34924290965653265 and parameters: {'n_estimators': 638, 'learning_rate': 0.08144088917473381, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.8900182956288196, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:30:10,876] Trial 16 finished with value: 0.35014408074055364 and parameters: {'n_estimators': 309, 'learning_rate': 0.04932457903375384, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 14, 'subsample': 0.8829895887548838, 'max_features': 'log2'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:30:42,953] Trial 17 finished with value: 0.3508813006402641 and parameters: {'n_estimators': 544, 'learning_rate': 0.03776092969430832, 'max_depth': 6, 'min_samples_split': 20, 'min_samples_leaf': 20, 'subsample': 0.938353452654221, 'max_features': 'log2'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:41:57,988] Trial 18 finished with value: 0.36878354999017005 and parameters: {'n_estimators': 856, 'learning_rate': 0.07515308190925067, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.8395661630538819, 'max_features': None}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:43:30,002] Trial 19 finished with value: 0.3462620337994498 and parameters: {'n_estimators': 589, 'learning_rate': 0.018646146230946663, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.9987577540219446, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:44:30,247] Trial 20 finished with value: 0.34897041306121823 and parameters: {'n_estimators': 999, 'learning_rate': 0.03689413928521844, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 13, 'subsample': 0.9392334233963489, 'max_features': 'log2'}. Best is trial 9 with value: 0.3448033977746117.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:45:08,266] Trial 21 finished with value: 0.34443858627668134 and parameters: {'n_estimators': 497, 'learning_rate': 0.029268991193954694, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7595402204954409, 'max_features': 'log2'}. Best is trial 21 with value: 0.34443858627668134.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:45:48,844] Trial 22 finished with value: 0.34746868012227755 and parameters: {'n_estimators': 489, 'learning_rate': 0.03123702295529098, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.7838349971993009, 'max_features': 'log2'}. Best is trial 21 with value: 0.34443858627668134.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:46:47,624] Trial 23 finished with value: 0.3457570364372958 and parameters: {'n_estimators': 731, 'learning_rate': 0.04731593119990702, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.8429551946489617, 'max_features': 'log2'}. Best is trial 21 with value: 0.34443858627668134.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:47:12,712] Trial 24 finished with value: 0.3436792563922323 and parameters: {'n_estimators': 354, 'learning_rate': 0.017936249194558097, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.707950608333635, 'max_features': 'log2'}. Best is trial 24 with value: 0.3436792563922323.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:47:33,309] Trial 25 finished with value: 0.345924322461765 and parameters: {'n_estimators': 284, 'learning_rate': 0.020365737601593787, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.7172938357381968, 'max_features': 'log2'}. Best is trial 24 with value: 0.3436792563922323.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:47:43,106] Trial 26 finished with value: 0.3414000235689851 and parameters: {'n_estimators': 149, 'learning_rate': 0.014080182933039453, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6848433923890892, 'max_features': 'log2'}. Best is trial 26 with value: 0.3414000235689851.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:47:49,844] Trial 27 finished with value: 0.340288736650873 and parameters: {'n_estimators': 112, 'learning_rate': 0.014045491532625938, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.7128891580731868, 'max_features': 'log2'}. Best is trial 27 with value: 0.340288736650873.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:48:03,087] Trial 28 finished with value: 0.3381325761302376 and parameters: {'n_estimators': 120, 'learning_rate': 0.01008097268404675, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.6936243976917326, 'max_features': 'sqrt'}. Best is trial 28 with value: 0.3381325761302376.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3370771178.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n"]},{"output_type":"stream","name":"stdout","text":["[I 2026-01-21 12:48:15,464] Trial 29 finished with value: 0.3382128759213653 and parameters: {'n_estimators': 111, 'learning_rate': 0.011054997968519263, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.6827449380817949, 'max_features': 'sqrt'}. Best is trial 28 with value: 0.3381325761302376.\n","Optuna optimization finished.\n","\n","Best trial:\n","  Value (Mean RMSE): 0.3381\n","  Params:\n","    n_estimators: 120\n","    learning_rate: 0.01008097268404675\n","    max_depth: 8\n","    min_samples_split: 2\n","    min_samples_leaf: 5\n","    subsample: 0.6936243976917326\n","    max_features: sqrt\n","\n","Training final GradientBoostingRegressor model with best parameters...\n","{'Pipelines': 'GradientBoosting', 'RMSE': np.float64(0.24390578689087578), 'MAE': 0.16609121385139064, 'MSE': 0.05949003287885731}\n"]}]},{"cell_type":"code","source":["predicted_DF = pd.DataFrame(predicted_val , index=DF_test.index, columns=[\"GradientBoosting\"])\n","\n","predicted_DF = predicted_DF.join(y_test)\n","\n","predicted_DF=predicted_DF.loc[DF_test.index]\n","\n","predicted_DF.columns = [\"GradientBoosting\", \"target\"]\n","\n","\n","predicted_DF[:300].plot()"],"metadata":{"id":"00BVmpFpcar0","executionInfo":{"status":"ok","timestamp":1768999701738,"user_tz":-60,"elapsed":1344,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}},"colab":{"base_uri":"https://localhost:8080/","height":499},"outputId":"68ddc21c-c960-4eeb-f525-e28608b1395b"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='timestamp'>"]},"metadata":{},"execution_count":12},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Ensure it's a Timestamp / datetime\n","test_date_ts = pd.to_datetime(test_date)\n","\n","# Format without forbidden chars (:, etc.)\n","test_date_str = test_date_ts.strftime(\"%Y-%m-%d_%H-%M-%S\")  # e.g. 2025-09-19_00-00-00\n","\n","test_ts = f\"{test_date_str}_GradientBoosting.csv\"\n","test_filepath = os.path.join(path, test_ts)\n","\n","predicted_DF[\"GradientBoosting\"].to_csv(test_filepath, index=True)"],"metadata":{"id":"pihCwffEc-2b","executionInfo":{"status":"ok","timestamp":1768999701744,"user_tz":-60,"elapsed":3,"user":{"displayName":"Dimitrios Papadopoulos","userId":"00591946952139354992"}}},"execution_count":13,"outputs":[]}]}